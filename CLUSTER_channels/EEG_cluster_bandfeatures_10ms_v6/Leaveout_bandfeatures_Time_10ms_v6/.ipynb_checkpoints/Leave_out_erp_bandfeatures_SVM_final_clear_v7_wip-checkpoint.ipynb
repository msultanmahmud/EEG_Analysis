{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libirires shuffle, and hyperparameters [Cross-validation](http://scikit-learn.org/stable/modules/cross_validation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score,ShuffleSplit,LeaveOneOut\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,roc_curve, auc,classification_report\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "from scipy.stats import norm, zscore\n",
    "#import seaborn as sns; sns.set(font_scale=1.2)\n",
    "from sklearn.externals import joblib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9.062235e-14</td>\n",
       "      <td>4.130522e-14</td>\n",
       "      <td>3.495434e-14</td>\n",
       "      <td>1.295076e-13</td>\n",
       "      <td>1.901673e-13</td>\n",
       "      <td>8.048468e-14</td>\n",
       "      <td>3.531210e-14</td>\n",
       "      <td>3.196135e-14</td>\n",
       "      <td>1.143896e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.067692e-13</td>\n",
       "      <td>4.193570e-14</td>\n",
       "      <td>4.586276e-14</td>\n",
       "      <td>1.455026e-13</td>\n",
       "      <td>2.143150e-13</td>\n",
       "      <td>2.462601e-14</td>\n",
       "      <td>1.010044e-14</td>\n",
       "      <td>9.922016e-15</td>\n",
       "      <td>2.935956e-14</td>\n",
       "      <td>4.736799e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.913017e-13</td>\n",
       "      <td>6.042521e-15</td>\n",
       "      <td>1.872660e-14</td>\n",
       "      <td>2.221667e-13</td>\n",
       "      <td>3.210776e-13</td>\n",
       "      <td>1.581491e-13</td>\n",
       "      <td>5.663927e-15</td>\n",
       "      <td>1.833481e-14</td>\n",
       "      <td>1.842429e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.524585e-13</td>\n",
       "      <td>1.104273e-14</td>\n",
       "      <td>3.634665e-14</td>\n",
       "      <td>1.814725e-13</td>\n",
       "      <td>2.693697e-13</td>\n",
       "      <td>1.737748e-14</td>\n",
       "      <td>5.566461e-15</td>\n",
       "      <td>1.397429e-14</td>\n",
       "      <td>2.295641e-14</td>\n",
       "      <td>3.469796e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.017000e-13</td>\n",
       "      <td>8.795132e-14</td>\n",
       "      <td>1.394948e-14</td>\n",
       "      <td>1.845844e-13</td>\n",
       "      <td>2.366540e-13</td>\n",
       "      <td>9.215951e-14</td>\n",
       "      <td>7.936271e-14</td>\n",
       "      <td>1.636610e-14</td>\n",
       "      <td>1.655971e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.307338e-13</td>\n",
       "      <td>1.173222e-13</td>\n",
       "      <td>5.320181e-14</td>\n",
       "      <td>2.317469e-13</td>\n",
       "      <td>2.941198e-13</td>\n",
       "      <td>3.078723e-14</td>\n",
       "      <td>3.158777e-14</td>\n",
       "      <td>3.005926e-14</td>\n",
       "      <td>5.825906e-14</td>\n",
       "      <td>6.276757e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2.883162e-13</td>\n",
       "      <td>1.718212e-14</td>\n",
       "      <td>8.996052e-14</td>\n",
       "      <td>3.496524e-13</td>\n",
       "      <td>6.856537e-13</td>\n",
       "      <td>2.404430e-13</td>\n",
       "      <td>1.522790e-14</td>\n",
       "      <td>7.388476e-14</td>\n",
       "      <td>2.925383e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>2.370522e-13</td>\n",
       "      <td>2.045834e-14</td>\n",
       "      <td>6.823475e-14</td>\n",
       "      <td>2.931582e-13</td>\n",
       "      <td>5.419109e-13</td>\n",
       "      <td>2.694255e-14</td>\n",
       "      <td>4.983685e-15</td>\n",
       "      <td>6.765318e-15</td>\n",
       "      <td>3.386905e-14</td>\n",
       "      <td>4.923570e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.449475e-13</td>\n",
       "      <td>1.555291e-13</td>\n",
       "      <td>5.523409e-14</td>\n",
       "      <td>1.438152e-13</td>\n",
       "      <td>3.171872e-13</td>\n",
       "      <td>1.239206e-13</td>\n",
       "      <td>1.310694e-13</td>\n",
       "      <td>5.341977e-14</td>\n",
       "      <td>1.254590e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.356595e-13</td>\n",
       "      <td>1.428580e-13</td>\n",
       "      <td>1.040858e-13</td>\n",
       "      <td>1.544794e-13</td>\n",
       "      <td>3.228246e-13</td>\n",
       "      <td>1.949444e-14</td>\n",
       "      <td>2.611271e-14</td>\n",
       "      <td>4.226952e-14</td>\n",
       "      <td>3.290497e-14</td>\n",
       "      <td>8.106339e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1.029596e-13</td>\n",
       "      <td>4.820368e-14</td>\n",
       "      <td>7.050277e-14</td>\n",
       "      <td>5.328622e-14</td>\n",
       "      <td>1.709448e-13</td>\n",
       "      <td>8.501017e-14</td>\n",
       "      <td>4.034812e-14</td>\n",
       "      <td>5.793891e-14</td>\n",
       "      <td>4.481823e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>7.926026e-14</td>\n",
       "      <td>4.188637e-14</td>\n",
       "      <td>5.223299e-14</td>\n",
       "      <td>4.616245e-14</td>\n",
       "      <td>1.454461e-13</td>\n",
       "      <td>6.768807e-15</td>\n",
       "      <td>6.303458e-15</td>\n",
       "      <td>4.221057e-15</td>\n",
       "      <td>5.898320e-15</td>\n",
       "      <td>1.570370e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1.260067e-13</td>\n",
       "      <td>1.503067e-14</td>\n",
       "      <td>3.029189e-13</td>\n",
       "      <td>4.896017e-13</td>\n",
       "      <td>3.926549e-13</td>\n",
       "      <td>1.075261e-13</td>\n",
       "      <td>1.304163e-14</td>\n",
       "      <td>2.625853e-13</td>\n",
       "      <td>4.115503e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.174973e-13</td>\n",
       "      <td>1.544006e-14</td>\n",
       "      <td>3.063713e-13</td>\n",
       "      <td>4.191675e-13</td>\n",
       "      <td>3.273886e-13</td>\n",
       "      <td>1.730275e-14</td>\n",
       "      <td>2.694448e-15</td>\n",
       "      <td>4.897646e-14</td>\n",
       "      <td>4.883845e-14</td>\n",
       "      <td>3.733034e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>4.112735e-14</td>\n",
       "      <td>2.851334e-14</td>\n",
       "      <td>3.304322e-14</td>\n",
       "      <td>3.117144e-14</td>\n",
       "      <td>2.337348e-13</td>\n",
       "      <td>3.667084e-14</td>\n",
       "      <td>2.434718e-14</td>\n",
       "      <td>2.952262e-14</td>\n",
       "      <td>2.978675e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>5.151590e-14</td>\n",
       "      <td>2.857869e-14</td>\n",
       "      <td>4.138833e-14</td>\n",
       "      <td>5.273701e-14</td>\n",
       "      <td>2.241908e-13</td>\n",
       "      <td>1.490220e-14</td>\n",
       "      <td>7.121807e-15</td>\n",
       "      <td>1.077298e-14</td>\n",
       "      <td>1.815318e-14</td>\n",
       "      <td>3.724769e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>4.006348e-14</td>\n",
       "      <td>3.367356e-14</td>\n",
       "      <td>3.503045e-14</td>\n",
       "      <td>4.765621e-14</td>\n",
       "      <td>1.085760e-13</td>\n",
       "      <td>3.847278e-14</td>\n",
       "      <td>3.053790e-14</td>\n",
       "      <td>3.111129e-14</td>\n",
       "      <td>4.504753e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>6.872467e-14</td>\n",
       "      <td>4.744840e-14</td>\n",
       "      <td>4.977599e-14</td>\n",
       "      <td>7.818609e-14</td>\n",
       "      <td>1.640759e-13</td>\n",
       "      <td>2.267830e-14</td>\n",
       "      <td>1.462856e-14</td>\n",
       "      <td>2.287678e-14</td>\n",
       "      <td>2.678258e-14</td>\n",
       "      <td>4.637800e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>4.119818e-14</td>\n",
       "      <td>6.748188e-14</td>\n",
       "      <td>5.702418e-14</td>\n",
       "      <td>6.871250e-14</td>\n",
       "      <td>1.291316e-13</td>\n",
       "      <td>3.736217e-14</td>\n",
       "      <td>5.632346e-14</td>\n",
       "      <td>4.901976e-14</td>\n",
       "      <td>6.198453e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>5.128360e-14</td>\n",
       "      <td>6.176596e-14</td>\n",
       "      <td>5.597567e-14</td>\n",
       "      <td>8.468713e-14</td>\n",
       "      <td>1.560156e-13</td>\n",
       "      <td>1.081420e-14</td>\n",
       "      <td>1.441466e-14</td>\n",
       "      <td>8.338221e-15</td>\n",
       "      <td>1.975151e-14</td>\n",
       "      <td>3.277283e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1.312647e-13</td>\n",
       "      <td>7.477556e-14</td>\n",
       "      <td>2.072499e-14</td>\n",
       "      <td>1.226857e-13</td>\n",
       "      <td>3.144261e-13</td>\n",
       "      <td>1.148339e-13</td>\n",
       "      <td>7.298705e-14</td>\n",
       "      <td>2.137020e-14</td>\n",
       "      <td>1.061915e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.447837e-13</td>\n",
       "      <td>1.383818e-13</td>\n",
       "      <td>4.838253e-14</td>\n",
       "      <td>1.271844e-13</td>\n",
       "      <td>3.939809e-13</td>\n",
       "      <td>2.888245e-14</td>\n",
       "      <td>4.613706e-14</td>\n",
       "      <td>1.992346e-14</td>\n",
       "      <td>2.257416e-14</td>\n",
       "      <td>8.719823e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1.477169e-13</td>\n",
       "      <td>9.006077e-15</td>\n",
       "      <td>6.261339e-15</td>\n",
       "      <td>1.272914e-13</td>\n",
       "      <td>1.327922e-13</td>\n",
       "      <td>1.252132e-13</td>\n",
       "      <td>8.181049e-15</td>\n",
       "      <td>5.914774e-15</td>\n",
       "      <td>1.075611e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.332400e-13</td>\n",
       "      <td>1.356149e-14</td>\n",
       "      <td>9.565100e-15</td>\n",
       "      <td>1.127287e-13</td>\n",
       "      <td>1.219308e-13</td>\n",
       "      <td>1.855093e-14</td>\n",
       "      <td>5.558167e-15</td>\n",
       "      <td>2.478933e-15</td>\n",
       "      <td>1.622432e-14</td>\n",
       "      <td>1.848264e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>3.999037e-14</td>\n",
       "      <td>3.998425e-14</td>\n",
       "      <td>1.026865e-13</td>\n",
       "      <td>9.943638e-14</td>\n",
       "      <td>3.374541e-13</td>\n",
       "      <td>3.537716e-14</td>\n",
       "      <td>3.461581e-14</td>\n",
       "      <td>8.737639e-14</td>\n",
       "      <td>8.558423e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>4.570524e-14</td>\n",
       "      <td>4.240168e-14</td>\n",
       "      <td>9.749379e-14</td>\n",
       "      <td>1.005637e-13</td>\n",
       "      <td>2.951104e-13</td>\n",
       "      <td>8.891083e-15</td>\n",
       "      <td>8.603102e-15</td>\n",
       "      <td>1.574273e-14</td>\n",
       "      <td>2.185782e-14</td>\n",
       "      <td>3.612818e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>3.872944e-14</td>\n",
       "      <td>1.048018e-14</td>\n",
       "      <td>1.069865e-14</td>\n",
       "      <td>4.271296e-14</td>\n",
       "      <td>1.153013e-13</td>\n",
       "      <td>3.631187e-14</td>\n",
       "      <td>9.512314e-15</td>\n",
       "      <td>9.429760e-15</td>\n",
       "      <td>3.932135e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>5.978893e-14</td>\n",
       "      <td>1.433449e-14</td>\n",
       "      <td>1.177428e-14</td>\n",
       "      <td>5.706191e-14</td>\n",
       "      <td>1.219382e-13</td>\n",
       "      <td>1.925680e-14</td>\n",
       "      <td>4.281601e-15</td>\n",
       "      <td>2.084140e-15</td>\n",
       "      <td>1.224343e-14</td>\n",
       "      <td>1.811147e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>2.025260e-13</td>\n",
       "      <td>1.205531e-13</td>\n",
       "      <td>1.743924e-14</td>\n",
       "      <td>7.843901e-14</td>\n",
       "      <td>3.157967e-13</td>\n",
       "      <td>1.744051e-13</td>\n",
       "      <td>1.010062e-13</td>\n",
       "      <td>1.643959e-14</td>\n",
       "      <td>6.951262e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>2.173745e-13</td>\n",
       "      <td>1.195586e-13</td>\n",
       "      <td>3.226330e-14</td>\n",
       "      <td>9.708568e-14</td>\n",
       "      <td>3.399544e-13</td>\n",
       "      <td>6.305806e-14</td>\n",
       "      <td>3.626033e-14</td>\n",
       "      <td>1.591026e-14</td>\n",
       "      <td>2.593712e-14</td>\n",
       "      <td>6.788905e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>2.228615e-14</td>\n",
       "      <td>2.140732e-14</td>\n",
       "      <td>1.315166e-14</td>\n",
       "      <td>6.877844e-15</td>\n",
       "      <td>4.768374e-14</td>\n",
       "      <td>1.938838e-14</td>\n",
       "      <td>1.811988e-14</td>\n",
       "      <td>1.136598e-14</td>\n",
       "      <td>7.226051e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>2.559916e-14</td>\n",
       "      <td>1.978330e-14</td>\n",
       "      <td>1.356577e-14</td>\n",
       "      <td>1.849831e-14</td>\n",
       "      <td>3.620465e-14</td>\n",
       "      <td>7.651323e-15</td>\n",
       "      <td>3.237749e-15</td>\n",
       "      <td>2.715517e-15</td>\n",
       "      <td>1.022302e-14</td>\n",
       "      <td>4.872841e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1.211758e-13</td>\n",
       "      <td>1.606703e-14</td>\n",
       "      <td>1.314028e-14</td>\n",
       "      <td>1.032633e-13</td>\n",
       "      <td>2.567731e-13</td>\n",
       "      <td>1.072885e-13</td>\n",
       "      <td>1.426755e-14</td>\n",
       "      <td>1.400552e-14</td>\n",
       "      <td>8.970032e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>1.458781e-13</td>\n",
       "      <td>2.503292e-14</td>\n",
       "      <td>4.526505e-14</td>\n",
       "      <td>1.083655e-13</td>\n",
       "      <td>2.550462e-13</td>\n",
       "      <td>3.816348e-14</td>\n",
       "      <td>1.345544e-14</td>\n",
       "      <td>3.650378e-14</td>\n",
       "      <td>2.023944e-14</td>\n",
       "      <td>3.770532e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>3.712481e-14</td>\n",
       "      <td>3.241252e-14</td>\n",
       "      <td>8.490039e-15</td>\n",
       "      <td>4.338409e-14</td>\n",
       "      <td>6.377996e-14</td>\n",
       "      <td>3.139857e-14</td>\n",
       "      <td>2.687650e-14</td>\n",
       "      <td>7.697816e-15</td>\n",
       "      <td>3.692820e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>3.374581e-14</td>\n",
       "      <td>2.639347e-14</td>\n",
       "      <td>1.145955e-14</td>\n",
       "      <td>3.983994e-14</td>\n",
       "      <td>5.239449e-14</td>\n",
       "      <td>5.097662e-15</td>\n",
       "      <td>3.408258e-15</td>\n",
       "      <td>3.582388e-15</td>\n",
       "      <td>5.644987e-15</td>\n",
       "      <td>5.782184e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1.592916e-13</td>\n",
       "      <td>1.768986e-14</td>\n",
       "      <td>5.080786e-14</td>\n",
       "      <td>7.500625e-14</td>\n",
       "      <td>1.997301e-13</td>\n",
       "      <td>1.315357e-13</td>\n",
       "      <td>1.591519e-14</td>\n",
       "      <td>4.404552e-14</td>\n",
       "      <td>6.302553e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>1.241871e-13</td>\n",
       "      <td>2.300984e-14</td>\n",
       "      <td>5.183791e-14</td>\n",
       "      <td>6.445913e-14</td>\n",
       "      <td>1.683145e-13</td>\n",
       "      <td>1.352090e-14</td>\n",
       "      <td>5.996392e-15</td>\n",
       "      <td>8.519540e-15</td>\n",
       "      <td>8.598825e-15</td>\n",
       "      <td>2.412715e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1.893573e-13</td>\n",
       "      <td>3.252718e-14</td>\n",
       "      <td>7.611199e-15</td>\n",
       "      <td>1.012711e-13</td>\n",
       "      <td>3.200276e-13</td>\n",
       "      <td>1.563013e-13</td>\n",
       "      <td>2.693361e-14</td>\n",
       "      <td>6.278217e-15</td>\n",
       "      <td>8.356206e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>1.456420e-13</td>\n",
       "      <td>2.592706e-14</td>\n",
       "      <td>6.023603e-15</td>\n",
       "      <td>7.733374e-14</td>\n",
       "      <td>2.406660e-13</td>\n",
       "      <td>1.256924e-14</td>\n",
       "      <td>2.863227e-15</td>\n",
       "      <td>9.364237e-16</td>\n",
       "      <td>7.121557e-15</td>\n",
       "      <td>1.945333e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>4.037688e-14</td>\n",
       "      <td>4.262002e-15</td>\n",
       "      <td>6.191330e-15</td>\n",
       "      <td>6.391661e-14</td>\n",
       "      <td>5.381598e-14</td>\n",
       "      <td>3.711266e-14</td>\n",
       "      <td>4.239068e-15</td>\n",
       "      <td>5.626129e-15</td>\n",
       "      <td>5.780591e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>5.320501e-14</td>\n",
       "      <td>8.072603e-15</td>\n",
       "      <td>8.928871e-15</td>\n",
       "      <td>7.705714e-14</td>\n",
       "      <td>7.128975e-14</td>\n",
       "      <td>1.108381e-14</td>\n",
       "      <td>2.642184e-15</td>\n",
       "      <td>2.996516e-15</td>\n",
       "      <td>1.400257e-14</td>\n",
       "      <td>1.492517e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>2.341279e-14</td>\n",
       "      <td>5.310068e-14</td>\n",
       "      <td>6.353728e-15</td>\n",
       "      <td>1.195754e-14</td>\n",
       "      <td>6.802973e-14</td>\n",
       "      <td>2.090423e-14</td>\n",
       "      <td>4.516878e-14</td>\n",
       "      <td>5.576505e-15</td>\n",
       "      <td>1.084793e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>2.839523e-14</td>\n",
       "      <td>5.130694e-14</td>\n",
       "      <td>7.155748e-15</td>\n",
       "      <td>1.626497e-14</td>\n",
       "      <td>6.819299e-14</td>\n",
       "      <td>6.392987e-15</td>\n",
       "      <td>9.785830e-15</td>\n",
       "      <td>1.859367e-15</td>\n",
       "      <td>5.045506e-15</td>\n",
       "      <td>1.343801e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>2.205196e-14</td>\n",
       "      <td>2.766212e-14</td>\n",
       "      <td>4.922270e-15</td>\n",
       "      <td>1.362090e-14</td>\n",
       "      <td>5.702644e-14</td>\n",
       "      <td>1.957784e-14</td>\n",
       "      <td>2.346263e-14</td>\n",
       "      <td>5.091038e-15</td>\n",
       "      <td>1.249584e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>2.559716e-14</td>\n",
       "      <td>2.541609e-14</td>\n",
       "      <td>1.159670e-14</td>\n",
       "      <td>1.888751e-14</td>\n",
       "      <td>5.944653e-14</td>\n",
       "      <td>5.044842e-15</td>\n",
       "      <td>3.644006e-15</td>\n",
       "      <td>4.963080e-15</td>\n",
       "      <td>4.625879e-15</td>\n",
       "      <td>9.802016e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>6.905202e-14</td>\n",
       "      <td>9.166164e-14</td>\n",
       "      <td>9.201141e-15</td>\n",
       "      <td>4.960864e-14</td>\n",
       "      <td>4.041517e-14</td>\n",
       "      <td>5.829346e-14</td>\n",
       "      <td>7.606272e-14</td>\n",
       "      <td>8.102557e-15</td>\n",
       "      <td>4.454340e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>6.244617e-14</td>\n",
       "      <td>7.428467e-14</td>\n",
       "      <td>1.087499e-14</td>\n",
       "      <td>7.065450e-14</td>\n",
       "      <td>4.979390e-14</td>\n",
       "      <td>1.078828e-14</td>\n",
       "      <td>9.182213e-15</td>\n",
       "      <td>2.659088e-15</td>\n",
       "      <td>2.714434e-14</td>\n",
       "      <td>1.348443e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>7.212534e-14</td>\n",
       "      <td>4.558738e-14</td>\n",
       "      <td>2.122817e-14</td>\n",
       "      <td>2.606259e-14</td>\n",
       "      <td>1.188875e-13</td>\n",
       "      <td>6.264843e-14</td>\n",
       "      <td>3.859538e-14</td>\n",
       "      <td>1.775074e-14</td>\n",
       "      <td>2.223622e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>7.400918e-14</td>\n",
       "      <td>4.317707e-14</td>\n",
       "      <td>1.837445e-14</td>\n",
       "      <td>2.497976e-14</td>\n",
       "      <td>1.314389e-13</td>\n",
       "      <td>1.237740e-14</td>\n",
       "      <td>8.084057e-15</td>\n",
       "      <td>2.720802e-15</td>\n",
       "      <td>4.663649e-15</td>\n",
       "      <td>2.384377e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>2.082482e-13</td>\n",
       "      <td>5.068907e-14</td>\n",
       "      <td>1.957472e-14</td>\n",
       "      <td>1.312046e-13</td>\n",
       "      <td>4.248764e-13</td>\n",
       "      <td>1.792867e-13</td>\n",
       "      <td>4.415969e-14</td>\n",
       "      <td>1.742793e-14</td>\n",
       "      <td>1.157795e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>2.078644e-13</td>\n",
       "      <td>5.912378e-14</td>\n",
       "      <td>2.539884e-14</td>\n",
       "      <td>1.475337e-13</td>\n",
       "      <td>4.307946e-13</td>\n",
       "      <td>3.647616e-14</td>\n",
       "      <td>1.824295e-14</td>\n",
       "      <td>8.334698e-15</td>\n",
       "      <td>2.964882e-14</td>\n",
       "      <td>7.915771e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>3.654064e-13</td>\n",
       "      <td>2.143744e-13</td>\n",
       "      <td>3.538330e-14</td>\n",
       "      <td>2.673067e-13</td>\n",
       "      <td>5.509835e-13</td>\n",
       "      <td>3.075863e-13</td>\n",
       "      <td>1.849697e-13</td>\n",
       "      <td>3.115388e-14</td>\n",
       "      <td>2.231796e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>3.145388e-13</td>\n",
       "      <td>2.091797e-13</td>\n",
       "      <td>4.155479e-14</td>\n",
       "      <td>2.224599e-13</td>\n",
       "      <td>4.762536e-13</td>\n",
       "      <td>3.527473e-14</td>\n",
       "      <td>2.876296e-14</td>\n",
       "      <td>9.964063e-15</td>\n",
       "      <td>2.532626e-14</td>\n",
       "      <td>5.357598e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1.650454e-13</td>\n",
       "      <td>1.312687e-13</td>\n",
       "      <td>1.763186e-14</td>\n",
       "      <td>1.274048e-13</td>\n",
       "      <td>3.607287e-13</td>\n",
       "      <td>1.421226e-13</td>\n",
       "      <td>1.113833e-13</td>\n",
       "      <td>1.648450e-14</td>\n",
       "      <td>1.100530e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.681886e-13</td>\n",
       "      <td>1.253652e-13</td>\n",
       "      <td>3.042097e-14</td>\n",
       "      <td>1.361228e-13</td>\n",
       "      <td>3.716931e-13</td>\n",
       "      <td>3.341961e-14</td>\n",
       "      <td>2.374763e-14</td>\n",
       "      <td>1.468455e-14</td>\n",
       "      <td>3.173303e-14</td>\n",
       "      <td>7.311692e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>8.654516e-14</td>\n",
       "      <td>2.037732e-14</td>\n",
       "      <td>3.711558e-14</td>\n",
       "      <td>7.455531e-14</td>\n",
       "      <td>1.906334e-13</td>\n",
       "      <td>7.286026e-14</td>\n",
       "      <td>1.815671e-14</td>\n",
       "      <td>3.249696e-14</td>\n",
       "      <td>6.380052e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>7.687037e-14</td>\n",
       "      <td>2.429696e-14</td>\n",
       "      <td>4.099077e-14</td>\n",
       "      <td>7.001252e-14</td>\n",
       "      <td>1.655236e-13</td>\n",
       "      <td>1.191020e-14</td>\n",
       "      <td>5.199770e-15</td>\n",
       "      <td>8.621988e-15</td>\n",
       "      <td>9.258675e-15</td>\n",
       "      <td>2.209204e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>1.271909e-13</td>\n",
       "      <td>3.904124e-14</td>\n",
       "      <td>1.721178e-14</td>\n",
       "      <td>1.479596e-13</td>\n",
       "      <td>2.243237e-13</td>\n",
       "      <td>1.106120e-13</td>\n",
       "      <td>3.451544e-14</td>\n",
       "      <td>1.549345e-14</td>\n",
       "      <td>1.258981e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333884e-13</td>\n",
       "      <td>4.874214e-14</td>\n",
       "      <td>2.302207e-14</td>\n",
       "      <td>1.393210e-13</td>\n",
       "      <td>2.488761e-13</td>\n",
       "      <td>2.674621e-14</td>\n",
       "      <td>1.426631e-14</td>\n",
       "      <td>8.447624e-15</td>\n",
       "      <td>2.492894e-14</td>\n",
       "      <td>5.890823e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>5.851748e-14</td>\n",
       "      <td>5.257739e-14</td>\n",
       "      <td>2.866950e-15</td>\n",
       "      <td>1.178461e-14</td>\n",
       "      <td>1.077687e-13</td>\n",
       "      <td>4.862742e-14</td>\n",
       "      <td>4.340971e-14</td>\n",
       "      <td>2.624049e-15</td>\n",
       "      <td>1.047399e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>4.667173e-14</td>\n",
       "      <td>4.140589e-14</td>\n",
       "      <td>4.203343e-15</td>\n",
       "      <td>1.353463e-14</td>\n",
       "      <td>9.205260e-14</td>\n",
       "      <td>4.907180e-15</td>\n",
       "      <td>4.395539e-15</td>\n",
       "      <td>1.444900e-15</td>\n",
       "      <td>2.797905e-15</td>\n",
       "      <td>1.043625e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1.353136e-13</td>\n",
       "      <td>1.780719e-14</td>\n",
       "      <td>3.915330e-14</td>\n",
       "      <td>1.204111e-13</td>\n",
       "      <td>2.155822e-13</td>\n",
       "      <td>1.176597e-13</td>\n",
       "      <td>1.513101e-14</td>\n",
       "      <td>3.364020e-14</td>\n",
       "      <td>1.043147e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.519543e-13</td>\n",
       "      <td>1.650222e-14</td>\n",
       "      <td>4.050628e-14</td>\n",
       "      <td>1.303234e-13</td>\n",
       "      <td>2.304940e-13</td>\n",
       "      <td>3.918815e-14</td>\n",
       "      <td>2.600984e-15</td>\n",
       "      <td>9.207104e-15</td>\n",
       "      <td>3.095929e-14</td>\n",
       "      <td>5.415520e-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0             1             2             3             4             5   \\\n",
       "0    0  9.062235e-14  4.130522e-14  3.495434e-14  1.295076e-13  1.901673e-13   \n",
       "1    0  1.913017e-13  6.042521e-15  1.872660e-14  2.221667e-13  3.210776e-13   \n",
       "2    0  1.017000e-13  8.795132e-14  1.394948e-14  1.845844e-13  2.366540e-13   \n",
       "3    1  2.883162e-13  1.718212e-14  8.996052e-14  3.496524e-13  6.856537e-13   \n",
       "4    1  1.449475e-13  1.555291e-13  5.523409e-14  1.438152e-13  3.171872e-13   \n",
       "5    1  1.029596e-13  4.820368e-14  7.050277e-14  5.328622e-14  1.709448e-13   \n",
       "6    1  1.260067e-13  1.503067e-14  3.029189e-13  4.896017e-13  3.926549e-13   \n",
       "7    0  4.112735e-14  2.851334e-14  3.304322e-14  3.117144e-14  2.337348e-13   \n",
       "8    0  4.006348e-14  3.367356e-14  3.503045e-14  4.765621e-14  1.085760e-13   \n",
       "9    0  4.119818e-14  6.748188e-14  5.702418e-14  6.871250e-14  1.291316e-13   \n",
       "10   1  1.312647e-13  7.477556e-14  2.072499e-14  1.226857e-13  3.144261e-13   \n",
       "11   1  1.477169e-13  9.006077e-15  6.261339e-15  1.272914e-13  1.327922e-13   \n",
       "12   1  3.999037e-14  3.998425e-14  1.026865e-13  9.943638e-14  3.374541e-13   \n",
       "13   0  3.872944e-14  1.048018e-14  1.069865e-14  4.271296e-14  1.153013e-13   \n",
       "14   1  2.025260e-13  1.205531e-13  1.743924e-14  7.843901e-14  3.157967e-13   \n",
       "15   0  2.228615e-14  2.140732e-14  1.315166e-14  6.877844e-15  4.768374e-14   \n",
       "16   1  1.211758e-13  1.606703e-14  1.314028e-14  1.032633e-13  2.567731e-13   \n",
       "17   1  3.712481e-14  3.241252e-14  8.490039e-15  4.338409e-14  6.377996e-14   \n",
       "18   1  1.592916e-13  1.768986e-14  5.080786e-14  7.500625e-14  1.997301e-13   \n",
       "19   1  1.893573e-13  3.252718e-14  7.611199e-15  1.012711e-13  3.200276e-13   \n",
       "20   1  4.037688e-14  4.262002e-15  6.191330e-15  6.391661e-14  5.381598e-14   \n",
       "21   0  2.341279e-14  5.310068e-14  6.353728e-15  1.195754e-14  6.802973e-14   \n",
       "22   0  2.205196e-14  2.766212e-14  4.922270e-15  1.362090e-14  5.702644e-14   \n",
       "23   0  6.905202e-14  9.166164e-14  9.201141e-15  4.960864e-14  4.041517e-14   \n",
       "24   1  7.212534e-14  4.558738e-14  2.122817e-14  2.606259e-14  1.188875e-13   \n",
       "25   1  2.082482e-13  5.068907e-14  1.957472e-14  1.312046e-13  4.248764e-13   \n",
       "26   1  3.654064e-13  2.143744e-13  3.538330e-14  2.673067e-13  5.509835e-13   \n",
       "27   0  1.650454e-13  1.312687e-13  1.763186e-14  1.274048e-13  3.607287e-13   \n",
       "28   1  8.654516e-14  2.037732e-14  3.711558e-14  7.455531e-14  1.906334e-13   \n",
       "29   1  1.271909e-13  3.904124e-14  1.721178e-14  1.479596e-13  2.243237e-13   \n",
       "30   0  5.851748e-14  5.257739e-14  2.866950e-15  1.178461e-14  1.077687e-13   \n",
       "31   1  1.353136e-13  1.780719e-14  3.915330e-14  1.204111e-13  2.155822e-13   \n",
       "\n",
       "              6             7             8             9       ...       \\\n",
       "0   8.048468e-14  3.531210e-14  3.196135e-14  1.143896e-13      ...        \n",
       "1   1.581491e-13  5.663927e-15  1.833481e-14  1.842429e-13      ...        \n",
       "2   9.215951e-14  7.936271e-14  1.636610e-14  1.655971e-13      ...        \n",
       "3   2.404430e-13  1.522790e-14  7.388476e-14  2.925383e-13      ...        \n",
       "4   1.239206e-13  1.310694e-13  5.341977e-14  1.254590e-13      ...        \n",
       "5   8.501017e-14  4.034812e-14  5.793891e-14  4.481823e-14      ...        \n",
       "6   1.075261e-13  1.304163e-14  2.625853e-13  4.115503e-13      ...        \n",
       "7   3.667084e-14  2.434718e-14  2.952262e-14  2.978675e-14      ...        \n",
       "8   3.847278e-14  3.053790e-14  3.111129e-14  4.504753e-14      ...        \n",
       "9   3.736217e-14  5.632346e-14  4.901976e-14  6.198453e-14      ...        \n",
       "10  1.148339e-13  7.298705e-14  2.137020e-14  1.061915e-13      ...        \n",
       "11  1.252132e-13  8.181049e-15  5.914774e-15  1.075611e-13      ...        \n",
       "12  3.537716e-14  3.461581e-14  8.737639e-14  8.558423e-14      ...        \n",
       "13  3.631187e-14  9.512314e-15  9.429760e-15  3.932135e-14      ...        \n",
       "14  1.744051e-13  1.010062e-13  1.643959e-14  6.951262e-14      ...        \n",
       "15  1.938838e-14  1.811988e-14  1.136598e-14  7.226051e-15      ...        \n",
       "16  1.072885e-13  1.426755e-14  1.400552e-14  8.970032e-14      ...        \n",
       "17  3.139857e-14  2.687650e-14  7.697816e-15  3.692820e-14      ...        \n",
       "18  1.315357e-13  1.591519e-14  4.404552e-14  6.302553e-14      ...        \n",
       "19  1.563013e-13  2.693361e-14  6.278217e-15  8.356206e-14      ...        \n",
       "20  3.711266e-14  4.239068e-15  5.626129e-15  5.780591e-14      ...        \n",
       "21  2.090423e-14  4.516878e-14  5.576505e-15  1.084793e-14      ...        \n",
       "22  1.957784e-14  2.346263e-14  5.091038e-15  1.249584e-14      ...        \n",
       "23  5.829346e-14  7.606272e-14  8.102557e-15  4.454340e-14      ...        \n",
       "24  6.264843e-14  3.859538e-14  1.775074e-14  2.223622e-14      ...        \n",
       "25  1.792867e-13  4.415969e-14  1.742793e-14  1.157795e-13      ...        \n",
       "26  3.075863e-13  1.849697e-13  3.115388e-14  2.231796e-13      ...        \n",
       "27  1.421226e-13  1.113833e-13  1.648450e-14  1.100530e-13      ...        \n",
       "28  7.286026e-14  1.815671e-14  3.249696e-14  6.380052e-14      ...        \n",
       "29  1.106120e-13  3.451544e-14  1.549345e-14  1.258981e-13      ...        \n",
       "30  4.862742e-14  4.340971e-14  2.624049e-15  1.047399e-14      ...        \n",
       "31  1.176597e-13  1.513101e-14  3.364020e-14  1.043147e-13      ...        \n",
       "\n",
       "              11            12            13            14            15  \\\n",
       "0   1.067692e-13  4.193570e-14  4.586276e-14  1.455026e-13  2.143150e-13   \n",
       "1   1.524585e-13  1.104273e-14  3.634665e-14  1.814725e-13  2.693697e-13   \n",
       "2   1.307338e-13  1.173222e-13  5.320181e-14  2.317469e-13  2.941198e-13   \n",
       "3   2.370522e-13  2.045834e-14  6.823475e-14  2.931582e-13  5.419109e-13   \n",
       "4   1.356595e-13  1.428580e-13  1.040858e-13  1.544794e-13  3.228246e-13   \n",
       "5   7.926026e-14  4.188637e-14  5.223299e-14  4.616245e-14  1.454461e-13   \n",
       "6   1.174973e-13  1.544006e-14  3.063713e-13  4.191675e-13  3.273886e-13   \n",
       "7   5.151590e-14  2.857869e-14  4.138833e-14  5.273701e-14  2.241908e-13   \n",
       "8   6.872467e-14  4.744840e-14  4.977599e-14  7.818609e-14  1.640759e-13   \n",
       "9   5.128360e-14  6.176596e-14  5.597567e-14  8.468713e-14  1.560156e-13   \n",
       "10  1.447837e-13  1.383818e-13  4.838253e-14  1.271844e-13  3.939809e-13   \n",
       "11  1.332400e-13  1.356149e-14  9.565100e-15  1.127287e-13  1.219308e-13   \n",
       "12  4.570524e-14  4.240168e-14  9.749379e-14  1.005637e-13  2.951104e-13   \n",
       "13  5.978893e-14  1.433449e-14  1.177428e-14  5.706191e-14  1.219382e-13   \n",
       "14  2.173745e-13  1.195586e-13  3.226330e-14  9.708568e-14  3.399544e-13   \n",
       "15  2.559916e-14  1.978330e-14  1.356577e-14  1.849831e-14  3.620465e-14   \n",
       "16  1.458781e-13  2.503292e-14  4.526505e-14  1.083655e-13  2.550462e-13   \n",
       "17  3.374581e-14  2.639347e-14  1.145955e-14  3.983994e-14  5.239449e-14   \n",
       "18  1.241871e-13  2.300984e-14  5.183791e-14  6.445913e-14  1.683145e-13   \n",
       "19  1.456420e-13  2.592706e-14  6.023603e-15  7.733374e-14  2.406660e-13   \n",
       "20  5.320501e-14  8.072603e-15  8.928871e-15  7.705714e-14  7.128975e-14   \n",
       "21  2.839523e-14  5.130694e-14  7.155748e-15  1.626497e-14  6.819299e-14   \n",
       "22  2.559716e-14  2.541609e-14  1.159670e-14  1.888751e-14  5.944653e-14   \n",
       "23  6.244617e-14  7.428467e-14  1.087499e-14  7.065450e-14  4.979390e-14   \n",
       "24  7.400918e-14  4.317707e-14  1.837445e-14  2.497976e-14  1.314389e-13   \n",
       "25  2.078644e-13  5.912378e-14  2.539884e-14  1.475337e-13  4.307946e-13   \n",
       "26  3.145388e-13  2.091797e-13  4.155479e-14  2.224599e-13  4.762536e-13   \n",
       "27  1.681886e-13  1.253652e-13  3.042097e-14  1.361228e-13  3.716931e-13   \n",
       "28  7.687037e-14  2.429696e-14  4.099077e-14  7.001252e-14  1.655236e-13   \n",
       "29  1.333884e-13  4.874214e-14  2.302207e-14  1.393210e-13  2.488761e-13   \n",
       "30  4.667173e-14  4.140589e-14  4.203343e-15  1.353463e-14  9.205260e-14   \n",
       "31  1.519543e-13  1.650222e-14  4.050628e-14  1.303234e-13  2.304940e-13   \n",
       "\n",
       "              16            17            18            19            20  \n",
       "0   2.462601e-14  1.010044e-14  9.922016e-15  2.935956e-14  4.736799e-14  \n",
       "1   1.737748e-14  5.566461e-15  1.397429e-14  2.295641e-14  3.469796e-14  \n",
       "2   3.078723e-14  3.158777e-14  3.005926e-14  5.825906e-14  6.276757e-14  \n",
       "3   2.694255e-14  4.983685e-15  6.765318e-15  3.386905e-14  4.923570e-14  \n",
       "4   1.949444e-14  2.611271e-14  4.226952e-14  3.290497e-14  8.106339e-14  \n",
       "5   6.768807e-15  6.303458e-15  4.221057e-15  5.898320e-15  1.570370e-14  \n",
       "6   1.730275e-14  2.694448e-15  4.897646e-14  4.883845e-14  3.733034e-14  \n",
       "7   1.490220e-14  7.121807e-15  1.077298e-14  1.815318e-14  3.724769e-14  \n",
       "8   2.267830e-14  1.462856e-14  2.287678e-14  2.678258e-14  4.637800e-14  \n",
       "9   1.081420e-14  1.441466e-14  8.338221e-15  1.975151e-14  3.277283e-14  \n",
       "10  2.888245e-14  4.613706e-14  1.992346e-14  2.257416e-14  8.719823e-14  \n",
       "11  1.855093e-14  5.558167e-15  2.478933e-15  1.622432e-14  1.848264e-14  \n",
       "12  8.891083e-15  8.603102e-15  1.574273e-14  2.185782e-14  3.612818e-14  \n",
       "13  1.925680e-14  4.281601e-15  2.084140e-15  1.224343e-14  1.811147e-14  \n",
       "14  6.305806e-14  3.626033e-14  1.591026e-14  2.593712e-14  6.788905e-14  \n",
       "15  7.651323e-15  3.237749e-15  2.715517e-15  1.022302e-14  4.872841e-15  \n",
       "16  3.816348e-14  1.345544e-14  3.650378e-14  2.023944e-14  3.770532e-14  \n",
       "17  5.097662e-15  3.408258e-15  3.582388e-15  5.644987e-15  5.782184e-15  \n",
       "18  1.352090e-14  5.996392e-15  8.519540e-15  8.598825e-15  2.412715e-14  \n",
       "19  1.256924e-14  2.863227e-15  9.364237e-16  7.121557e-15  1.945333e-14  \n",
       "20  1.108381e-14  2.642184e-15  2.996516e-15  1.400257e-14  1.492517e-14  \n",
       "21  6.392987e-15  9.785830e-15  1.859367e-15  5.045506e-15  1.343801e-14  \n",
       "22  5.044842e-15  3.644006e-15  4.963080e-15  4.625879e-15  9.802016e-15  \n",
       "23  1.078828e-14  9.182213e-15  2.659088e-15  2.714434e-14  1.348443e-14  \n",
       "24  1.237740e-14  8.084057e-15  2.720802e-15  4.663649e-15  2.384377e-14  \n",
       "25  3.647616e-14  1.824295e-14  8.334698e-15  2.964882e-14  7.915771e-14  \n",
       "26  3.527473e-14  2.876296e-14  9.964063e-15  2.532626e-14  5.357598e-14  \n",
       "27  3.341961e-14  2.374763e-14  1.468455e-14  3.173303e-14  7.311692e-14  \n",
       "28  1.191020e-14  5.199770e-15  8.621988e-15  9.258675e-15  2.209204e-14  \n",
       "29  2.674621e-14  1.426631e-14  8.447624e-15  2.492894e-14  5.890823e-14  \n",
       "30  4.907180e-15  4.395539e-15  1.444900e-15  2.797905e-15  1.043625e-14  \n",
       "31  3.918815e-14  2.600984e-15  9.207104e-15  3.095929e-14  5.415520e-14  \n",
       "\n",
       "[32 rows x 21 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path='/home/sultan/EEG/CLUSTER_channels/S_E12/clearbandfeatures.xlsx'\n",
    "dataset=pd.read_excel(path,header=None)\n",
    "#dataset =pd.read_csv(path) # This is the csv read\n",
    "print(\"Total rows: {0}\".format(len(dataset)))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gamma = np.logspace(-5, 4, 10)\n",
    "# print gamma\n",
    "# C = np.logspace(-2, 3, 10)\n",
    "# #C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leaveout on Whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score for Theta is 67.74\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.62      0.59        13\n",
      "          1       0.72      0.68      0.70        19\n",
      "\n",
      "avg / total       0.66      0.66      0.66        32\n",
      "\n",
      "ROC_AUC: Theta is 0.65\n",
      "\n",
      "\n",
      "Total score for alpha is 74.19\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.69      0.67        13\n",
      "          1       0.78      0.74      0.76        19\n",
      "\n",
      "avg / total       0.72      0.72      0.72        32\n",
      "\n",
      "ROC_AUC: alpha is 0.71\n",
      "\n",
      "\n",
      "Total score for beta is 67.74\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.54      0.56        13\n",
      "          1       0.70      0.74      0.72        19\n",
      "\n",
      "avg / total       0.65      0.66      0.65        32\n",
      "\n",
      "ROC_AUC: beta is 0.64\n",
      "\n",
      "\n",
      "Total score for gamma is 58.06\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       0.58      0.95      0.72        19\n",
      "\n",
      "avg / total       0.34      0.56      0.43        32\n",
      "\n",
      "ROC_AUC: gamma is 0.47\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "leaveout = LeaveOneOut()\n",
    "#leaveout.get_n_splits(X)\n",
    "#parameters = {'kernel':('linear', 'rbf','poly','sigmoid'), 'C':[1, 10,100,1000],'gamma':[0.01,.002, 0.003]}\n",
    "parameters = {'kernel':['rbf'], 'C':[1, 10,100,1000],'gamma':[0.01,.002, 0.003]}\n",
    "#parameters = {'kernel':('linear', 'rbf','poly','sigmoid'), 'C':np.logspace(-2, 3, 10),'gamma':np.logspace(-5, 4, 10)}\n",
    "svc = svm.SVC()\n",
    "### Here is the leaveout\n",
    "cn=0\n",
    "pos=[1,6,11,16]; # This is the cluster number lhpos=[3,8,13,19],j=i+2 rhpos=[1,6,11,16], j=i+2\n",
    "a=['Theta',\"alpha\",'beta', 'gamma']\n",
    "for i in pos:\n",
    "    j=i+5\n",
    "    X=dataset.iloc[:,i:j].values;# theta:1-6, alpha=6-11, beta=11-16: gamma=16-21 # 1-3 RH, 3-5 LH\n",
    "    #print X\n",
    "    X_scaled = preprocessing.scale(X)\n",
    "    y=dataset.iloc[:,0].values\n",
    "    count = 0\n",
    "    totalacc = 0\n",
    "    cper=[];ytt=[];\n",
    "    for train_index, test_index in leaveout.split(X_scaled):\n",
    "        #print train_index,test_index\n",
    "        ##X_trn, X_tst = X[train_index], X[test_index]\n",
    "        X_trn, X_tst = X_scaled[train_index], X_scaled[test_index]\n",
    "        y_trn, y_tst = y[train_index], y[test_index]\n",
    "        clf = GridSearchCV(svc, parameters)\n",
    "        #print X_trn, y_trn\n",
    "        clf.fit(X_trn, y_trn)\n",
    "        #print clf.best_estimator_\n",
    "        acc = accuracy_score(clf.best_estimator_.predict(X_tst),y_tst)\n",
    "        totalacc = totalacc + acc\n",
    "        pred=clf.best_estimator_.predict(X_tst)\n",
    "        cper.append(pred)\n",
    "        ytt.append(y_tst)\n",
    "        #print count, y_tst, acc\n",
    "        count = count + 1\n",
    "        #print count, acc, totalacc; # See the how many correct over the whole\n",
    "    score=totalacc/(count-1)*100.0\n",
    "    #print 'Accuracy of',a[cn],'=', totalacc/count \n",
    "    #print(\"Total score for %s is %2.2f.\"%(a[cn], score));# see 2 digit results \n",
    "    print(\"Total score for {} is {}\".format(a[cn], round(score,2)))\n",
    "    print (classification_report(np.array(ytt), np.array(cper)))\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(np.array(ytt),np.array(cper))\n",
    "    roc_acu=roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    print(\"ROC_AUC: {} is {}\".format(a[cn], round(roc_acu,2)))\n",
    "    print '\\n'\n",
    "    cn+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different kernel\n",
    "# Total score for Theta is 67.74\n",
    "# Total score for alpha is 70.97\n",
    "# Total score for beta is 64.52\n",
    "# Total score for gamma is 58.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Total score for Theta is 65.625\n",
    "# Total score for alpha is 68.75\n",
    "# Total score for beta is 62.5\n",
    "# Total score for gamma is 56.25\n",
    "##parameters = {'kernel':('linear', 'rbf','poly','sigmoid'), 'C':[1, 10,100,1000],'gamma':[0.01,.002, 0.003]}\n",
    "# Total score for Theta is 67.74\n",
    "# Total score for alpha is 70.97\n",
    "# Total score for beta is 54.84\n",
    "# Total score for gamma is 48.39"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score for Theta is 61.29\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.23      0.32        13\n",
      "          1       0.62      0.84      0.71        19\n",
      "\n",
      "avg / total       0.57      0.59      0.55        32\n",
      "\n",
      "ROC_AUC Theta is 0.54\n",
      "\n",
      "\n",
      "Total score for alpha is 54.84\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.25      0.08      0.12        13\n",
      "          1       0.57      0.84      0.68        19\n",
      "\n",
      "avg / total       0.44      0.53      0.45        32\n",
      "\n",
      "ROC_AUC alpha is 0.46\n",
      "\n",
      "\n",
      "Total score for beta is 54.84\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       0.57      0.89      0.69        19\n",
      "\n",
      "avg / total       0.34      0.53      0.41        32\n",
      "\n",
      "ROC_AUC beta is 0.45\n",
      "\n",
      "\n",
      "Total score for gamma is 61.29\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       0.59      1.00      0.75        19\n",
      "\n",
      "avg / total       0.35      0.59      0.44        32\n",
      "\n",
      "ROC_AUC gamma is 0.5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# X=dataset.iloc[:,16:21].values;# theta:1-6, alpha=6-11, beta=11-16: gamma=16-21 \n",
    "# X_scaled = preprocessing.scale(X); # normalizing 0 mean and 1 stdv\n",
    "# y=dataset.iloc[:,0].values\n",
    "leaveout = LeaveOneOut()\n",
    "#leaveout.get_n_splits(X)\n",
    "#parameters = {'kernel':('linear', 'rbf','poly','sigmoid'), 'C':[1, 10,100,1000],'gamma':[0.01,.002,0.003]}\n",
    "parameters = {'kernel':['rbf'], 'C':[1, 10,100,1000],'gamma':[0.01,.002, 0.003]}\n",
    "#parameters = {'kernel':('linear', 'rbf','poly','sigmoid'), 'C':np.logspace(-2, 3, 10),'gamma':np.logspace(-5, 4, 10)}\n",
    "svc = svm.SVC()\n",
    "### Here is the leaveout\n",
    "cn=0\n",
    "pos=[3,8,13,18]; # This is the cluster number lhpos=[3,8,13,18],j=i+2 rhpos=[1,6,11,16], j=i+2\n",
    "a=['Theta',\"alpha\",'beta', 'gamma']\n",
    "for i in pos:\n",
    "    j=i+2\n",
    "    X=dataset.iloc[:,i:j].values;# theta:1-6, alpha=6-11, beta=11-16: gamma=16-21 # 1-3 RH, 3-5 LH\n",
    "    #print X\n",
    "    X_scaled = preprocessing.scale(X)\n",
    "    y=dataset.iloc[:,0].values\n",
    "    count = 0\n",
    "    totalacc = 0\n",
    "    cper=[];ytt=[];\n",
    "    for train_index, test_index in leaveout.split(X_scaled):\n",
    "        #print train_index,test_index\n",
    "        X_trn, X_tst = X_scaled[train_index], X_scaled[test_index]\n",
    "        y_trn, y_tst = y[train_index], y[test_index]\n",
    "        clf = GridSearchCV(svc, parameters)\n",
    "        clf.fit(X_trn, y_trn)\n",
    "        #print clf.best_estimator_\n",
    "        #pred=clf.best_estimator_.predict(X_tst)\n",
    "        acc = accuracy_score(clf.best_estimator_.predict(X_tst),y_tst)\n",
    "        totalacc = totalacc + acc\n",
    "        pred=clf.best_estimator_.predict(X_tst)\n",
    "        cper.append(pred)\n",
    "        ytt.append(y_tst)\n",
    "        count = count + 1 \n",
    "        #print totalacc, y_tst, pred,acc\n",
    "        #print count, acc, totalacc; # See the how many correct over the whole\n",
    "    score=totalacc/(count-1.0)*100.0\n",
    "    #print 'Accuracy of',a[cn],'=', totalacc/count\n",
    "    print(\"Total score for {} is {}\".format(a[cn], round(score,2)))\n",
    "    print (classification_report(np.array(ytt), np.array(cper)))\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(np.array(ytt),np.array(cper))\n",
    "    roc_acu=roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    print(\"ROC_AUC: {} is {}\".format(a[cn], round(roc_acu,2)))\n",
    "    print '\\n'\n",
    "    cn+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Total score for Theta is 59.375\n",
    "# Total score for alpha is 53.125\n",
    "# Total score for beta is 53.125\n",
    "# Total score for gamma is 59.375"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score for Theta is 74.19\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.69      0.67        13\n",
      "          1       0.78      0.74      0.76        19\n",
      "\n",
      "avg / total       0.72      0.72      0.72        32\n",
      "\n",
      "ROC_AUC: Theta is 0.71\n",
      "\n",
      "\n",
      "Total score for alpha is 74.19\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.69      0.67        13\n",
      "          1       0.78      0.74      0.76        19\n",
      "\n",
      "avg / total       0.72      0.72      0.72        32\n",
      "\n",
      "ROC_AUC: alpha is 0.71\n",
      "\n",
      "\n",
      "Total score for beta is 61.29\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.62      0.55        13\n",
      "          1       0.69      0.58      0.63        19\n",
      "\n",
      "avg / total       0.61      0.59      0.60        32\n",
      "\n",
      "ROC_AUC: beta is 0.6\n",
      "\n",
      "\n",
      "Total score for gamma is 61.29\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        13\n",
      "          1       0.59      1.00      0.75        19\n",
      "\n",
      "avg / total       0.35      0.59      0.44        32\n",
      "\n",
      "ROC_AUC: gamma is 0.5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "leaveout = LeaveOneOut()\n",
    "#leaveout.get_n_splits(X)\n",
    "parameters = {'kernel':['rbf'], 'C':[1, 10,100,1000],'gamma':[0.01,.002, 0.003]}\n",
    "#parameters = {'kernel':('linear', 'rbf','poly','sigmoid'), 'C':[1, 10,100,1000],'gamma':[0.01,.002,0.003]}\n",
    "##parameters = {'kernel':('linear', 'rbf','poly','sigmoid'), 'C':[1, 10,100,1000],'gamma': (0.1,2,10)}\n",
    "svc = svm.SVC()\n",
    "#### Here is the leaveout\n",
    "cn=0\n",
    "pos=[1,6,11,16]; # This is the cluster number lhpos=[3,8,13,18],j=i+2 rhpos=[1,6,11,16], j=i+2\n",
    "a=['Theta',\"alpha\",'beta', 'gamma']\n",
    "for i in pos:\n",
    "    j=i+2\n",
    "    X=dataset.iloc[:,i:j].values;# theta:1-6, alpha=6-11, beta=11-16: gamma=16-21 # 1-3 RH, 3-5 LH\n",
    "    X_scaled = preprocessing.scale(X)\n",
    "    y=dataset.iloc[:,0].values\n",
    "    count = 0;\n",
    "    totalacc = 0;\n",
    "    cper=[];ytt=[];\n",
    "    svc = svm.SVC()\n",
    "    #parameters = {'kernel':('linear', 'rbf','poly','sigmoid'), 'C':np.logspace(-2, 3, 10),'gamma':np.logspace(-5, 4, 10)}\n",
    "    for train_index, test_index in leaveout.split(X_scaled):\n",
    "        #print train_index,test_index\n",
    "        X_trn, X_tst = X_scaled[train_index], X_scaled[test_index]\n",
    "        y_trn, y_tst = y[train_index], y[test_index]\n",
    "        clf = GridSearchCV(svc, parameters)\n",
    "        clf.fit(X_trn, y_trn)\n",
    "        #print clf.best_estimator_\n",
    "        acc = accuracy_score(clf.best_estimator_.predict(X_tst),y_tst)\n",
    "        totalacc = totalacc + acc\n",
    "        pred=clf.best_estimator_.predict(X_tst)\n",
    "        cper.append(pred)\n",
    "        ytt.append(y_tst)\n",
    "        count = count + 1 \n",
    "        #print count, acc, totalacc; # See the how many correct over the whole\n",
    "    score=totalacc/(count-1)*100.0\n",
    "    #print 'Accuracy of',a[cn],'=', totalacc/count\n",
    "    print(\"Total score for {} is {}\".format(a[cn], round(score,2)))\n",
    "    print (classification_report(np.array(ytt), np.array(cper)))\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(np.array(ytt),np.array(cper))\n",
    "    roc_acu=roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    print(\"ROC_AUC: {} is {}\".format(a[cn], round(roc_acu,2)))\n",
    "    print '\\n'\n",
    "    cn+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "##parameters = {'kernel':('linear', 'rbf','poly','sigmoid'), 'C':[1, 10,100,1000],'gamma':[0.01,.002,0.003]}\n",
    "# Total score for Theta is 74.19\n",
    "# Total score for alpha is 74.19\n",
    "# Total score for beta is 67.74\n",
    "# Total score for gamma is 61.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working for F score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score for Theta is 67.74\n",
      "Total score for alpha is 70.97\n",
      "Total score for beta is 64.52\n",
      "Total score for gamma is 58.06\n"
     ]
    }
   ],
   "source": [
    "leaveout = LeaveOneOut()\n",
    "#leaveout.get_n_splits(X)\n",
    "parameters = {'kernel':('linear', 'rbf','poly','sigmoid'), 'C':[1, 10,100,1000],'gamma':[0.01,.002, 0.003]}\n",
    "#parameters = {'kernel':('linear', 'rbf','poly','sigmoid'), 'C':np.logspace(-2, 3, 10),'gamma':np.logspace(-5, 4, 10)}\n",
    "svc = svm.SVC()\n",
    "### Here is the leaveout\n",
    "cn=0\n",
    "pos=[1,6,11,16]; # This is the cluster number lhpos=[3,8,13,19],j=i+2 rhpos=[1,6,11,16], j=i+2\n",
    "a=['Theta',\"alpha\",'beta', 'gamma']\n",
    "for i in pos:\n",
    "    j=i+5\n",
    "    X=dataset.iloc[:,i:j].values;# theta:1-6, alpha=6-11, beta=11-16: gamma=16-21 # 1-3 RH, 3-5 LH\n",
    "    #print X\n",
    "    X_scaled = preprocessing.scale(X)\n",
    "    y=dataset.iloc[:,0].values\n",
    "    count = 0\n",
    "    totalacc = 0\n",
    "    cper=[];ytt=[];\n",
    "    for train_index, test_index in leaveout.split(X_scaled):\n",
    "        #print train_index,test_index\n",
    "        ##X_trn, X_tst = X[train_index], X[test_index]\n",
    "        X_trn, X_tst = X_scaled[train_index], X_scaled[test_index]\n",
    "        y_trn, y_tst = y[train_index], y[test_index]\n",
    "        clf = GridSearchCV(svc, parameters)\n",
    "        #print X_trn, y_trn\n",
    "        clf.fit(X_trn, y_trn)\n",
    "        #print clf.best_estimator_\n",
    "        acc = accuracy_score(clf.best_estimator_.predict(X_tst),y_tst)\n",
    "        totalacc = totalacc + acc\n",
    "        pred=clf.best_estimator_.predict(X_tst)\n",
    "        cper.append(pred)\n",
    "        ytt.append(y_tst)\n",
    "        #print count, y_tst, acc\n",
    "        count = count + 1\n",
    "        #print count, acc, totalacc; # See the how many correct over the whole\n",
    "    score=totalacc/(count-1)*100.0\n",
    "    #print 'Accuracy of',a[cn],'=', totalacc/count \n",
    "    #print(\"Total score for %s is %2.2f.\"%(a[cn], score));# see 2 digit results \n",
    "    print(\"Total score for {} is {}\".format(a[cn], round(score,2)))\n",
    "    #print (accuracy_score(np.array(ytt), np.array(cper))*100.0)\n",
    "    #print (classification_report(np.array(ytt), np.array(cper)))\n",
    "    #print('Acc: {}'.format(totalacc/count) \n",
    "    cn+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whole brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n",
      "Total score for Theta is 50.0\n",
      "50.0\n",
      "Total score for alpha is 50.0\n",
      "43.75\n",
      "Total score for beta is 43.75\n",
      "59.375\n",
      "Total score for gamma is 59.38\n"
     ]
    }
   ],
   "source": [
    "cn=0\n",
    "pos=[1,6,11,16]; # This is the cluster number lhpos=[3,8,13,19],j=i+2 rhpos=[1,6,11,16], j=i+2\n",
    "a=['Theta',\"alpha\",'beta', 'gamma']\n",
    "for i in pos:\n",
    "    j=i+5\n",
    "    X=dataset.iloc[:,i:j].values;# theta:1-6, alpha=6-11, beta=11-16: gamma=16-21 # 1-3 RH, 3-5 LH\n",
    "    #print X\n",
    "    X_scaled = preprocessing.scale(X)\n",
    "    y=dataset.iloc[:,0].values\n",
    "    count = 0\n",
    "    totalacc = 0\n",
    "    cper=[];ytt=[];\n",
    "    kmeans = KMeans(n_clusters = 2, init = 'k-means++', random_state = 42)\n",
    "    y_kmeans = kmeans.fit_predict(X_scaled)\n",
    "    y_kmeans\n",
    "    y_kmeans=np.where(y_kmeans==0,1,0);\n",
    "    df1=pd.DataFrame({'True_label':y,'predic_label':y_kmeans})\n",
    "#     print df1\n",
    "    score=accuracy_score(y_kmeans, y)*100.0\n",
    "    print (score)\n",
    "    print(\"Total score for {} is {}\".format(a[cn], round(score,2)))\n",
    "    #print (classification_report(y_kmeans, y))\n",
    "    cn+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=dataset.iloc[:,1:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.625\n"
     ]
    }
   ],
   "source": [
    "X_scaled = preprocessing.scale(X1)\n",
    "y=dataset.iloc[:,0].values\n",
    "count = 0\n",
    "totalacc = 0\n",
    "cper=[];ytt=[];\n",
    "kmeans = KMeans(n_clusters = 2, init = 'k-means++', random_state = 42)\n",
    "y_kmeans = kmeans.fit_predict(X1)\n",
    "y_kmeans\n",
    "# y_kmeans=np.where(y_kmeans==0,1,0);\n",
    "df1=pd.DataFrame({'True_label':y,'predic_label':y_kmeans})\n",
    "#     print df1\n",
    "score=accuracy_score(y_kmeans, y)*100.0\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
