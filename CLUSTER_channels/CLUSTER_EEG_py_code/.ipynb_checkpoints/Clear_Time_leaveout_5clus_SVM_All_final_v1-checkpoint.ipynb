{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score,ShuffleSplit,LeaveOneOut\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,roc_curve, auc\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "from scipy.stats import norm, zscore\n",
    "#import seaborn as sns; sns.set(font_scale=1.2)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of clear speech-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 32\n"
     ]
    }
   ],
   "source": [
    "pathr=\"C:/Users/Sultan/OneDrive - The University of Memphis/RESEARCH2017S/CLUSTER_channels/S_E12/\"\n",
    "fnamecl='Allsube12.xlsx'\n",
    "d=pd.read_excel(pathr+fnamecl)\n",
    "print(\"Total rows: {0}\".format(len(d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# allacc=[];\n",
    "# for count in range(2,108):\n",
    "#     dpc=[];yc=[];\n",
    "#     for i in range(3):\n",
    "#         a=[]\n",
    "#         k=0\n",
    "#         for j in range(5):\n",
    "#             #print i,k\n",
    "#             dd=d.values[i,k+count]\n",
    "#             #b=np.concatenate((M,dd),axis=0)\n",
    "#             j+=1\n",
    "#             k=106*j\n",
    "#             a.append(dd)      \n",
    "#         y=d.values[i,0]\n",
    "#         a.append(y)\n",
    "#         dpc.append(a)\n",
    "#         c=pd.DataFrame(dpc)\n",
    "#         X=c.iloc[:,0:5]\n",
    "#         labels=c.iloc[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allacc=[];\n",
    "for count in range(2,108):# Number of sample in the data\n",
    "    dpc=[];yc=[];\n",
    "    for i in range(32):\n",
    "        a=[]\n",
    "        k=0\n",
    "        for j in range(5):\n",
    "            #print i,k\n",
    "            dd=d.values[i,k+count] # data separate each sample\n",
    "            #b=np.concatenate((M,dd),axis=0)\n",
    "            j+=1\n",
    "            k=106*j\n",
    "            a.append(dd)      \n",
    "        y=d.values[i,0]; # Label first column\n",
    "        a.append(y)\n",
    "        dpc.append(a)\n",
    "        c=pd.DataFrame(dpc)\n",
    "        X=c.iloc[:,0:5]\n",
    "        y=c.iloc[:,5]\n",
    "        #print y\n",
    "        # Upto this feature extraction\n",
    "    #print X\n",
    "    cn=0; totalacc=0;\n",
    "    X_scaled = preprocessing.scale(X)\n",
    "    for train_index, test_index in leaveout.split(X_scaled):\n",
    "        #print train_index,test_index\n",
    "        ##X_trn, X_tst = X[train_index], X[test_index]\n",
    "        X_trn, X_tst = X_scaled[train_index], X_scaled[test_index]\n",
    "        y_trn, y_tst = y[train_index], y[test_index]\n",
    "        parameters = {'kernel':('linear', 'rbf','poly','sigmoid'), 'C':[1, 10,100,1000],'gamma':[0.01,.002,0.003]}\n",
    "        svc = svm.SVC()\n",
    "        clf = GridSearchCV(svc, parameters)\n",
    "        #print X_trn, y_trn\n",
    "        clf.fit(X_trn, y_trn)\n",
    "        #print clf.best_estimator_\n",
    "        acc = accuracy_score(clf.best_estimator_.predict(X_tst),y_tst)\n",
    "        totalacc = totalacc + acc\n",
    "        cn = cn + 1\n",
    "        #print cn, acc, totalacc; # See the how many correct over the whole\n",
    "        score=totalacc/cn*100.0\n",
    "    allacc.append(score)\n",
    "    Acd=pd.DataFrame(allacc)\n",
    "    #print score\n",
    "t=np.linspace(-10,200,106)\n",
    "#Acd.plot(kind='line',ylim=[0,1])\n",
    "plt.plot(t,Acd,c='k')\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('% Accuracy')\n",
    "#print par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print par\n",
    "time=pd.DataFrame(t)\n",
    "tad=pd.concat([time, Acd],axis=1)\n",
    "selt=tad.iloc[25:34]\n",
    "av=selt.mean()\n",
    "print selt,'\\n','The average accuracy over the time is:', av.iloc[1]*100.0\n",
    "#print tad.iloc[20:42]\n",
    "#tad.to_csv('clear_speech_classi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t1=tad.iloc[5:,0];Acd1=tad.iloc[5:,1];\n",
    "plt.plot(t1,Acd1,c='g')\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('% Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification from LH's two clusters (C1, C2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allacc=[];\n",
    "for count in range(2,108): # Number of sample in the data\n",
    "    dpc=[];yc=[]; # empty variable for dictionary\n",
    "    for i in range(32): # number of participant\n",
    "        a=[]; # Dictionary\n",
    "        k=0 ;\n",
    "        for j in range(2):\n",
    "            #print i,k\n",
    "            dd=d.values[i,k+count] ; # data separate each sample\n",
    "            #b=np.concatenate((M,dd),axis=0)\n",
    "            j+=1\n",
    "            k=106*j\n",
    "            a.append(dd) # append features      \n",
    "        y=d.values[i,0]\n",
    "        a.append(y)\n",
    "        dpc.append(a) # data frame with label\n",
    "        c=pd.DataFrame(dpc) # c is the new data \n",
    "        X=c.iloc[:,0:2] # X is the feature from clusters\n",
    "        labels=c.iloc[:,2]\n",
    "        y=labels\n",
    "# Upto this feature extraction\n",
    "    cn=0; totalacc=0;\n",
    "    X_scaled = preprocessing.scale(X)\n",
    "    for train_index, test_index in leaveout.split(X_scaled):\n",
    "        #print train_index,test_index\n",
    "        ##X_trn, X_tst = X[train_index], X[test_index]\n",
    "        X_trn, X_tst = X_scaled[train_index], X_scaled[test_index]\n",
    "        y_trn, y_tst = y[train_index], y[test_index]\n",
    "        parameters = {'kernel':('linear', 'rbf','poly','sigmoid'), 'C':[1, 10,100,1000],'gamma':[0.01,.002,0.003]}\n",
    "        svc = svm.SVC()\n",
    "        clf = GridSearchCV(svc, parameters)\n",
    "        #print X_trn, y_trn\n",
    "        clf.fit(X_trn, y_trn)\n",
    "        #print clf.best_estimator_\n",
    "        acc = accuracy_score(clf.best_estimator_.predict(X_tst),y_tst)\n",
    "        totalacc = totalacc + acc\n",
    "        cn = cn + 1\n",
    "        #print cn, acc, totalacc; # See the how many correct over the whole\n",
    "        score=totalacc/cn*100.0\n",
    "    allacc.append(score)\n",
    "    Acd=pd.DataFrame(allacc)\n",
    "    #print acc*100.0\n",
    "t=np.linspace(-10,200,106)\n",
    "#Acd.plot(kind='line',ylim=[0,1])\n",
    "plt.plot(t,Acd,c='k')\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('% Accuracy')\n",
    "#print par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print par\n",
    "time=pd.DataFrame(t)\n",
    "tad=pd.concat([time, Acd],axis=1)\n",
    "selt=tad.iloc[35:45]\n",
    "av=selt.mean()\n",
    "print selt,'\\n','The average accuracy over the time is:', av.iloc[1]*100.0\n",
    "#print tad.iloc[20:42]\n",
    "#tad.to_csv('clear_speech_classi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t1=tad.iloc[5:,0];Acd1=tad.iloc[5:,1];\n",
    "plt.plot(t1,Acd1,c='g')\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('% Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification from RH's two clusters (C3, C4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allacc=[];\n",
    "for count in range(2,108): # Number of sample in the data\n",
    "    dpc=[];yc=[]; # empty variable for dictionary\n",
    "    for i in range(32): # number of participant\n",
    "        a=[]; # Dictionary\n",
    "        k=0 ;\n",
    "        for j in range(2,4):\n",
    "            k=106*j\n",
    "            #print i,k\n",
    "            dd=d.values[i,k+count] ; # data separate each sample\n",
    "            #b=np.concatenate((M,dd),axis=0)\n",
    "            j+=1\n",
    "            a.append(dd) # append features      \n",
    "        y=d.values[i,0]\n",
    "        a.append(y)\n",
    "        dpc.append(a) # data frame with label\n",
    "        c=pd.DataFrame(dpc) # c is the new data \n",
    "        X=c.iloc[:,0:2] # X is the feature from clusters\n",
    "        labels=c.iloc[:,2]\n",
    "        y=labels\n",
    "# Upto this feature extraction\n",
    "      cn=0; totalacc=0;\n",
    "    X_scaled = preprocessing.scale(X)\n",
    "    for train_index, test_index in leaveout.split(X_scaled):\n",
    "        #print train_index,test_index\n",
    "        ##X_trn, X_tst = X[train_index], X[test_index]\n",
    "        X_trn, X_tst = X_scaled[train_index], X_scaled[test_index]\n",
    "        y_trn, y_tst = y[train_index], y[test_index]\n",
    "        parameters = {'kernel':('linear', 'rbf','poly','sigmoid'), 'C':[1, 10,100,1000],'gamma':[0.01,.002,0.003]}\n",
    "        svc = svm.SVC()\n",
    "        clf = GridSearchCV(svc, parameters)\n",
    "        #print X_trn, y_trn\n",
    "        clf.fit(X_trn, y_trn)\n",
    "        #print clf.best_estimator_\n",
    "        acc = accuracy_score(clf.best_estimator_.predict(X_tst),y_tst)\n",
    "        totalacc = totalacc + acc\n",
    "        cn = cn + 1\n",
    "        #print cn, acc, totalacc; # See the how many correct over the whole\n",
    "        score=totalacc/cn*100.0\n",
    "    allacc.append(score)\n",
    "    Acdn=pd.DataFrame(allacc)\n",
    "    #print acc*100.0\n",
    "t=np.linspace(-10,200,106)\n",
    "#Acd.plot(kind='line',ylim=[0,1])\n",
    "plt.plot(t,Acdn,c='r')\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('% Accuracy')\n",
    "#print par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print par\n",
    "time=pd.DataFrame(t)\n",
    "tadn=pd.concat([time, Acdn],axis=1)\n",
    "seltn=tadn.iloc[27:37]\n",
    "av=seltn.mean()\n",
    "print seltn,'\\n','The average accuracy over the time is:', av.iloc[1]*100.0\n",
    "#print tad.iloc[40:60]\n",
    "#tadn.to_csv('Noise-degraded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
