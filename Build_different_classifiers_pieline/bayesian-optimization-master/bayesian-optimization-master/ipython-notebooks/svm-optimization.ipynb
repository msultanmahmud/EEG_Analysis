{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Bayesian optimization of SVM]((https://thuijskens.github.io/2016/12/29/bayesian-optimisation/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Load the Python scripts that contain the Bayesian optimization code\n",
    "%run ./../python/gp.py\n",
    "%run ./../python/plotters.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how this algorithm behaves, we'll use it on a classification task. Luckily for us, scikit-learn provides helper functions like `make_classification()`, to build dummy data sets that can be used to test classifiers.\n",
    "\n",
    "We'll optimize the penalization parameter $C$, and kernel parameter $\\gamma$, of a support vector machine, with RBF kernel. The loss function we will use is the cross-validated area under the curve (AUC), based on three folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import sklearn.gaussian_process as gp\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = make_classification(n_samples=2500,\n",
    "                                   n_features=45,\n",
    "                                   n_informative=15,\n",
    "                                   n_redundant=5)\n",
    "\n",
    "def sample_loss(params):\n",
    "    return cross_val_score(SVC(C=10 ** params[0], gamma=10 ** params[1], random_state=12345),\n",
    "                           X=data, y=target, scoring='roc_auc', cv=3).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this is a relatively simple problem, we can actually compute the loss surface as a function of $C$ and $\\gamma$. This way, we can get an accurate estimate of where the true optimum of the loss surface is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.375     , -2.15789474])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas = np.linspace(1, -4, 25)\n",
    "gammas = np.linspace(1, -4, 20)\n",
    "\n",
    "# We need the cartesian combination of these two vectors\n",
    "param_grid = np.array([[C, gamma] for gamma in gammas for C in lambdas])\n",
    "\n",
    "real_loss = [sample_loss(params) for params in param_grid]\n",
    "\n",
    "# The maximum is at:\n",
    "param_grid[np.array(real_loss).argmax(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import rc\n",
    "rc('text', usetex=True)\n",
    "C, G = np.meshgrid(lambdas, gammas)\n",
    "plt.figure()\n",
    "cp = plt.contourf(C, G, np.array(real_loss).reshape(C.shape))\n",
    "plt.colorbar(cp)\n",
    "plt.title('Filled contours plot of loss function $\\mathcal{L}$($\\gamma$, $C$)')\n",
    "plt.xlabel('$C$')\n",
    "# plt.ylabel('$\\gamma')\n",
    "# plt.savefig('/Users/thomashuijskens/Personal/gp-optimisation/figures/real_loss_contour.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the underlying GP, we'll assume a [Matern](http://scikit-learn.org/stable/modules/gaussian_process.html#matern-kernel) kernel as the covariance function. Although we skim over the selection of the kernel here, in general the behaviour of the algorithm is dependent on the choice of the kernel. Using a Matern kernel, with the default parameters, means we implicitly assume the loss $f$ is at least once differentiable. [There are a number of kernels available](http://scikit-learn.org/stable/modules/gaussian_process.html#kernels-for-gaussian-processes) in scikit-learn, and each kernel implies a different assumption on the behaviour of the loss $f$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'warnflag': 2, 'task': 'ABNORMAL_TERMINATION_IN_LNSRCH', 'grad': array([-3.18435523e-05]), 'nit': 5, 'funcalls': 50}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    }
   ],
   "source": [
    "bounds = np.array([[-4, 1], [-4, 1]])\n",
    "\n",
    "xp, yp = bayesian_optimisation(n_iters=30, \n",
    "                               sample_loss=sample_loss, \n",
    "                               bounds=bounds,\n",
    "                               n_pre_samples=3,\n",
    "                               random_search=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The animation below shows the sequence of points selected, if we run the Bayesian optimization algorithm in this setting. The star shows the value of $C$ and $\\gamma$ that result in the largest value of cross-validated AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'gp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-b756c3044f69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musetex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond_param_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgammas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.58333333\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2.15789474\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/sultan/EEG/Build_different_classifiers_pieline/bayesian-optimization-master/bayesian-optimization-master/python/plotters.py\u001b[0m in \u001b[0;36mplot_iteration\u001b[0;34m(first_param_grid, sampled_params, sampled_loss, first_iter, alpha, greater_is_better, true_y, second_param_grid, param_dims_to_plot, filepath, optimum)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# Create the GP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMatern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     model = gp.GaussianProcessRegressor(kernel=kernel,\n\u001b[1;32m     46\u001b[0m                                         \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'gp' is not defined"
     ]
    }
   ],
   "source": [
    "rc('text', usetex=False)\n",
    "plot_iteration(lambdas, xp, yp, first_iter=3, second_param_grid=gammas, optimum=[0.58333333, -2.15789474])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a gif from the images\n",
    "import imageio\n",
    "images = []\n",
    "\n",
    "for i in range(3, 23):\n",
    "    filename = \"/Users/thomashuijskens/Personal/gp-optimisation/figures/bo_iteration_%d.png\" % i \n",
    "    images.append(imageio.imread(filename))\n",
    "    \n",
    "imageio.mimsave('/Users/thomashuijskens/Personal/gp-optimisation/figures/bo_2d_new_data.gif', images, duration=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_optimization(n_iters, sample_loss, xp, yp):\n",
    "              \"\"\"\n",
    "\n",
    "              Arguments:\n",
    "              ----------\n",
    "                n_iters: int.\n",
    "                  Number of iterations to run the algorithm for.\n",
    "                sample_loss: function.\n",
    "                  Loss function that takes an array of parameters.\n",
    "                xp: array-like, shape = [n_samples, n_params].\n",
    "                  Array of previously evaluated hyperparameters.\n",
    "                yp: array-like, shape = [n_samples, 1].\n",
    "                  Array of values of `sample_loss` for the hyperparameters\n",
    "                  in `xp`.\n",
    "              \"\"\"\n",
    "\n",
    "              # Define the GP\n",
    "              kernel = gp.kernels.Matern()\n",
    "              model = gp.GaussianProcessRegressor(kernel=kernel,\n",
    "                                                  alpha=1e-4,\n",
    "                                                  n_restarts_optimizer=10,\n",
    "                                                  normalize_y=True)\n",
    "              for i in range(n_iters):\n",
    "                # Update our belief of the loss function\n",
    "                model.fit(xp, yp)\n",
    "\n",
    "                # sample_next_hyperparameter is a method that computes the arg\n",
    "                # max of the acquisition function\n",
    "                next_sample = sample_next_hyperparameter(model, yp)\n",
    "\n",
    "                # Evaluate the loss for the new hyperparameters\n",
    "                next_loss = sample_loss(next_sample)\n",
    "\n",
    "                # Update xp and yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_loss(params):\n",
    "          C = params[0]\n",
    "          gamma = params[1]\n",
    "\n",
    "          # Sample C and gamma on the log-uniform scale\n",
    "          model = SVC(C=10 ** C, gamma=10 ** gamma, random_state=12345)\n",
    "\n",
    "          # Sample parameters on a log scale\n",
    "          return cross_val_score(model=model,\n",
    "                                 X=data,\n",
    "                                 y=target,\n",
    "                                 scoring='roc_auc',\n",
    "                                 cv=3).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
