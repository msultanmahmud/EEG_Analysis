{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,ShuffleSplit\n",
    "from sklearn import svm\n",
    "import sys\n",
    "# sys.path.append('/home/ralfahad/PythonUtility/PTE')\n",
    "# from PhaseTE_MF import PhaseTE_MF\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "import warnings\n",
    "from sklearn import svm, metrics,preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,roc_curve, auc,classification_report\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "from scipy.stats import norm\n",
    "# from sklearn import metrics\n",
    "# import seaborn as sns; sns.set(font_scale=1.2)\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>1418</th>\n",
       "      <th>1419</th>\n",
       "      <th>1420</th>\n",
       "      <th>1421</th>\n",
       "      <th>1422</th>\n",
       "      <th>1423</th>\n",
       "      <th>1424</th>\n",
       "      <th>1425</th>\n",
       "      <th>1426</th>\n",
       "      <th>1427</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.388002e-10</td>\n",
       "      <td>-3.592889e-10</td>\n",
       "      <td>-1.451065e-10</td>\n",
       "      <td>1.075404e-10</td>\n",
       "      <td>-1.060196e-10</td>\n",
       "      <td>-8.093499e-11</td>\n",
       "      <td>-6.206288e-10</td>\n",
       "      <td>9.926738e-11</td>\n",
       "      <td>1.713508e-10</td>\n",
       "      <td>-2.551228e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.905225e-12</td>\n",
       "      <td>-1.388882e-10</td>\n",
       "      <td>7.810877e-11</td>\n",
       "      <td>9.192349e-11</td>\n",
       "      <td>-2.688938e-10</td>\n",
       "      <td>1.406612e-11</td>\n",
       "      <td>-3.957793e-10</td>\n",
       "      <td>-3.586176e-10</td>\n",
       "      <td>1.575622e-10</td>\n",
       "      <td>-1.560890e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 1430 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  label    0    1    2    3    4    5    6    7      ...       \\\n",
       "0           0    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0      ...        \n",
       "1           1    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0      ...        \n",
       "\n",
       "           1418          1419          1420          1421          1422  \\\n",
       "0  1.388002e-10 -3.592889e-10 -1.451065e-10  1.075404e-10 -1.060196e-10   \n",
       "1  2.905225e-12 -1.388882e-10  7.810877e-11  9.192349e-11 -2.688938e-10   \n",
       "\n",
       "           1423          1424          1425          1426          1427  \n",
       "0 -8.093499e-11 -6.206288e-10  9.926738e-11  1.713508e-10 -2.551228e-10  \n",
       "1  1.406612e-11 -3.957793e-10 -3.586176e-10  1.575622e-10 -1.560890e-10  \n",
       "\n",
       "[2 rows x 1430 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the metadata\n",
    "# path='/home/sultan/EEG/Source_Level_Analysis/25sam_10ms_clear_all_erp.csv'\n",
    "# path=\"/home/sultan/EEG/Source_Level_Analysis/50tr10ms_all_clear_erp.csv\"\n",
    "# path=\"/home/sultan/EEG/Source_Level_Analysis/75sam_10ms_clear_all_erp.csv\"\n",
    "# path=\"/home/sultan/EEG/Source_Level_Analysis/100sam_10ms_clear_all_erp.csv\"\n",
    "path=\"/home/sultan/EEG/Source_Level_Analysis/Baseline_100sam_10ms_noise_all_erp.csv\"\n",
    "# path=\"/home/sultan/EEG/Source_Level_Analysis/125sam_10ms_clear_all_erp.csv\"\n",
    "Metadata=pd.read_csv(path)\n",
    "Metadata.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##Load the metadata\n",
    "# # path='/home/sultan/EEG/Source_Level_Analysis/25sam_10ms_noise_all_erp.csv'\n",
    "# # path='/home/sultan/EEG/Source_Level_Analysis/50Tr10msnoise_all_erp.csv'\n",
    "# # path=\"/home/sultan/EEG/Source_Level_Analysis/75sam_10ms_noise_all_erp.csv\"\n",
    "# path=\"/home/sultan/EEG/Source_Level_Analysis/100sam_10ms_noise_all_erp.csv\"\n",
    "# # path=\"/home/sultan/EEG/Source_Level_Analysis/125sam_10ms_noise_all_erp.csv\"\n",
    "# Metadata=pd.read_csv(path)\n",
    "# Metadata.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X=Metadata.iloc[:,2:]\n",
    "# y=Metadata['label']\n",
    "# X.shape,y.unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #NH=0;0-776HI=1;778-1863\n",
    "# y=Metadata['label']\n",
    "# # ynh=y.iloc[0:776]\n",
    "# yhi=y.iloc[777:]\n",
    "# print ynh.shape\n",
    "# print yhi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1804, 1428), (1804,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=Metadata.iloc[:,2:]\n",
    "y=Metadata['label']\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply SVM on Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma_range = np.logspace(-2, 2, 5)\n",
    "gamma_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1804, 1428) (1804,)\n",
      "[1.e-02 1.e-01 1.e+00 1.e+01 1.e+02] [0.01, 0.002, 0.00069, 0.0007, 0.0005]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "# X=preprocessing.scale(X)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "print X.shape,y.shape\n",
    "from sklearn.preprocessing import label_binarize\n",
    "y=label_binarize(np.asarray(y),[0,1])\n",
    "\n",
    "#C_range = np.logspace(-2, 10, 13)\n",
    "# gamma_range = np.logspace(-2, 2, 5)\n",
    "gamma_range = [0.01,0.002,0.00069,0.0007,0.0005]\n",
    "C_range = np.logspace(-2, 2, 5)\n",
    "#gamma_range = np.logspace(-2, 2, 5)\n",
    "\n",
    "print C_range,gamma_range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish tuning\n"
     ]
    }
   ],
   "source": [
    "#Classifiaction:\n",
    "# #Splitting\n",
    "from sklearn import preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,random_state=66)\n",
    "cv = ShuffleSplit(X_train.shape[0], test_size=0.20, random_state=66)\n",
    "\n",
    "# Define Classifier\n",
    "svr = svm.SVC(kernel='rbf')\n",
    "\n",
    "# Deffine tuning parameter\n",
    "C_range = np.logspace(-2, 2, 5)\n",
    "# gamma_range = np.logspace(-2, 2, 5)\n",
    "gamma_range = [0.01,0.002,0.00069,0.0007,0.0005]\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "clf_Tune = GridSearchCV(estimator=svr, cv=5, param_grid=param_grid,n_jobs=-1, verbose=True)\n",
    "clf_Tune.fit(X_train,y_train)\n",
    "print 'Finish tuning'      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.76      0.78       151\n",
      "          1       0.83      0.86      0.85       210\n",
      "\n",
      "avg / total       0.82      0.82      0.82       361\n",
      "\n",
      "0.8199445983379502\n",
      "0.8117470829391359\n"
     ]
    }
   ],
   "source": [
    "y_p = clf_Tune.best_estimator_.predict(X_test)\n",
    "ACC=classification_report(y_test, y_p)\n",
    "print ACC\n",
    "ACC_AVG=accuracy_score(y_test, y_p)\n",
    "print ACC_AVG\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test,y_p)\n",
    "AUC_Th2_T=metrics.auc(fpr, tpr)\n",
    "print AUC_Th2_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8199445983379502\n",
      "support: 70.200970201\n"
     ]
    }
   ],
   "source": [
    "y_p=clf_Tune.best_estimator_.predict(X_test)\n",
    "print \"Accuracy:\", clf_Tune.score(X_test, y_test)  \n",
    "# print pred\n",
    "# print y_test\n",
    "print \"support:\", len(clf_Tune.best_estimator_.support_vectors_)*100.0/(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10.0, 'gamma': 0.0007}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print 'Validation accuracy={}, best {}' .format(clf_Tune.best_score_,clf_Tune.best_params_)\n",
    "clf_Tune.best_params_\n",
    "# clf_Tune.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Utility function to move the midpoint of a colormap to be around\n",
    "# # the values of interest.\n",
    "# from matplotlib.colors import Normalize\n",
    "# class MidpointNormalize(Normalize):\n",
    "\n",
    "#     def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "#         self.midpoint = midpoint\n",
    "#         Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "#     def __call__(self, value, clip=None):\n",
    "#         x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "#         return np.ma.masked_array(np.interp(value, x, y))\n",
    "    \n",
    "# scores = clf_Tune.cv_results_['mean_test_score'].reshape(len(C_range),len(gamma_range))\n",
    "# #print scores.shape,len(C_range),len(gamma_range)\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# #plt.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n",
    "# plt.imshow(scores, interpolation='nearest', cmap=plt.cm.hot, norm=MidpointNormalize(vmin=0.2, midpoint=0.92))\n",
    "# plt.xlabel('gamma')\n",
    "# plt.ylabel('C')\n",
    "# plt.colorbar()\n",
    "# plt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n",
    "# plt.yticks(np.arange(len(C_range)), C_range)\n",
    "# plt.title('Validation accuracy={}, best {}' .format(clf_Tune.best_score_,clf_Tune.best_params_))\n",
    "\n",
    "# #filename='ParameterTuning'\n",
    "# #save_format='png'\n",
    "# #print filename+'.'+save_format\n",
    "# #pp='home/ralfahad/Pictures'\n",
    "# #plt.savefig(filename+'.'+save_format,dpi=100)\n",
    "# #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Significant correlation with stability selections "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre Processing \n",
    "X[0,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1804, 1428) (1804, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "X=preprocessing.scale(X)\n",
    "# scaler = preprocessing.StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "print X.shape,y.shape\n",
    "from sklearn.preprocessing import label_binarize\n",
    "y=label_binarize(np.asarray(y),[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.var(X[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import (RandomizedLasso, lasso_stability_path,LassoLarsCV)\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "#Model Library\n",
    "from sklearn.linear_model import (RandomizedLasso, lasso_stability_path, LassoLarsCV)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, RandomizedLogisticRegression\n",
    "from sklearn import svm\n",
    "\n",
    "# Performance analysis library \n",
    "from sklearn.model_selection import KFold, cross_val_score, LeaveOneOut, cross_val_predict\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split # test train split\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00368117])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    #warnings.simplefilter('ignore', UserWarning)\n",
    "    warnings.simplefilter('ignore', ConvergenceWarning)\n",
    "    lars_cv = LassoLarsCV(cv=5).fit(X, y)\n",
    "# print lars_cv.alpha_\n",
    "lars_cv.alphas_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00368117 0.00331305 0.00294493 0.00257682 0.0022087  0.00184058\n",
      " 0.00147247 0.00110435 0.00073623 0.00036812]\n"
     ]
    }
   ],
   "source": [
    "# Run the RandomizedLasso: we use a paths going down to .1*alpha_max\n",
    "# to avoid exploring the regime in which very noisy variables enter\n",
    "# the model\n",
    "alphas = np.linspace(lars_cv.alphas_[0], .1 * lars_cv.alphas_[0], 10)\n",
    "print alphas\n",
    "clf = RandomizedLasso(alpha=alphas,random_state=66,max_iter=1000).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.  , 0.  , ..., 0.  , 0.01, 0.  ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Rank the Features according to the importance\n",
    "# names=range(0,1428) # Feature names used as 1-1428 features\n",
    "# cn=np.asarray(names) # converted as numpy.ndarray\n",
    "# # print \"Features sorted by their score:\"\n",
    "# b= sorted(zip(map(lambda x: round(x, 4), clf.scores_), cn), reverse=True)\n",
    "# bb=np.asarray(b)\n",
    "# rakfe=bb[bb[:,0]>0.34]\n",
    "# ROIs=rakfe[:,1]%68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print \"Features sorted by their score:\"\n",
    "# b= sorted(zip(map(lambda x: round(x, 4), clf.scores_), \n",
    "#                  cn), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bb=np.asarray(b)\n",
    "# # rf=np.where(bb[:,0]>0.7)\n",
    "# # ifea=np.squeeze(np.asarray(np.where(clf.scores_>=0.815)))\n",
    "# ra=bb[bb[:,0]>0.50]\n",
    "# # r=bb[e]\n",
    "# ra[:,1]%68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ind=np.where(clf.scores_>=0.710)\n",
    "# ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter\n",
    "data=clf.scores_\n",
    "fig, ax = plt.subplots()\n",
    "counts, bins, patches = ax.hist(data,bins=np.round(0.1*np.arange(0,10),2) ,edgecolor='gray')\n",
    "\n",
    "# Set the ticks to be at the edges of the bins.\n",
    "ax.set_xticks(bins)\n",
    "\n",
    "# Set the xaxis's tick labels to be formatted with 1 decimal place...\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter('%0.1f'))\n",
    "\n",
    "\n",
    "# Label the raw counts and the percentages below the x-axis...\n",
    "bin_centers = 0.5 * np.diff(bins) + bins[:-1]\n",
    "for count, x in zip(counts, bin_centers):\n",
    "    # Label the raw counts\n",
    "    ax.annotate(str(count), xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "        xytext=(0, -18), textcoords='offset points', va='top', ha='center')\n",
    "\n",
    "    # Label the percentages\n",
    "    percent = '%0.0f%%' % (100 * float(count) / counts.sum())\n",
    "    ax.annotate(percent, xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "        xytext=(0, -32), textcoords='offset points', va='top', ha='center')\n",
    "\n",
    "\n",
    "# Give ourselves some more room at the bottom of the plot\n",
    "plt.subplots_adjust(bottom=0.15)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9]\n",
      "[0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9]\n"
     ]
    }
   ],
   "source": [
    "Th_2_Bins_Index= np.where((bins<=1.0) & (bins>=0.0)) # take the bins within a range\n",
    "# print Th_2_Bins_Index\n",
    "print bins\n",
    "Th_2_Bins=bins[Th_2_Bins_Index]\n",
    "print Th_2_Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1804, 1428) (1804, 1)\n",
      "(1443, 1428) (361, 1428) (1443, 1) (361, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "X=preprocessing.scale(X)\n",
    "print X.shape,y.shape\n",
    "from sklearn.preprocessing import label_binarize\n",
    "y=label_binarize(np.asarray(y),[0,1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=66)\n",
    "print X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:,1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)#[:,np.squeeze(np.asarray(np.where(clf.scores_>=0.16)))].shape#,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 65 candidates, totalling 325 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 325 out of 325 | elapsed:  9.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'C': [1, 2, 4, 6, 8, 10, 12, 15, 16, 20, 30, 40, 100], 'gamma': [0.01, 0.002, 0.00069, 0.0007, 0.0005]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C_range = np.logspace(-2, 2, 5)\n",
    "C_range = [1,2,4,6,8,10,12,15,16,20,30,40,100]\n",
    "gamma_range = [0.01,0.002,0.00069,0.0007,0.0005]\n",
    "# gamma_range = np.logspace(-2, 2, 5)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "#clf_Tune = GridSearchCV(estimator=svr, cv=1, param_grid=param_grid,n_jobs=-1)\n",
    "clf_Tune = GridSearchCV(estimator=svr, cv=5, param_grid=param_grid,n_jobs=-1, verbose=True)\n",
    "clf_Tune.fit(X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=Th_2_Bins[0])))],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8310249307479224\n"
     ]
    }
   ],
   "source": [
    "# use tuned parameter on to get model\n",
    "y_p = clf_Tune.best_estimator_.predict(X_test[:,np.squeeze(np.asarray(np.where(clf.scores_>=Th_2_Bins[0])))])\n",
    "\n",
    "print accuracy_score(y_test, y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "(1443, 1428)\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:  4.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1443, 1428) (1443, 1)\n",
      "Finish tuning\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.002, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Shape (361, 1428)\n",
      "ACC 0.8060941828254847 0.7830968148848944\n",
      "0.94455994456\n",
      "0.1\n",
      "(1443, 214)\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:   30.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1443, 214) (1443, 1)\n",
      "Finish tuning\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.002, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Shape (361, 214)\n",
      "ACC 0.8088642659279779 0.8059444970040996\n",
      "0.534303534304\n",
      "0.2\n",
      "(1443, 123)\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:   20.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1443, 123) (1443, 1)\n",
      "Finish tuning\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Shape (361, 123)\n",
      "ACC 0.8060941828254847 0.7951907915484074\n",
      "0.654192654193\n",
      "0.3\n",
      "(1443, 72)\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:   14.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1443, 72) (1443, 1)\n",
      "Finish tuning\n",
      "SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.002, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Shape (361, 72)\n",
      "ACC 0.7922437673130194 0.7925890886155786\n",
      "0.463617463617\n",
      "0.4\n",
      "(1443, 37)\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:    9.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1443, 37) (1443, 1)\n",
      "Finish tuning\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Shape (361, 37)\n",
      "ACC 0.8033240997229917 0.7965310627562283\n",
      "0.531531531532\n",
      "0.5\n",
      "(1443, 8)\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 118 out of 125 | elapsed:    5.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:    5.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1443, 8) (1443, 1)\n",
      "Finish tuning\n",
      "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.25, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Shape (361, 8)\n",
      "ACC 0.6703601108033241 0.6338694418164617\n",
      "0.762993762994\n",
      "0.6\n",
      "(1443, 2)\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 118 out of 125 | elapsed:    7.7s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:    8.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1443, 2) (1443, 1)\n",
      "Finish tuning\n",
      "SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Shape (361, 2)\n",
      "ACC 0.5817174515235457 0.5\n",
      "0.823977823978\n",
      "0.7\n",
      "(1443, 0)\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "error at: 0.7\n",
      "0.8\n",
      "(1443, 0)\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "error at: 0.8\n",
      "0.9\n",
      "(1443, 0)\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "error at: 0.9\n"
     ]
    }
   ],
   "source": [
    "# #Splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=66)\n",
    "#cv = ShuffleSplit(X_train.shape[0], test_size=0.2, random_state=66)\n",
    "\n",
    "# Define Classifier\n",
    "svr = svm.SVC(kernel='rbf')\n",
    "\n",
    "# Deffine tuning parameter\n",
    "# C_range = np.logspace(-2, 10, 13)\n",
    "# gamma_range = np.logspace(-9, 3, 13)\n",
    "\n",
    "C_range = np.logspace(-2, 2, 5)\n",
    "gamma_range = [1,0.5, 0.25,0.01,0.002]\n",
    "# gamma_range = [0.01,0.002,0.0006,0.0007]\n",
    "# gamma_range = [0.1,0.01,0.002,0.0005,0.0006,0.0007,]\n",
    "# C_range = [20, 30,50]\n",
    "# C_range=[1000,1500]\n",
    "# C_range = [1,2,4,6,8,10,12,15,16,20,30,40,100]\n",
    "# gamma_range = [0.01,0.015, 0.018, 0.002,0.003,0.0004, 0.0005,0.0006,0.0007]; # 0.0007=1/1428 1428 = no. of features\n",
    "# gamma_range = np.logspace(-2, 2, 5)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "#clf_Tune = GridSearchCV(estimator=svr, cv=1, param_grid=param_grid,n_jobs=-1)\n",
    "clf_Tune = GridSearchCV(estimator=svr, cv=5, param_grid=param_grid,n_jobs=-1, verbose=True)\n",
    "##  Define LeaveOneOutCrossValidation\n",
    "#loocv = LeaveOneOut()\n",
    "ACC_Th2=[]\n",
    "AUC_Th2=[]\n",
    "SV=[]\n",
    "Bins=[]\n",
    "Fsc=[]\n",
    "for i in Th_2_Bins:\n",
    "    print i\n",
    "    try:\n",
    "        print X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))].shape\n",
    "        \n",
    "        #Hyper parameter Tuning \n",
    "        clf_Tune.fit(X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))],y_train)\n",
    "        print X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))].shape ,y_train.shape\n",
    "        print 'Finish tuning'\n",
    "        print clf_Tune.best_estimator_\n",
    "\n",
    "        # use tuned parameter on to get model\n",
    "        y_p = clf_Tune.best_estimator_.predict(X_test[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))])\n",
    "\n",
    "        ACC_Th2_T=accuracy_score(y_test, y_p)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test,y_p)\n",
    "        AUC_Th2_T=metrics.auc(fpr, tpr)\n",
    "        perf=classification_report(y_test, y_p)\n",
    "        print 'Shape', X_test[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))].shape\n",
    "        print 'ACC',ACC_Th2_T,AUC_Th2_T\n",
    "        SVe=float(len(clf_Tune.best_estimator_.support_vectors_))/X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))].shape[0]\n",
    "        print SVe\n",
    "        SV.append(SVe)\n",
    "#         print 'Report',classification_report(y_test, y_p)\n",
    "        ACC_Th2.append(ACC_Th2_T)\n",
    "        AUC_Th2.append(AUC_Th2_T)\n",
    "        Fsc.append(perf)\n",
    "        Bins.append(i)\n",
    "    except:\n",
    "        print 'error at:',i\n",
    "    # false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_p)\n",
    "    # roc_auc_T = auc(false_positive_rate, true_positive_rate)\n",
    "    # print 'AUC',roc_auc_T\n",
    "    # AUC_Th2.append(roc_auc_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score(y_test, y_p)\n",
    "# MulticlassAuc(y_test,y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8060941828254847\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.64      0.73       151\n",
      "          1       0.78      0.92      0.85       210\n",
      "\n",
      "avg / total       0.81      0.81      0.80       361\n",
      "\n",
      "0.8088642659279779\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.79      0.78       151\n",
      "          1       0.84      0.82      0.83       210\n",
      "\n",
      "avg / total       0.81      0.81      0.81       361\n",
      "\n",
      "0.8060941828254847\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.73      0.76       151\n",
      "          1       0.82      0.86      0.84       210\n",
      "\n",
      "avg / total       0.81      0.81      0.80       361\n",
      "\n",
      "0.7922437673130194\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.79      0.76       151\n",
      "          1       0.84      0.79      0.82       210\n",
      "\n",
      "avg / total       0.80      0.79      0.79       361\n",
      "\n",
      "0.8033240997229917\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.75      0.76       151\n",
      "          1       0.83      0.84      0.83       210\n",
      "\n",
      "avg / total       0.80      0.80      0.80       361\n",
      "\n",
      "0.6703601108033241\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.41      0.51       151\n",
      "          1       0.67      0.86      0.75       210\n",
      "\n",
      "avg / total       0.67      0.67      0.65       361\n",
      "\n",
      "0.5817174515235457\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       151\n",
      "          1       0.58      1.00      0.74       210\n",
      "\n",
      "avg / total       0.34      0.58      0.43       361\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-1033f4833abe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0mACC_Th2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mFsc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(0,9):\n",
    "    print ACC_Th2[i] \n",
    "    print (Fsc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "#         ACC_Th2_T=accuracy_score(y_test, y_p)\n",
    "#         AUC_Th2_T=MulticlassAuc(y_test,y_p)\n",
    "#         print 'Shape', X_test[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))].shape\n",
    "#         print 'ACC',ACC_Th2_T,AUC_Th2_T\n",
    "#         ACC_Th2.append(ACC_Th2_T)\n",
    "#         AUC_Th2.append(AUC_Th2_T)\n",
    "#         Bins.append(i)\n",
    "#     except:\n",
    "#         print 'error at:',i\n",
    "#     # false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_p)\n",
    "#     # roc_auc_T = auc(false_positive_rate, true_positive_rate)\n",
    "#     # print 'AUC',roc_auc_T\n",
    "#     # AUC_Th2.append(roc_auc_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC_Th2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter\n",
    "Th_2_Bins=np.asarray(Bins)\n",
    "data=clf.scores_\n",
    "fig, ax = plt.subplots()\n",
    "fig.subplots_adjust(right=0.75)\n",
    "#counts, bins, patches = ax.hist(data,10 ,edgecolor='gray')\n",
    "counts, bins, patches = ax.hist(data,bins=np.round(0.1*np.arange(0,10),2),facecolor=\"None\",edgecolor='blue', lw=1)\n",
    "# Set the ticks to be at the edges of the bins.\n",
    "ax.set_xticks(bins)\n",
    "# Set the xaxis's tick labels to be formatted with 1 decimal place...\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter('%0.1f'))\n",
    "\n",
    "\n",
    "bin_centers = 0.5 * np.diff(bins) + bins[:-1]\n",
    "\n",
    "#show % value\n",
    "for count, x in zip(counts, bin_centers):\n",
    "    # Label the raw counts\n",
    "    ax.annotate(int(count), xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "        xytext=(0, -18), textcoords='offset points', va='top', ha='center')\n",
    "\n",
    "    # Label the percentages\n",
    "    percent = '%0.0f%%' % (100 * float(count) / counts.sum())\n",
    "    ax.annotate(percent, xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "        xytext=(0, -32), textcoords='offset points', va='top', ha='center')\n",
    "    \n",
    "    # Give ourselves some more room at the bottom of the plot\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(Th_2_Bins,AUC_Th2, color='red',ls='dashed' )#,THbin,CCC_Per)\n",
    "ax2.set_frame_on(False)\n",
    "ax2.set_ylabel('AUC', color='red')\n",
    "ax2.patch.set_visible(False)\n",
    "for i,j in zip(Th_2_Bins,AUC_Th2):\n",
    "    #ax2.annotate((\"%.2f\" % j),xy=(i+0.04,j-0.01), color ='red') ##############################\n",
    "    ax2.annotate((\"%.3f\" % j),xy=(i,j-0.01), color ='red') ##############################\n",
    "    ax2.plot(i,j, marker='o', markersize=7, color=\"red\")\n",
    "\n",
    "\n",
    "    \n",
    "ax3 = ax.twinx()\n",
    "ax3.plot(Th_2_Bins,ACC_Th2, color='black')#,THbin,CCC_Per)\n",
    "ax3.set_frame_on(False)\n",
    "ax3.set_ylabel('Accuracy', color='black')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i,j in zip(Th_2_Bins,ACC_Th2):\n",
    "     #ax3.annotate((\"%0.2f\" % j),xy=(i-0.05,j), color='black')\n",
    "    #ax3.annotate((\"%0.2f\" % j),xy=(i-0.1,j), color='black')##################################\n",
    "    ax3.annotate((\"%0.3f\" % j),xy=(i,j+0.01), color='black')##################################\n",
    "    ax3.plot(i,j, marker='*', markersize=10, color=\"black\")\n",
    "    #ax3.annotate((\"%0.2f,%0.2f\" % (i,j)),xy=(i-0.05,j), color='green')\n",
    "    #ax3.annotate((\"%0.3f\" %j),xy=(i,j), color='green')\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Move the last y-axis spine over to the right by 20% of the width of the axes\n",
    "ax3.spines['right'].set_position(('axes', 1.15))\n",
    "ax3.spines['right'].set_visible(True)\n",
    "\n",
    "# To make the border of the right-most axis visible, we need to turn the frame\n",
    "# on. This hides the other plots, however, so we need to turn its fill off.\n",
    "ax3.set_frame_on(True)\n",
    "ax3.patch.set_visible(False)\n",
    "\n",
    "\n",
    "#ax.plot(bins,np.linspace(0,1,11))\n",
    "plt.subplots_adjust(bottom=0.15)\n",
    "plt.grid(False,which='both')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.yaxis.label.set_color('Blue')\n",
    "plt.title(\"Clear\")\n",
    "plt.tight_layout()\n",
    "# #Save the image\n",
    "\n",
    "filename='StabilitySelection_clear'\n",
    "save_format='png'\n",
    "#print filename+'.'+save_format\n",
    "#pp='home/ralfahad/Pictures'\n",
    "#plt.savefig(filename+'.'+save_format,dpi=100)\n",
    "plt.savefig(filename+'.'+save_format,dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROIs added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roisc=[68,68,61,45,22,8,3,0,2]\n",
    "roisc=[68,64,56,46,35,13,5,2,2]\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "Th_2_Bins=np.asarray(Bins)\n",
    "data=clf.scores_\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "fig.subplots_adjust(right=0.75)\n",
    "#counts, bins, patches = ax.hist(data,10 ,edgecolor='gray')\n",
    "counts, bins, patches = ax.hist(data,bins=np.round(0.1*np.arange(0,10),2),facecolor=\"None\",edgecolor='blue', lw=1)\n",
    "# Set the ticks to be at the edges of the bins.\n",
    "ax.set_xticks(bins)\n",
    "# Set the xaxis's tick labels to be formatted with 1 decimal place...\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter('%0.1f'))\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "                tick.label.set_fontsize(14) \n",
    "\n",
    "bin_centers = 0.5 * np.diff(bins) + bins[:-1]\n",
    "\n",
    "#show % value\n",
    "for count, x,rois in zip(counts, bin_centers,roisc):\n",
    "    # Label the raw counts\n",
    "    ax.annotate(int(count), xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "        xytext=(0, -20), fontsize=14,textcoords='offset points', va='top', ha='center')\n",
    "\n",
    "    # Label the percentages\n",
    "    percent = '%0.0f%%' % (100 * float(count) / counts.sum())\n",
    "    ax.annotate(percent, xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "        xytext=(0, -40), fontsize=14,textcoords='offset points', va='top', ha='center')\n",
    "    # ROIs\n",
    "    ax.annotate(rois, xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "    xytext=(0, -60),fontsize=14, textcoords='offset points', va='top', ha='center')\n",
    "    \n",
    "    # Give ourselves some more room at the bottom of the plot\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(Th_2_Bins,AUC_Th2, color='red',ls='dashed',alpha=0.5)#,THbin,CCC_Per)\n",
    "ax2.set_frame_on(False)\n",
    "ax2.set_ylabel('AUC', color='red',fontsize=15)\n",
    "ax2.patch.set_visible(False)\n",
    "for i,j in zip(Th_2_Bins,AUC_Th2):\n",
    "    #ax2.annotate((\"%.2f\" % j),xy=(i+0.04,j-0.01), color ='red') ##############################\n",
    "    ax2.annotate((\"%.3f\" % j),xy=(i,j-0.01), color ='red',fontsize=12) ##############################\n",
    "    ax2.plot(i,j, marker='o', markersize=7, color=\"red\")\n",
    "\n",
    "\n",
    "    \n",
    "ax3 = ax.twinx()\n",
    "ax3.plot(Th_2_Bins,ACC_Th2, color='black')#,THbin,CCC_Per)\n",
    "ax3.set_frame_on(False)\n",
    "ax3.set_ylabel('Accuracy', color='black',fontsize=15)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i,j in zip(Th_2_Bins,ACC_Th2):\n",
    "     #ax3.annotate((\"%0.2f\" % j),xy=(i-0.05,j), color='black')\n",
    "    #ax3.annotate((\"%0.2f\" % j),xy=(i-0.1,j), color='black')##################################\n",
    "    ax3.annotate((\"%0.3f\" % j),xy=(i,j+0.015), color='black',fontsize=12)##################################\n",
    "    ax3.plot(i,j, marker='*', markersize=10, color=\"black\",alpha=0.2)\n",
    "    #ax3.annotate((\"%0.2f,%0.2f\" % (i,j)),xy=(i-0.05,j), color='green')\n",
    "    #ax3.annotate((\"%0.3f\" %j),xy=(i,j), color='green')\n",
    "    \n",
    "    \n",
    "# Move the last y-axis spine over to the right by 20% of the width of the axes\n",
    "ax3.spines['right'].set_position(('axes', 1.15))\n",
    "ax3.spines['right'].set_visible(True)\n",
    "\n",
    "# To make the border of the right-most axis visible, we need to turn the frame\n",
    "# on. This hides the other plots, however, so we need to turn its fill off.\n",
    "ax3.set_frame_on(True)\n",
    "ax3.patch.set_visible(False)\n",
    "\n",
    "\n",
    "#ax.plot(bins,np.linspace(0,1,11))\n",
    "plt.subplots_adjust(bottom=.15)\n",
    "plt.grid(False,which='both')\n",
    "ax.set_ylabel('Frequency',fontsize=15)\n",
    "ax.yaxis.label.set_color('Blue')\n",
    "plt.title(\"Clear\")\n",
    "plt.tight_layout()\n",
    "# #Save the image\n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "                tick.label.set_fontsize(14)\n",
    "filename='StabilitySelection_clear'\n",
    "save_format='png'\n",
    "#print filename+'.'+save_format\n",
    "#pp='home/ralfahad/Pictures'\n",
    "#plt.savefig(filename+'.'+save_format,dpi=100)\n",
    "plt.savefig(filename+'.'+save_format,dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make it inside boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roisc=[68,68,61,45,22,8,3,0,2]\n",
    "roisc=[68,64,56,46,35,13,5,2,2]\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "Th_2_Bins=np.asarray(Bins)\n",
    "data=clf.scores_\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "fig.subplots_adjust(right=0.75)\n",
    "#counts, bins, patches = ax.hist(data,10 ,edgecolor='gray')\n",
    "counts, bins, patches = ax.hist(data,bins=np.round(0.1*np.arange(0,10),2),facecolor=\"None\",edgecolor='blue', lw=1)\n",
    "# Set the ticks to be at the edges of the bins.\n",
    "ax.set_xticks(bins)\n",
    "# Set the xaxis's tick labels to be formatted with 1 decimal place...\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter('%0.1f'))\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "                tick.label.set_fontsize(14) \n",
    "\n",
    "bin_centers = 0.5 * np.diff(bins) + bins[:-1]\n",
    "\n",
    "#show % value\n",
    "for count, x,rois in zip(counts, bin_centers,roisc):\n",
    "    # Label the raw counts\n",
    "    ax.annotate(int(count), xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "        xytext=(0, -20), fontsize=14,textcoords='offset points', va='top', ha='center')\n",
    "\n",
    "    # Label the percentages\n",
    "    percent = '%0.0f%%' % (100 * float(count) / counts.sum())\n",
    "    ax.annotate(percent, xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "        xytext=(0, -40), fontsize=14,textcoords='offset points', va='top', ha='center')\n",
    "    # ROIs\n",
    "    ax.annotate(rois, xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "    xytext=(0, -60),fontsize=14, textcoords='offset points', va='top', ha='center')\n",
    "    \n",
    "    # Give ourselves some more room at the bottom of the plot\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(Th_2_Bins,AUC_Th2, color='red',ls='dashed',alpha=0.5)#,THbin,CCC_Per)\n",
    "ax2.set_frame_on(False)\n",
    "ax2.set_ylabel('AUC', color='red',fontsize=15)\n",
    "ax2.patch.set_visible(False)\n",
    "for i,j in zip(Th_2_Bins,AUC_Th2):\n",
    "    #ax2.annotate((\"%.2f\" % j),xy=(i+0.04,j-0.01), color ='red') ##############################\n",
    "    ax2.annotate((\"%.3f\" % j),xy=(i,j-0.012), color ='red',fontsize=12) ##############################\n",
    "    ax2.plot(i,j, marker='o', markersize=7, color=\"red\")\n",
    "\n",
    "\n",
    "    \n",
    "ax3 = ax.twinx()\n",
    "ax3.plot(Th_2_Bins,ACC_Th2, color='black')#,THbin,CCC_Per)\n",
    "ax3.set_frame_on(False)\n",
    "ax3.set_ylabel('Accuracy', color='black',fontsize=15)\n",
    "\n",
    "\n",
    "\n",
    "for i,j in zip(Th_2_Bins,ACC_Th2):\n",
    "     #ax3.annotate((\"%0.2f\" % j),xy=(i-0.05,j), color='black')\n",
    "    #ax3.annotate((\"%0.2f\" % j),xy=(i-0.1,j), color='black')##################################\n",
    "    ax3.annotate((\"%0.3f\" % j),xy=(i,j+0.0065), color='black',fontsize=12)##################################\n",
    "    ax3.plot(i,j, marker='*', markersize=10, color=\"black\",alpha=0.2)\n",
    "    #ax3.annotate((\"%0.2f,%0.2f\" % (i,j)),xy=(i-0.05,j), color='green')\n",
    "    #ax3.annotate((\"%0.3f\" %j),xy=(i,j), color='green')\n",
    "    \n",
    "    \n",
    "# Move the last y-axis spine over to the right by 20% of the width of the axes\n",
    "ax3.spines['right'].set_position(('axes', 1.15))\n",
    "ax3.spines['right'].set_visible(True)\n",
    "\n",
    "# To make the border of the right-most axis visible, we need to turn the frame\n",
    "# on. This hides the other plots, however, so we need to turn its fill off.\n",
    "ax3.set_frame_on(True)\n",
    "ax3.patch.set_visible(False)\n",
    "\n",
    "#ax.plot(bins,np.linspace(0,1,11))\n",
    "plt.subplots_adjust(bottom=.15)\n",
    "plt.grid(False,which='both')\n",
    "ax.set_ylabel('Frequency',fontsize=15)\n",
    "ax.yaxis.label.set_color('Blue')\n",
    "plt.title(\"Clear speech\", fontsize=15)\n",
    "plt.tight_layout()\n",
    "# #Save the image\n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "                tick.label.set_fontsize(12)\n",
    "filename='StabilitySelection_clear'\n",
    "save_format='png'\n",
    "#print filename+'.'+save_format\n",
    "#pp='home/ralfahad/Pictures'\n",
    "#plt.savefig(filename+'.'+save_format,dpi=100)\n",
    "# plt.savefig(filename+'.'+save_format,dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,j in zip(Th_2_Bins,AUC_Th2):\n",
    "#     print i,j\n",
    "All_ACC=[]\n",
    "All_AUC=[]\n",
    "ALL_Bins=[]\n",
    "All_SV=[]\n",
    "NumberofElement=[]\n",
    "for i,j,k,l in zip(Th_2_Bins,ACC_Th2,AUC_Th2, SV):\n",
    "    Th2Index=np.squeeze(np.asarray(np.where(clf.scores_>=i)))\n",
    "#     print (\"{0:.2f}\".format(i)),(\"{0:.2f}\".format(j)),(\"{0:.2f}\".format(k)),len(Th2Index),(\"{0:.2f}\".format(l))\n",
    "#     NumberofElement.append(len(Th2Index))\n",
    "    print (\"{0:.2f}\".format(i)),(\"{0:.2f}\".format(j)),(\"{0:.2f}\".format(k)),len(Th2Index)\n",
    "    NumberofElement.append(len(Th2Index))\n",
    "    ALL_Bins.append(\"{0:.2f}\".format(i))\n",
    "    All_ACC.append(\"{0:.2f}\".format(j))\n",
    "    All_AUC.append(\"{0:.2f}\".format(k))\n",
    "    All_SV.append(\"{0:.2f}\".format(l))\n",
    "\n",
    "# Selected_Feature_Result=pd.concat([pd.DataFrame(ALL_Bins),pd.DataFrame(All_ACC),\n",
    "#            pd.DataFrame(All_AUC),pd.DataFrame(NumberofElement),pd.DataFrame(All_SV)],axis=1)\n",
    "# Selected_Feature_Result.columns=['Threshold','ACC','AUC','NoEle','SV']\n",
    "Selected_Feature_Result=pd.concat([pd.DataFrame(ALL_Bins),pd.DataFrame(All_ACC),\n",
    "           pd.DataFrame(All_AUC),pd.DataFrame(NumberofElement)],axis=1)\n",
    "Selected_Feature_Result.columns=['Threshold','ACC','AUC','NoEle']\n",
    "Selected_Feature_Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Th_2_Bins[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to chage gamma range . It is selecting too many features\n",
    "# Let 0.34 is our best Thr. TO get the index numer with this thr\n",
    "fealoc=np.squeeze(np.asarray(np.where(clf.scores_>=Th_2_Bins[4])))\n",
    "fealoc\n",
    "# len(fealoc)\n",
    "# Do you get it? yes > How about number of support of the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI=fealoc%68\n",
    "ROI\n",
    "np.unique(ROI,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(ROI))\n",
    "# np.unique(ROI,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for th in Th_2_Bins:\n",
    "    clf_Tune.fit(X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=th)))],y_train)\n",
    "    print X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=th)))].shape ,y_train.shape\n",
    "    print 'Finish tuning'\n",
    "    print float(len(clf_Tune.best_estimator_.support_vectors_))/X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=th)))].shape[0]*100\n",
    "# use tuned parameter on to get model\n",
    "#y_p = clf_Tune.best_estimator_.predict(X_test[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# float(len(clf_Tune.best_estimator_.support_vectors_))/X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=0.25)))].shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result it overfitting need to be less or equal to 40%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank the Feature Vectors as their importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank the Features according to the importance\n",
    "names=range(0,1428) # Feature names used as 1-1428 features\n",
    "cn=np.asarray(names) # converted as numpy.ndarray\n",
    "# print \"Features sorted by their score:\"\n",
    "b= sorted(zip(map(lambda x: round(x, 4), clf.scores_), cn), reverse=True)\n",
    "# print b\n",
    "bb=np.asarray(b)\n",
    "rakfe=bb[bb[:,0]>=Th_2_Bins[4]]\n",
    "# rakfe=bb[bb[:,0]>=.50]\n",
    "ROIs=rakfe[:,1]%68\n",
    "print ROIs\n",
    "print len(ROIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # b\n",
    "# ROIstime=np.floor(rakfe[:,1]/68)\n",
    "# timeloc=ROIstime*10\n",
    "# plt.hist(timeloc, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI\n",
    "print np.unique(ROI,return_counts=True)\n",
    "print len(np.unique(ROIs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Roiname=pd.read_csv(\"/home/sultan/EEG/Source_Level_Analysis/DK_atlas_Visualize_index_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nor=80\n",
    "shdkroi=Roiname['Desikan_Freesurfer_v5.1'] # \"Desikan_Freesurfer_v5.1\"  is the label of short name columns \n",
    "sdk=shdkroi[ROIs]# ROIs is the index of label\n",
    "# sdk.head(nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dkfull=Roiname['BrainMesh_ICBM152.nv']\n",
    "dk=dkfull[ROIs]\n",
    "print dk.head(nor)\n",
    "len(dk.head(nor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aa=pd.DataFrame(dk.values[0:nor])\n",
    "# aa.columns=['ROIs']\n",
    "# ab=aa.drop_duplicates()\n",
    "# Toprois=pd.DataFrame(ab.values)\n",
    "# print Toprois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rois1=bb[0:16,1]%68\n",
    "# pd.DataFrame(bb[0:16,0],shdkroi[rois1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saa=pd.DataFrame(sdk.values[0:nor])\n",
    "# saa.columns=['short ROIs']\n",
    "# sab=saa.drop_duplicates()\n",
    "# sToprois=pd.DataFrame(sab.values)\n",
    "# # print sToprois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nor1=14\n",
    "# sc=pd.DataFrame(bb[0:nor1,0])\n",
    "# sn=pd.concat([Toprois,sToprois,sc],axis=1)\n",
    "# sn.columns=['Fullname','ROIs short name', 'Feature score'] # sn: score and roi\n",
    "# # ddd=pd.DataFrame(bb[0:16,0],sToprois)\n",
    "# sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sn.to_csv('Top15fea.csv')\n",
    "# Th_2_Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=pd.DataFrame(dk.values[0:nor])\n",
    "aa.columns=['ROIs']\n",
    "Toprois=pd.DataFrame(aa.values)\n",
    "# print Toprois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saa=pd.DataFrame(sdk.values[0:nor])\n",
    "saa.columns=['short ROIs']\n",
    "sToprois=pd.DataFrame(saa.values)\n",
    "# print sToprois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nor1=75\n",
    "sc=pd.DataFrame(bb[0:nor1,0])\n",
    "sn=pd.concat([Toprois,sToprois,sc],axis=1)\n",
    "sn.columns=['Fullname','ROIs short name', ' Feature score'] # sn: score and roi\n",
    "# ddd=pd.DataFrame(bb[0:16,0],sToprois)\n",
    "sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allrois=sn.drop_duplicates(subset=['Fullname']) # Drop the duplicate name \n",
    "alluR=pd.DataFrame(allrois.values) #alluR is the unique ROIs\n",
    "alluR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alluR.to_csv('Top14.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wpath=\"/home/sultan/EEG/Source_Level_Analysis/SVM_results/\"\n",
    "# dall=alluR\n",
    "# dall.to_csv(wpath+'Clear_top_rois_0.4_stability.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clf.scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AllROIs_stability selection_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=clf.scores_\n",
    "allROIs=range(0,68)\n",
    "x=[];\n",
    "for i in allROIs:\n",
    "#     print i\n",
    "    r=np.arange(i,1428,68)\n",
    "    l=np.int_(r)\n",
    "#     ll=g[r]\n",
    "    ll=g[l]\n",
    "    x.append(ll)\n",
    "hh=pd.DataFrame(x)  \n",
    "t=np.linspace(0,200,21)\n",
    "yu=hh.values\n",
    "# yu=hh.values[[0,1,2,3,4,16],:]\n",
    "plt.plot(t,yu.T)\n",
    "plt.xlim(0, 200)\n",
    "plt.ylim(0,1)\n",
    "plt.grid(True)\n",
    "plt.ylabel(\"Stability scores\")\n",
    "plt.xlabel(\"Epoch time (ms)\")\n",
    "plt.title(\"Clear_all\")\n",
    "# plt.legend(leg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=np.linspace(0,200,21)\n",
    "yu=hh.values\n",
    "# yu=hh.values[[0,1,2,3,4,16],:]\n",
    "plt.plot(t,yu.T)\n",
    "plt.xlim(0, 200)\n",
    "plt.ylim(0,1)\n",
    "plt.grid(True)\n",
    "plt.ylabel(\"Stability scores\")\n",
    "plt.xlabel(\"Epoch time (ms)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top score selected ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leg=['rTP','rFUS', 'rPRC','lPRC','lSP']\n",
    "x=[];\n",
    "for i in ROIs:\n",
    "#     print i\n",
    "    r=np.arange(i,1428,68)\n",
    "    l=np.int_(r)\n",
    "#     ll=g[r]\n",
    "    ll=g[l]\n",
    "    x.append(ll)\n",
    "hh=pd.DataFrame(x)  \n",
    "t=np.linspace(0,200,21)\n",
    "yu=hh.values\n",
    "# yu=hh.values[0:9,:]\n",
    "# yu=hh.values[[0,1,2,3,4],:]\n",
    "plt.plot(t,yu.T)\n",
    "plt.xlim(0, 200)\n",
    "plt.ylim(0,1)\n",
    "plt.grid(True)\n",
    "plt.ylabel(\"Stability scores\")\n",
    "plt.xlabel(\"Epoch time (ms)\")\n",
    "plt.title(\"Clear\")\n",
    "# plt.legend(leg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leg=['rTP','rFUS', 'rPRC','lPRC','lSP']\n",
    "x=[];\n",
    "for i in ROIs:\n",
    "#     print i\n",
    "    r=np.arange(i,1428,68)\n",
    "    l=np.int_(r)\n",
    "#     ll=g[r]\n",
    "    ll=g[l]\n",
    "    x.append(ll)\n",
    "hh=pd.DataFrame(x)  \n",
    "t=np.linspace(0,200,21)\n",
    "yu=hh.values\n",
    "# yu=hh.values[0:9,:]\n",
    "yu=hh.values[[0,1,2,3,4],:]\n",
    "plt.plot(t,yu.T)\n",
    "plt.xlim(0, 200)\n",
    "plt.ylim(0,1)\n",
    "# plt.ylim(0.5,1)\n",
    "plt.grid(True)\n",
    "plt.ylabel(\"Stability scores\")\n",
    "plt.xlabel(\"Epoch time (ms)\")\n",
    "plt.title(\"Clear\")\n",
    "plt.legend(leg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leg=['rTP','rFUS', 'rPRC','lPRC','lSP']\n",
    "x=[];\n",
    "for i in ROIs:\n",
    "#     print i\n",
    "    r=np.arange(i,1428,68)\n",
    "    l=np.int_(r)\n",
    "#     ll=g[r]\n",
    "    ll=g[l]\n",
    "    x.append(ll)\n",
    "hh=pd.DataFrame(x)  \n",
    "t=np.linspace(0,200,21)\n",
    "yu=hh.values\n",
    "# yu=hh.values[0:9,:]\n",
    "yu=hh.values[[0,1,2],:]\n",
    "plt.plot(t,yu.T)\n",
    "plt.xlim(0, 200)\n",
    "plt.ylim(top=1)\n",
    "# plt.ylim(0.50,1)\n",
    "plt.grid(True)\n",
    "plt.ylabel(\"Stability scores\")\n",
    "plt.xlabel(\"Epoch time (ms)\")\n",
    "plt.title(\"Clear\")\n",
    "plt.legend(leg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROIs=range(0,68)\n",
    "x=[];\n",
    "for i in ROIs:\n",
    "#     print i\n",
    "    r=np.arange(i,1428,68)\n",
    "    l=np.int_(r)\n",
    "#     ll=g[r]\n",
    "    ll=g[l]\n",
    "    x.append(ll)\n",
    "hh=pd.DataFrame(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urois=[];\n",
    "names=range(0,1428) # Feature names used as 1-1428 features\n",
    "cn=np.asarray(names) # converted as numpy.ndarray\n",
    "# print \"Features sorted by their score:\"\n",
    "b= sorted(zip(map(lambda x: round(x, 4), clf.scores_), cn), reverse=True)\n",
    "# print b\n",
    "bb=np.asarray(b)\n",
    "for i in range(0,9):\n",
    "    rakfe=bb[bb[:,0]>=Th_2_Bins[i]]\n",
    "    # rakfe=bb[bb[:,0]>=.50]\n",
    "    ROIs=rakfe[:,1]%68\n",
    "#     print ROIs\n",
    "    print len(ROIs)\n",
    "    un= len(np.unique(ROIs));\n",
    "    urois.append(un)\n",
    "print urois    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_ACC=[]\n",
    "All_AUC=[]\n",
    "ALL_Bins=[]\n",
    "All_SV=[]\n",
    "All_UR=[];\n",
    "NumberofElement=[]\n",
    "for i,j,k,l,m in zip(Th_2_Bins,ACC_Th2,AUC_Th2, SV,urois):\n",
    "    Th2Index=np.squeeze(np.asarray(np.where(clf.scores_>=i)))\n",
    "#     print (\"{0:.2f}\".format(i)),(\"{0:.2f}\".format(j)),(\"{0:.2f}\".format(k)),len(Th2Index),(\"{0:.2f}\".format(l))\n",
    "#     NumberofElement.append(len(Th2Index))\n",
    "    print (\"{0:.2f}\".format(i)),(\"{0:.2f}\".format(j)),(\"{0:.2f}\".format(k)),len(Th2Index)\n",
    "    NumberofElement.append(len(Th2Index))\n",
    "    ALL_Bins.append(\"{0:.3f}\".format(i))\n",
    "    All_ACC.append(\"{0:.3f}\".format(j))\n",
    "    All_AUC.append(\"{0:.3f}\".format(k))\n",
    "    All_SV.append(\"{0:.3f}\".format(l))\n",
    "    All_UR.append(\"{0:.3f}\".format(m))\n",
    "\n",
    "# Selected_Feature_Result=pd.concat([pd.DataFrame(ALL_Bins),pd.DataFrame(All_ACC),\n",
    "#            pd.DataFrame(All_AUC),pd.DataFrame(NumberofElement),pd.DataFrame(All_SV)],axis=1)\n",
    "# Selected_Feature_Result.columns=['Threshold','ACC','AUC','NoEle','SV']\n",
    "Selected_Feature_Result=pd.concat([pd.DataFrame(ALL_Bins),pd.DataFrame(All_ACC),\n",
    "           pd.DataFrame(All_AUC),pd.DataFrame(NumberofElement),pd.DataFrame(All_UR)],axis=1)\n",
    "Selected_Feature_Result.columns=['Threshold','ACC','AUC','NoEle','UR']\n",
    "Selected_Feature_Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wpath=\"/home/sultan/EEG/Source_Level_Analysis/SVM_results/\"\n",
    "# dall=alluR\n",
    "# dall.to_csv(wpath+'Clear_top_rois_0.4_stability.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
