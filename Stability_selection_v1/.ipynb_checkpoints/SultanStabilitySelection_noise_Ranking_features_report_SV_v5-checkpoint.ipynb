{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,ShuffleSplit\n",
    "from sklearn import svm\n",
    "import sys\n",
    "# sys.path.append('/home/ralfahad/PythonUtility/PTE')\n",
    "# from PhaseTE_MF import PhaseTE_MF\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "import warnings\n",
    "from sklearn import svm, metrics,preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,roc_curve, auc,classification_report\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "from scipy.stats import norm\n",
    "# from sklearn import metrics\n",
    "# import seaborn as sns; sns.set(font_scale=1.2)\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>1418</th>\n",
       "      <th>1419</th>\n",
       "      <th>1420</th>\n",
       "      <th>1421</th>\n",
       "      <th>1422</th>\n",
       "      <th>1423</th>\n",
       "      <th>1424</th>\n",
       "      <th>1425</th>\n",
       "      <th>1426</th>\n",
       "      <th>1427</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.270001e-10</td>\n",
       "      <td>1.756739e-10</td>\n",
       "      <td>-1.582226e-10</td>\n",
       "      <td>-1.382528e-10</td>\n",
       "      <td>-1.566167e-10</td>\n",
       "      <td>-1.135809e-10</td>\n",
       "      <td>-1.100892e-10</td>\n",
       "      <td>-1.589276e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.110038e-10</td>\n",
       "      <td>1.152507e-10</td>\n",
       "      <td>-2.399226e-10</td>\n",
       "      <td>3.433448e-10</td>\n",
       "      <td>2.240594e-10</td>\n",
       "      <td>3.181698e-10</td>\n",
       "      <td>-1.644904e-10</td>\n",
       "      <td>1.001664e-10</td>\n",
       "      <td>-5.799119e-11</td>\n",
       "      <td>-4.880700e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.456352e-10</td>\n",
       "      <td>2.865467e-10</td>\n",
       "      <td>-2.532695e-10</td>\n",
       "      <td>-2.100140e-10</td>\n",
       "      <td>-2.099953e-10</td>\n",
       "      <td>-5.603980e-12</td>\n",
       "      <td>-2.883015e-10</td>\n",
       "      <td>1.572863e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>8.383168e-11</td>\n",
       "      <td>2.517060e-10</td>\n",
       "      <td>-8.620627e-11</td>\n",
       "      <td>2.037169e-10</td>\n",
       "      <td>2.261165e-10</td>\n",
       "      <td>3.166203e-10</td>\n",
       "      <td>-7.354289e-11</td>\n",
       "      <td>-5.902324e-11</td>\n",
       "      <td>-4.279494e-11</td>\n",
       "      <td>-3.508126e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 1430 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  label             0             1             2             3  \\\n",
       "0           0    0.0  4.270001e-10  1.756739e-10 -1.582226e-10 -1.382528e-10   \n",
       "1           1    0.0  5.456352e-10  2.865467e-10 -2.532695e-10 -2.100140e-10   \n",
       "\n",
       "              4             5             6             7      ...       \\\n",
       "0 -1.566167e-10 -1.135809e-10 -1.100892e-10 -1.589276e-10      ...        \n",
       "1 -2.099953e-10 -5.603980e-12 -2.883015e-10  1.572863e-11      ...        \n",
       "\n",
       "           1418          1419          1420          1421          1422  \\\n",
       "0  1.110038e-10  1.152507e-10 -2.399226e-10  3.433448e-10  2.240594e-10   \n",
       "1  8.383168e-11  2.517060e-10 -8.620627e-11  2.037169e-10  2.261165e-10   \n",
       "\n",
       "           1423          1424          1425          1426          1427  \n",
       "0  3.181698e-10 -1.644904e-10  1.001664e-10 -5.799119e-11 -4.880700e-10  \n",
       "1  3.166203e-10 -7.354289e-11 -5.902324e-11 -4.279494e-11 -3.508126e-10  \n",
       "\n",
       "[2 rows x 1430 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Load the metadata\n",
    "# path='/home/sultan/EEG/Source_Level_Analysis/25sam_10ms_noise_all_erp.csv'\n",
    "# path='/home/sultan/EEG/Source_Level_Analysis/50Tr10msnoise_all_erp.csv'\n",
    "# path=\"/home/sultan/EEG/Source_Level_Analysis/75sam_10ms_noise_all_erp.csv\"\n",
    "path=\"/home/sultan/EEG/Source_Level_Analysis/100sam_10ms_noise_all_erp.csv\"\n",
    "# path=\"/home/sultan/EEG/Source_Level_Analysis/125sam_10ms_noise_all_erp.csv\"\n",
    "Metadata=pd.read_csv(path)\n",
    "Metadata.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1804, 1428), (1804,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=Metadata.iloc[:,2:]\n",
    "y=Metadata['label']\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply SVM on Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma_range = np.logspace(-2, 2, 5)\n",
    "gamma_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1804, 1428) (1804,)\n",
      "[1.e-02 1.e-01 1.e+00 1.e+01 1.e+02] [0.01, 0.002, 0.00069, 0.0007, 0.0005]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "# X=preprocessing.scale(X)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "print X.shape,y.shape\n",
    "from sklearn.preprocessing import label_binarize\n",
    "y=label_binarize(np.asarray(y),[0,1])\n",
    "\n",
    "#C_range = np.logspace(-2, 10, 13)\n",
    "# gamma_range = np.logspace(-2, 2, 5)\n",
    "gamma_range = [0.01,0.002,0.00069,0.0007,0.0005]\n",
    "C_range = np.logspace(-2, 2, 5)\n",
    "#gamma_range = np.logspace(-2, 2, 5)\n",
    "\n",
    "print C_range,gamma_range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    }
   ],
   "source": [
    "#Classifiaction:\n",
    "# #Splitting\n",
    "from sklearn import preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,random_state=42)\n",
    "cv = ShuffleSplit(X_train.shape[0], test_size=0.20, random_state=42)\n",
    "\n",
    "# Define Classifier\n",
    "svr = svm.SVC(kernel='rbf')\n",
    "\n",
    "# Deffine tuning parameter\n",
    "C_range = np.logspace(-2, 2, 5)\n",
    "# gamma_range = np.logspace(-2, 2, 5)\n",
    "gamma_range = [0.01,0.002,0.00069,0.0007,0.0005]\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "clf_Tune = GridSearchCV(estimator=svr, cv=5, param_grid=param_grid,n_jobs=-1, verbose=True)\n",
    "clf_Tune.fit(X_train,y_train)\n",
    "print 'Finish tuning'      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p = clf_Tune.best_estimator_.predict(X_test)\n",
    "ACC=classification_report(y_test, y_p)\n",
    "print ACC\n",
    "ACC_AVG=accuracy_score(y_test, y_p)\n",
    "print ACC_AVG\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test,y_p)\n",
    "AUC_Th2_T=metrics.auc(fpr, tpr)\n",
    "print AUC_Th2_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p=clf_Tune.best_estimator_.predict(X_test)\n",
    "print \"Accuracy:\", clf_Tune.score(X_test, y_test)  \n",
    "# print pred\n",
    "# print y_test\n",
    "print \"support:\", len(clf_Tune.best_estimator_.support_vectors_)*100.0/(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print 'Validation accuracy={}, best {}' .format(clf_Tune.best_score_,clf_Tune.best_params_)\n",
    "clf_Tune.best_params_\n",
    "# clf_Tune.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Utility function to move the midpoint of a colormap to be around\n",
    "# # the values of interest.\n",
    "# from matplotlib.colors import Normalize\n",
    "# class MidpointNormalize(Normalize):\n",
    "\n",
    "#     def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "#         self.midpoint = midpoint\n",
    "#         Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "#     def __call__(self, value, clip=None):\n",
    "#         x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "#         return np.ma.masked_array(np.interp(value, x, y))\n",
    "    \n",
    "# scores = clf_Tune.cv_results_['mean_test_score'].reshape(len(C_range),len(gamma_range))\n",
    "# #print scores.shape,len(C_range),len(gamma_range)\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# #plt.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n",
    "# plt.imshow(scores, interpolation='nearest', cmap=plt.cm.hot, norm=MidpointNormalize(vmin=0.2, midpoint=0.92))\n",
    "# plt.xlabel('gamma')\n",
    "# plt.ylabel('C')\n",
    "# plt.colorbar()\n",
    "# plt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n",
    "# plt.yticks(np.arange(len(C_range)), C_range)\n",
    "# plt.title('Validation accuracy={}, best {}' .format(clf_Tune.best_score_,clf_Tune.best_params_))\n",
    "\n",
    "# #filename='ParameterTuning'\n",
    "# #save_format='png'\n",
    "# #print filename+'.'+save_format\n",
    "# #pp='home/ralfahad/Pictures'\n",
    "# #plt.savefig(filename+'.'+save_format,dpi=100)\n",
    "# #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Significant correlation with stability selections "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Processing \n",
    "X[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X=preprocessing.scale(X)\n",
    "# scaler = preprocessing.StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "print X.shape,y.shape\n",
    "from sklearn.preprocessing import label_binarize\n",
    "y=label_binarize(np.asarray(y),[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.var(X[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import (RandomizedLasso, lasso_stability_path,LassoLarsCV)\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "#Model Library\n",
    "from sklearn.linear_model import (RandomizedLasso, lasso_stability_path, LassoLarsCV)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, RandomizedLogisticRegression\n",
    "from sklearn import svm\n",
    "\n",
    "# Performance analysis library \n",
    "from sklearn.model_selection import KFold, cross_val_score, LeaveOneOut, cross_val_predict\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split # test train split\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    #warnings.simplefilter('ignore', UserWarning)\n",
    "    warnings.simplefilter('ignore', ConvergenceWarning)\n",
    "    lars_cv = LassoLarsCV(cv=5).fit(X, y)\n",
    "lars_cv.alphas_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the RandomizedLasso: we use a paths going down to .1*alpha_max\n",
    "# to avoid exploring the regime in which very noisy variables enter\n",
    "# the model\n",
    "alphas = np.linspace(lars_cv.alphas_[0], .1 * lars_cv.alphas_[0], 10)\n",
    "print alphas\n",
    "clf = RandomizedLasso(alpha=alphas, random_state=42,max_iter=1000).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Rank the Features according to the importance\n",
    "# names=range(0,1428) # Feature names used as 1-1428 features\n",
    "# cn=np.asarray(names) # converted as numpy.ndarray\n",
    "# # print \"Features sorted by their score:\"\n",
    "# b= sorted(zip(map(lambda x: round(x, 4), clf.scores_), cn), reverse=True)\n",
    "# bb=np.asarray(b)\n",
    "# rakfe=bb[bb[:,0]>0.34]\n",
    "# ROIs=rakfe[:,1]%68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print \"Features sorted by their score:\"\n",
    "# b= sorted(zip(map(lambda x: round(x, 4), clf.scores_), \n",
    "#                  cn), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bb=np.asarray(b)\n",
    "# # rf=np.where(bb[:,0]>0.7)\n",
    "# # ifea=np.squeeze(np.asarray(np.where(clf.scores_>=0.815)))\n",
    "# ra=bb[bb[:,0]>0.50]\n",
    "# # r=bb[e]\n",
    "# ra[:,1]%68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ind=np.where(clf.scores_>=0.710)\n",
    "# ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter\n",
    "data=clf.scores_\n",
    "fig, ax = plt.subplots()\n",
    "counts, bins, patches = ax.hist(data,10 ,edgecolor='gray')\n",
    "\n",
    "# Set the ticks to be at the edges of the bins.\n",
    "ax.set_xticks(bins)\n",
    "\n",
    "# Set the xaxis's tick labels to be formatted with 1 decimal place...\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter('%0.1f'))\n",
    "\n",
    "\n",
    "# Label the raw counts and the percentages below the x-axis...\n",
    "bin_centers = 0.5 * np.diff(bins) + bins[:-1]\n",
    "for count, x in zip(counts, bin_centers):\n",
    "    # Label the raw counts\n",
    "    ax.annotate(str(count), xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "        xytext=(0, -18), textcoords='offset points', va='top', ha='center')\n",
    "\n",
    "    # Label the percentages\n",
    "    percent = '%0.0f%%' % (100 * float(count) / counts.sum())\n",
    "    ax.annotate(percent, xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "        xytext=(0, -32), textcoords='offset points', va='top', ha='center')\n",
    "\n",
    "\n",
    "# Give ourselves some more room at the bottom of the plot\n",
    "plt.subplots_adjust(bottom=0.15)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Th_2_Bins_Index= np.where((bins<=0.9) & (bins>=0.1)) # take the bins within a range\n",
    "# print Th_2_Bins_Index\n",
    "print bins\n",
    "Th_2_Bins=bins[Th_2_Bins_Index]\n",
    "print Th_2_Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X=preprocessing.scale(X)\n",
    "print X.shape,y.shape\n",
    "from sklearn.preprocessing import label_binarize\n",
    "y=label_binarize(np.asarray(y),[0,1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:,1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train)#[:,np.squeeze(np.asarray(np.where(clf.scores_>=0.16)))].shape#,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C_range = np.logspace(-2, 2, 5)\n",
    "C_range = [1,2,4,6,8,10,12,15,16,20,30,40,100]\n",
    "# gamma_range = [0.01,0.002,0.00069,0.0007,0.0005]\n",
    "gamma_range = [0.1,0.15, 0.2,0.01,0.015,0.03,0.04, 0.05, 0.002,0.00069,0.0007,0.0005]\n",
    "# gamma_range = np.logspace(-2, 2, 5)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "#clf_Tune = GridSearchCV(estimator=svr, cv=1, param_grid=param_grid,n_jobs=-1)\n",
    "clf_Tune = GridSearchCV(estimator=svr, cv=5, param_grid=param_grid,n_jobs=-1, verbose=True)\n",
    "clf_Tune.fit(X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=Th_2_Bins[0])))],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use tuned parameter on to get model\n",
    "y_p = clf_Tune.best_estimator_.predict(X_test[:,np.squeeze(np.asarray(np.where(clf.scores_>=Th_2_Bins[0])))])\n",
    "\n",
    "print accuracy_score(y_test, y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#cv = ShuffleSplit(X_train.shape[0], test_size=0.2, random_state=42)\n",
    "\n",
    "# Define Classifier\n",
    "svr = svm.SVC(kernel='rbf')\n",
    "\n",
    "# Deffine tuning parameter\n",
    "# C_range = np.logspace(-2, 10, 13)\n",
    "# gamma_range = np.logspace(-9, 3, 13)\n",
    "\n",
    "C_range = np.logspace(-2, 2, 5)\n",
    "gamma_range = [0.01,0.002,0.0006,0.0007]\n",
    "# gamma_range = [0.1,0.01,0.002,0.0005,0.0006,0.0007,]\n",
    "# C_range = [20, 30,50]\n",
    "# C_range=[1000,1500]\n",
    "# C_range = [1,2,4,6,8,10,12,15,16,20,30,40,100]\n",
    "# gamma_range = [0.01,0.015, 0.018, 0.002,0.003,0.0004, 0.0005,0.0006,0.0007]; # 0.0007=1/1428 1428 = no. of features\n",
    "#gamma_range = np.logspace(-2, 2, 5)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "#clf_Tune = GridSearchCV(estimator=svr, cv=1, param_grid=param_grid,n_jobs=-1)\n",
    "clf_Tune = GridSearchCV(estimator=svr, cv=5, param_grid=param_grid,n_jobs=-1, verbose=True)\n",
    "##  Define LeaveOneOutCrossValidation\n",
    "#loocv = LeaveOneOut()\n",
    "ACC_Th2=[]\n",
    "AUC_Th2=[]\n",
    "SV=[]\n",
    "Bins=[]\n",
    "for i in Th_2_Bins:\n",
    "    print i\n",
    "    try:\n",
    "        print X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))].shape\n",
    "        \n",
    "        #Hyper parameter Tuning \n",
    "        clf_Tune.fit(X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))],y_train)\n",
    "        print X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))].shape ,y_train.shape\n",
    "        print 'Finish tuning'\n",
    "        print clf_Tune.best_estimator_\n",
    "\n",
    "        # use tuned parameter on to get model\n",
    "        y_p = clf_Tune.best_estimator_.predict(X_test[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))])\n",
    "\n",
    "        ACC_Th2_T=accuracy_score(y_test, y_p)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test,y_p)\n",
    "        AUC_Th2_T=metrics.auc(fpr, tpr)\n",
    "        print 'Shape', X_test[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))].shape\n",
    "        print 'ACC',ACC_Th2_T,AUC_Th2_T\n",
    "        SVe=float(len(clf_Tune.best_estimator_.support_vectors_))/X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))].shape[0]\n",
    "        print SVe\n",
    "        SV.append(SVe)\n",
    "#         print 'Report',classification_report(y_test, y_p)\n",
    "        ACC_Th2.append(ACC_Th2_T)\n",
    "        AUC_Th2.append(AUC_Th2_T)\n",
    "        Bins.append(i)\n",
    "    except:\n",
    "        print 'error at:',i\n",
    "    # false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_p)\n",
    "    # roc_auc_T = auc(false_positive_rate, true_positive_rate)\n",
    "    # print 'AUC',roc_auc_T\n",
    "    # AUC_Th2.append(roc_auc_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score(y_test, y_p)\n",
    "# MulticlassAuc(y_test,y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "#         ACC_Th2_T=accuracy_score(y_test, y_p)\n",
    "#         AUC_Th2_T=MulticlassAuc(y_test,y_p)\n",
    "#         print 'Shape', X_test[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))].shape\n",
    "#         print 'ACC',ACC_Th2_T,AUC_Th2_T\n",
    "#         ACC_Th2.append(ACC_Th2_T)\n",
    "#         AUC_Th2.append(AUC_Th2_T)\n",
    "#         Bins.append(i)\n",
    "#     except:\n",
    "#         print 'error at:',i\n",
    "#     # false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_p)\n",
    "#     # roc_auc_T = auc(false_positive_rate, true_positive_rate)\n",
    "#     # print 'AUC',roc_auc_T\n",
    "#     # AUC_Th2.append(roc_auc_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC_Th2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter\n",
    "Th_2_Bins=np.asarray(Bins)\n",
    "data=clf.scores_\n",
    "fig, ax = plt.subplots()\n",
    "fig.subplots_adjust(right=0.75)\n",
    "#counts, bins, patches = ax.hist(data,10 ,edgecolor='gray')\n",
    "counts, bins, patches = ax.hist(data,10,facecolor=\"None\",edgecolor='blue', lw=1)\n",
    "# Set the ticks to be at the edges of the bins.\n",
    "ax.set_xticks(bins)\n",
    "# Set the xaxis's tick labels to be formatted with 1 decimal place...\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter('%0.1f'))\n",
    "\n",
    "\n",
    "bin_centers = 0.5 * np.diff(bins) + bins[:-1]\n",
    "\n",
    "#show % value\n",
    "for count, x in zip(counts, bin_centers):\n",
    "    # Label the raw counts\n",
    "    ax.annotate(int(count), xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "        xytext=(0, -18), textcoords='offset points', va='top', ha='center')\n",
    "\n",
    "    # Label the percentages\n",
    "    percent = '%0.0f%%' % (100 * float(count) / counts.sum())\n",
    "    ax.annotate(percent, xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "        xytext=(0, -32), textcoords='offset points', va='top', ha='center')\n",
    "    \n",
    "    # Give ourselves some more room at the bottom of the plot\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(Th_2_Bins,AUC_Th2, color='red',ls='dashed' )#,THbin,CCC_Per)\n",
    "ax2.set_frame_on(False)\n",
    "ax2.set_ylabel('AUC', color='red')\n",
    "ax2.patch.set_visible(False)\n",
    "for i,j in zip(Th_2_Bins,AUC_Th2):\n",
    "    #ax2.annotate((\"%.2f\" % j),xy=(i+0.04,j-0.01), color ='red') ##############################\n",
    "    ax2.annotate((\"%.2f\" % j),xy=(i,j-0.01), color ='red') ##############################\n",
    "    ax2.plot(i,j, marker='o', markersize=7, color=\"red\")\n",
    "\n",
    "\n",
    "    \n",
    "ax3 = ax.twinx()\n",
    "ax3.plot(Th_2_Bins,ACC_Th2, color='black')#,THbin,CCC_Per)\n",
    "ax3.set_frame_on(False)\n",
    "ax3.set_ylabel('Accuracy', color='black')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i,j in zip(Th_2_Bins,ACC_Th2):\n",
    "     #ax3.annotate((\"%0.2f\" % j),xy=(i-0.05,j), color='black')\n",
    "    #ax3.annotate((\"%0.2f\" % j),xy=(i-0.1,j), color='black')##################################\n",
    "    ax3.annotate((\"%0.2f\" % j),xy=(i,j+0.01), color='black')##################################\n",
    "    ax3.plot(i,j, marker='*', markersize=10, color=\"black\")\n",
    "    #ax3.annotate((\"%0.2f,%0.2f\" % (i,j)),xy=(i-0.05,j), color='green')\n",
    "    #ax3.annotate((\"%0.3f\" %j),xy=(i,j), color='green')\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Move the last y-axis spine over to the right by 20% of the width of the axes\n",
    "ax3.spines['right'].set_position(('axes', 1.15))\n",
    "ax3.spines['right'].set_visible(True)\n",
    "\n",
    "# To make the border of the right-most axis visible, we need to turn the frame\n",
    "# on. This hides the other plots, however, so we need to turn its fill off.\n",
    "ax3.set_frame_on(True)\n",
    "ax3.patch.set_visible(False)\n",
    "\n",
    "\n",
    "#ax.plot(bins,np.linspace(0,1,11))\n",
    "plt.subplots_adjust(bottom=0.15)\n",
    "plt.grid(False,which='both')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.yaxis.label.set_color('Blue')\n",
    "plt.title('Noise')\n",
    "plt.tight_layout()\n",
    "# #Save the image\n",
    "\n",
    "filename='Corr_StabilitySelection_TH2'\n",
    "save_format='png'\n",
    "#print filename+'.'+save_format\n",
    "#pp='home/ralfahad/Pictures'\n",
    "#plt.savefig(filename+'.'+save_format,dpi=100)\n",
    "plt.savefig(filename+'.'+save_format,dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,j in zip(Th_2_Bins,AUC_Th2):\n",
    "#     print i,j\n",
    "All_ACC=[]\n",
    "All_AUC=[]\n",
    "ALL_Bins=[]\n",
    "All_SV=[]\n",
    "NumberofElement=[]\n",
    "for i,j,k,l in zip(Th_2_Bins,ACC_Th2,AUC_Th2, SV):\n",
    "    Th2Index=np.squeeze(np.asarray(np.where(clf.scores_>=i)))\n",
    "#     print (\"{0:.2f}\".format(i)),(\"{0:.2f}\".format(j)),(\"{0:.2f}\".format(k)),len(Th2Index),(\"{0:.2f}\".format(l))\n",
    "#     NumberofElement.append(len(Th2Index))\n",
    "    print (\"{0:.2f}\".format(i)),(\"{0:.2f}\".format(j)),(\"{0:.2f}\".format(k)),len(Th2Index)\n",
    "    NumberofElement.append(len(Th2Index))\n",
    "    ALL_Bins.append(\"{0:.2f}\".format(i))\n",
    "    All_ACC.append(\"{0:.2f}\".format(j))\n",
    "    All_AUC.append(\"{0:.2f}\".format(k))\n",
    "    All_SV.append(\"{0:.2f}\".format(l))\n",
    "\n",
    "# Selected_Feature_Result=pd.concat([pd.DataFrame(ALL_Bins),pd.DataFrame(All_ACC),\n",
    "#            pd.DataFrame(All_AUC),pd.DataFrame(NumberofElement),pd.DataFrame(All_SV)],axis=1)\n",
    "# Selected_Feature_Result.columns=['Threshold','ACC','AUC','NoEle','SV']\n",
    "Selected_Feature_Result=pd.concat([pd.DataFrame(ALL_Bins),pd.DataFrame(All_ACC),\n",
    "           pd.DataFrame(All_AUC),pd.DataFrame(NumberofElement)],axis=1)\n",
    "Selected_Feature_Result.columns=['Threshold','ACC','AUC','NoEle']\n",
    "Selected_Feature_Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Th_2_Bins[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to chage gamma range . It is selecting too many features\n",
    "# Let 0.34 is our best Thr. TO get the index numer with this thr\n",
    "fealoc=np.squeeze(np.asarray(np.where(clf.scores_>=Th_2_Bins[3])))\n",
    "fealoc\n",
    "print len(fealoc)\n",
    "print fealoc\n",
    "# Do you get it? yes> How about number of support of the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI=fealoc%68\n",
    "ROI\n",
    "np.unique(ROI,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(ROI))\n",
    "# np.unique(ROI,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for th in Th_2_Bins:\n",
    "    clf_Tune.fit(X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=th)))],y_train)\n",
    "    print X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=th)))].shape ,y_train.shape\n",
    "    print 'Finish tuning'\n",
    "    print float(len(clf_Tune.best_estimator_.support_vectors_))/X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=th)))].shape[0]*100\n",
    "# use tuned parameter on to get model\n",
    "#y_p = clf_Tune.best_estimator_.predict(X_test[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# float(len(clf_Tune.best_estimator_.support_vectors_))/X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=0.25)))].shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result it overfitting need to be less or equal to 40%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank the Feature Vectors as their importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank the Features according to the importance\n",
    "names=range(0,1428) # Feature names used as 1-1428 features\n",
    "cn=np.asarray(names) # converted as numpy.ndarray\n",
    "# print \"Features sorted by their score:\"\n",
    "b= sorted(zip(map(lambda x: round(x, 4), clf.scores_), cn), reverse=True)\n",
    "# print b\n",
    "bb=np.asarray(b)\n",
    "rakfe=bb[bb[:,0]>=Th_2_Bins[3]]\n",
    "ROIs=rakfe[:,1]%68\n",
    "# print ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # b\n",
    "# ROIstime=np.floor(rakfe[:,1]/68)\n",
    "# timeloc=ROIstime*10\n",
    "# plt.hist(timeloc, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI\n",
    "print np.unique(ROI,return_counts=True)\n",
    "print 'Unique ROIs:', len(np.unique(ROIs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Roiname=pd.read_csv(\"/home/sultan/EEG/Source_Level_Analysis/DK_atlas_Visualize_index_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nor=50\n",
    "shdkroi=Roiname['Desikan_Freesurfer_v5.1'] # \"Desikan_Freesurfer_v5.1\"  is the label of short name columns \n",
    "sdk=shdkroi[ROIs]# ROIs is the index of label\n",
    "# sdk.head(nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dkfull=Roiname['BrainMesh_ICBM152.nv']\n",
    "dk=dkfull[ROIs]\n",
    "print dk.head(nor)\n",
    "len(dk.head(nor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aa=pd.DataFrame(dk.values[0:nor])\n",
    "# aa.columns=['ROIs']\n",
    "# ab=aa.drop_duplicates()\n",
    "# Toprois=pd.DataFrame(ab.values)\n",
    "# print Toprois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rois1=bb[0:16,1]%68\n",
    "# pd.DataFrame(bb[0:16,0],shdkroi[rois1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saa=pd.DataFrame(sdk.values[0:nor])\n",
    "# saa.columns=['short ROIs']\n",
    "# sab=saa.drop_duplicates()\n",
    "# sToprois=pd.DataFrame(sab.values)\n",
    "# # print sToprois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nor1=22\n",
    "# sc=pd.DataFrame(bb[0:nor1,0])\n",
    "# sn=pd.concat([Toprois,sToprois,sc],axis=1)\n",
    "# sn.columns=['Fullname','ROIs short name', ' Feature score'] # sn: score and roi\n",
    "# # ddd=pd.DataFrame(bb[0:16,0],sToprois)\n",
    "# sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sn.to_csv('Top15fea_noise.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=pd.DataFrame(dk.values[0:nor])\n",
    "aa.columns=['ROIs']\n",
    "Toprois=pd.DataFrame(aa.values)\n",
    "# print Toprois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saa=pd.DataFrame(sdk.values[0:nor])\n",
    "saa.columns=['short ROIs']\n",
    "sToprois=pd.DataFrame(saa.values)\n",
    "# print sToprois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nor1=35\n",
    "sc=pd.DataFrame(bb[0:nor1,0])\n",
    "sn=pd.concat([Toprois,sToprois,sc],axis=1)\n",
    "sn.columns=['Fullname','ROIs short name', ' Feature score'] # sn: score and roi\n",
    "# ddd=pd.DataFrame(bb[0:16,0],sToprois)\n",
    "sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allrois=sn.drop_duplicates(subset=['Fullname']) # Drop the duplicate name \n",
    "alluR=pd.DataFrame(allrois.values) #alluR is the unique ROIs\n",
    "alluR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
