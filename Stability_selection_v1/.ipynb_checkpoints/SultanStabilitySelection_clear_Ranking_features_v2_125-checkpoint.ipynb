{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,ShuffleSplit\n",
    "from sklearn import svm\n",
    "import sys\n",
    "# sys.path.append('/home/ralfahad/PythonUtility/PTE')\n",
    "# from PhaseTE_MF import PhaseTE_MF\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "import warnings\n",
    "from sklearn import svm, metrics,preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,roc_curve, auc,classification_report\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "from scipy.stats import norm\n",
    "# from sklearn import metrics\n",
    "# import seaborn as sns; sns.set(font_scale=1.2)\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>1418</th>\n",
       "      <th>1419</th>\n",
       "      <th>1420</th>\n",
       "      <th>1421</th>\n",
       "      <th>1422</th>\n",
       "      <th>1423</th>\n",
       "      <th>1424</th>\n",
       "      <th>1425</th>\n",
       "      <th>1426</th>\n",
       "      <th>1427</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.796342e-10</td>\n",
       "      <td>-2.168943e-10</td>\n",
       "      <td>-1.003159e-10</td>\n",
       "      <td>-8.572146e-11</td>\n",
       "      <td>-6.510671e-11</td>\n",
       "      <td>3.655859e-11</td>\n",
       "      <td>-1.893814e-11</td>\n",
       "      <td>4.532950e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.244815e-10</td>\n",
       "      <td>2.281204e-10</td>\n",
       "      <td>5.523708e-13</td>\n",
       "      <td>3.882944e-10</td>\n",
       "      <td>2.316895e-10</td>\n",
       "      <td>3.596780e-10</td>\n",
       "      <td>2.255583e-10</td>\n",
       "      <td>-2.676447e-10</td>\n",
       "      <td>-7.681713e-11</td>\n",
       "      <td>-4.389414e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.220292e-10</td>\n",
       "      <td>1.423012e-11</td>\n",
       "      <td>-3.006853e-10</td>\n",
       "      <td>-2.818358e-10</td>\n",
       "      <td>4.462981e-11</td>\n",
       "      <td>1.095155e-10</td>\n",
       "      <td>-6.752202e-11</td>\n",
       "      <td>7.848902e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.401969e-11</td>\n",
       "      <td>-1.946118e-10</td>\n",
       "      <td>-8.172335e-11</td>\n",
       "      <td>-2.343086e-10</td>\n",
       "      <td>-1.130193e-10</td>\n",
       "      <td>-2.968451e-10</td>\n",
       "      <td>-6.467853e-12</td>\n",
       "      <td>4.677051e-10</td>\n",
       "      <td>1.519874e-10</td>\n",
       "      <td>3.110493e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 1430 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  label             0             1             2             3  \\\n",
       "0           0    0.0  1.796342e-10 -2.168943e-10 -1.003159e-10 -8.572146e-11   \n",
       "1           1    0.0  3.220292e-10  1.423012e-11 -3.006853e-10 -2.818358e-10   \n",
       "\n",
       "              4             5             6             7      ...       \\\n",
       "0 -6.510671e-11  3.655859e-11 -1.893814e-11  4.532950e-11      ...        \n",
       "1  4.462981e-11  1.095155e-10 -6.752202e-11  7.848902e-11      ...        \n",
       "\n",
       "           1418          1419          1420          1421          1422  \\\n",
       "0 -1.244815e-10  2.281204e-10  5.523708e-13  3.882944e-10  2.316895e-10   \n",
       "1 -2.401969e-11 -1.946118e-10 -8.172335e-11 -2.343086e-10 -1.130193e-10   \n",
       "\n",
       "           1423          1424          1425          1426          1427  \n",
       "0  3.596780e-10  2.255583e-10 -2.676447e-10 -7.681713e-11 -4.389414e-10  \n",
       "1 -2.968451e-10 -6.467853e-12  4.677051e-10  1.519874e-10  3.110493e-10  \n",
       "\n",
       "[2 rows x 1430 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the metadata\n",
    "# path='/home/sultan/EEG/Source_Level_Analysis/25sam_10ms_clear_all_erp.csv'\n",
    "# path=\"/home/sultan/EEG/Source_Level_Analysis/50tr10ms_all_clear_erp.csv\"\n",
    "# path=\"/home/sultan/EEG/Source_Level_Analysis/75sam_10ms_clear_all_erp.csv\"\n",
    "# path=\"/home/sultan/EEG/Source_Level_Analysis/100sam_10ms_clear_all_erp.csv\"\n",
    "path=\"/home/sultan/EEG/Source_Level_Analysis/125sam_10ms_clear_all_erp.csv\"\n",
    "Metadata=pd.read_csv(path)\n",
    "Metadata.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1479, 1428), (1479,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=Metadata.iloc[:,2:]\n",
    "y=Metadata['label']\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply SVM on Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma_range = np.logspace(-2, 2, 5)\n",
    "gamma_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1479, 1428) (1479,)\n",
      "[1.e-02 1.e-01 1.e+00 1.e+01 1.e+02] [0.01, 0.002, 0.0006, 0.0007]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "# X=preprocessing.scale(X)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "print X.shape,y.shape\n",
    "from sklearn.preprocessing import label_binarize\n",
    "y=label_binarize(np.asarray(y),[0,1])\n",
    "\n",
    "#C_range = np.logspace(-2, 10, 13)\n",
    "# gamma_range = np.logspace(-2, 2, 5)\n",
    "gamma_range = [0.01,0.002,0.0006,0.0007]\n",
    "C_range = np.logspace(-2, 2, 5)\n",
    "#gamma_range = np.logspace(-2, 2, 5)\n",
    "\n",
    "print C_range,gamma_range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   52.8s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c47989548833>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mC_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mclf_Tune\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mclf_Tune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'Finish tuning'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    638\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    639\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 640\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Classifiaction:\n",
    "# #Splitting\n",
    "from sklearn import preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,random_state=42)\n",
    "cv = ShuffleSplit(X_train.shape[0], test_size=0.20, random_state=42)\n",
    "\n",
    "# Define Classifier\n",
    "svr = svm.SVC(kernel='rbf')\n",
    "\n",
    "# Deffine tuning parameter\n",
    "C_range = np.logspace(-2, 2, 5)\n",
    "# gamma_range = np.logspace(-2, 2, 5)\n",
    "# gamma_range = [0.01,0.002,0.00069,0.0007,0.0005]\n",
    "gamma_range = [0.01,0.002,0.0006,0.0007]\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "clf_Tune = GridSearchCV(estimator=svr, cv=5, param_grid=param_grid,n_jobs=-1, verbose=True)\n",
    "clf_Tune.fit(X_train,y_train)\n",
    "print 'Finish tuning'      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p = clf_Tune.best_estimator_.predict(X_test)\n",
    "ACC=classification_report(y_test, y_p)\n",
    "print ACC\n",
    "ACC_AVG=accuracy_score(y_test, y_p)\n",
    "print ACC_AVG\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test,y_p)\n",
    "AUC_Th2_T=metrics.auc(fpr, tpr)\n",
    "print AUC_Th2_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p=clf_Tune.best_estimator_.predict(X_test)\n",
    "print \"Accuracy:\", clf_Tune.score(X_test, y_test)  \n",
    "# print pred\n",
    "# print y_test\n",
    "print \"support:\", len(clf_Tune.best_estimator_.support_vectors_)*100.0/(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print 'Validation accuracy={}, best {}' .format(clf_Tune.best_score_,clf_Tune.best_params_)\n",
    "clf_Tune.best_params_\n",
    "# clf_Tune.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Utility function to move the midpoint of a colormap to be around\n",
    "# # the values of interest.\n",
    "# from matplotlib.colors import Normalize\n",
    "# class MidpointNormalize(Normalize):\n",
    "\n",
    "#     def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "#         self.midpoint = midpoint\n",
    "#         Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "#     def __call__(self, value, clip=None):\n",
    "#         x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "#         return np.ma.masked_array(np.interp(value, x, y))\n",
    "    \n",
    "# scores = clf_Tune.cv_results_['mean_test_score'].reshape(len(C_range),len(gamma_range))\n",
    "# #print scores.shape,len(C_range),len(gamma_range)\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# #plt.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n",
    "# plt.imshow(scores, interpolation='nearest', cmap=plt.cm.hot, norm=MidpointNormalize(vmin=0.2, midpoint=0.92))\n",
    "# plt.xlabel('gamma')\n",
    "# plt.ylabel('C')\n",
    "# plt.colorbar()\n",
    "# plt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n",
    "# plt.yticks(np.arange(len(C_range)), C_range)\n",
    "# plt.title('Validation accuracy={}, best {}' .format(clf_Tune.best_score_,clf_Tune.best_params_))\n",
    "\n",
    "# #filename='ParameterTuning'\n",
    "# #save_format='png'\n",
    "# #print filename+'.'+save_format\n",
    "# #pp='home/ralfahad/Pictures'\n",
    "# #plt.savefig(filename+'.'+save_format,dpi=100)\n",
    "# #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Significant correlation with stability selections "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Processing \n",
    "X[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X=preprocessing.scale(X)\n",
    "# scaler = preprocessing.StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "print X.shape,y.shape\n",
    "from sklearn.preprocessing import label_binarize\n",
    "y=label_binarize(np.asarray(y),[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.var(X[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import (RandomizedLasso, lasso_stability_path,LassoLarsCV)\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "#Model Library\n",
    "from sklearn.linear_model import (RandomizedLasso, lasso_stability_path, LassoLarsCV)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, RandomizedLogisticRegression\n",
    "from sklearn import svm\n",
    "\n",
    "# Performance analysis library \n",
    "from sklearn.model_selection import KFold, cross_val_score, LeaveOneOut, cross_val_predict\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split # test train split\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    #warnings.simplefilter('ignore', UserWarning)\n",
    "    warnings.simplefilter('ignore', ConvergenceWarning)\n",
    "    lars_cv = LassoLarsCV(cv=5).fit(X, y)\n",
    "lars_cv.alphas_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the RandomizedLasso: we use a paths going down to .1*alpha_max\n",
    "# to avoid exploring the regime in which very noisy variables enter\n",
    "# the model\n",
    "alphas = np.linspace(lars_cv.alphas_[0], .1 * lars_cv.alphas_[0], 10)\n",
    "print alphas\n",
    "clf = RandomizedLasso(alpha=alphas, random_state=42,max_iter=10000).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Rank the Features according to the importance\n",
    "# names=range(0,1428) # Feature names used as 1-1428 features\n",
    "# cn=np.asarray(names) # converted as numpy.ndarray\n",
    "# # print \"Features sorted by their score:\"\n",
    "# b= sorted(zip(map(lambda x: round(x, 4), clf.scores_), cn), reverse=True)\n",
    "# bb=np.asarray(b)\n",
    "# rakfe=bb[bb[:,0]>0.34]\n",
    "# ROIs=rakfe[:,1]%68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print \"Features sorted by their score:\"\n",
    "# b= sorted(zip(map(lambda x: round(x, 4), clf.scores_), \n",
    "#                  cn), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bb=np.asarray(b)\n",
    "# # rf=np.where(bb[:,0]>0.7)\n",
    "# # ifea=np.squeeze(np.asarray(np.where(clf.scores_>=0.815)))\n",
    "# ra=bb[bb[:,0]>0.50]\n",
    "# # r=bb[e]\n",
    "# ra[:,1]%68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ind=np.where(clf.scores_>=0.710)\n",
    "# ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter\n",
    "data=clf.scores_\n",
    "fig, ax = plt.subplots()\n",
    "counts, bins, patches = ax.hist(data,10 ,edgecolor='gray')\n",
    "\n",
    "# Set the ticks to be at the edges of the bins.\n",
    "ax.set_xticks(bins)\n",
    "\n",
    "# Set the xaxis's tick labels to be formatted with 1 decimal place...\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter('%0.1f'))\n",
    "\n",
    "\n",
    "# Label the raw counts and the percentages below the x-axis...\n",
    "bin_centers = 0.5 * np.diff(bins) + bins[:-1]\n",
    "for count, x in zip(counts, bin_centers):\n",
    "    # Label the raw counts\n",
    "    ax.annotate(str(count), xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "        xytext=(0, -18), textcoords='offset points', va='top', ha='center')\n",
    "\n",
    "    # Label the percentages\n",
    "    percent = '%0.0f%%' % (100 * float(count) / counts.sum())\n",
    "    ax.annotate(percent, xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "        xytext=(0, -32), textcoords='offset points', va='top', ha='center')\n",
    "\n",
    "\n",
    "# Give ourselves some more room at the bottom of the plot\n",
    "plt.subplots_adjust(bottom=0.15)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Th_2_Bins_Index= np.where((bins<=0.9) & (bins>=0.1)) # take the bins within a range\n",
    "print bins\n",
    "Th_2_Bins=bins[Th_2_Bins_Index]\n",
    "print Th_2_Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X=preprocessing.scale(X)\n",
    "print X.shape,y.shape\n",
    "from sklearn.preprocessing import label_binarize\n",
    "y=label_binarize(np.asarray(y),[0,1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:,1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train)#[:,np.squeeze(np.asarray(np.where(clf.scores_>=0.16)))].shape#,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_range = np.logspace(-2, 2, 5)\n",
    "# gamma_range = [0.01,0.002,0.00069,0.0007,0.0005]\n",
    "gamma_range = [0.01,0.002,0.0006,0.0007]\n",
    "# gamma_range = np.logspace(-2, 2, 5)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "#clf_Tune = GridSearchCV(estimator=svr, cv=1, param_grid=param_grid,n_jobs=-1)\n",
    "clf_Tune = GridSearchCV(estimator=svr, cv=5, param_grid=param_grid,n_jobs=-1, verbose=True)\n",
    "clf_Tune.fit(X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=0.16)))],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use tuned parameter on to get model\n",
    "y_p = clf_Tune.best_estimator_.predict(X_test[:,np.squeeze(np.asarray(np.where(clf.scores_>=0.16)))])\n",
    "\n",
    "print accuracy_score(y_test, y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#cv = ShuffleSplit(X_train.shape[0], test_size=0.2, random_state=42)\n",
    "\n",
    "# Define Classifier\n",
    "svr = svm.SVC(kernel='rbf')\n",
    "\n",
    "# Deffine tuning parameter\n",
    "# C_range = np.logspace(-2, 10, 13)\n",
    "# gamma_range = np.logspace(-9, 3, 13)\n",
    "\n",
    "C_range = np.logspace(-2, 2, 5)\n",
    "# gamma_range = [0.01,0.002,0.00069,0.0007,0.0005]\n",
    "gamma_range = [0.01,0.002,0.0006,0.0007]\n",
    "#gamma_range = np.logspace(-2, 2, 5)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "#clf_Tune = GridSearchCV(estimator=svr, cv=1, param_grid=param_grid,n_jobs=-1)\n",
    "clf_Tune = GridSearchCV(estimator=svr, cv=5, param_grid=param_grid,n_jobs=-1, verbose=True)\n",
    "##  Define LeaveOneOutCrossValidation\n",
    "#loocv = LeaveOneOut()\n",
    "ACC_Th2=[]\n",
    "AUC_Th2=[]\n",
    "Bins=[]\n",
    "for i in Th_2_Bins:\n",
    "    print i\n",
    "    try:\n",
    "        print X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))].shape\n",
    "        \n",
    "        #Hyper parameter Tuning \n",
    "        clf_Tune.fit(X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))],y_train)\n",
    "        print X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))].shape ,y_train.shape\n",
    "        print 'Finish tuning'\n",
    "\n",
    "        # use tuned parameter on to get model\n",
    "        y_p = clf_Tune.best_estimator_.predict(X_test[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))])\n",
    "\n",
    "        ACC_Th2_T=accuracy_score(y_test, y_p)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test,y_p)\n",
    "        AUC_Th2_T=metrics.auc(fpr, tpr)\n",
    "        print 'Shape', X_test[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))].shape\n",
    "        print 'ACC',ACC_Th2_T,AUC_Th2_T\n",
    "        print float(len(clf_Tune.best_estimator_.support_vectors_))/X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))].shape[0]*100\n",
    "#         print 'Report',classification_report(y_test, y_p)\n",
    "        ACC_Th2.append(ACC_Th2_T)\n",
    "        AUC_Th2.append(AUC_Th2_T)\n",
    "        Bins.append(i)\n",
    "    except:\n",
    "        print 'error at:',i\n",
    "    # false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_p)\n",
    "    # roc_auc_T = auc(false_positive_rate, true_positive_rate)\n",
    "    # print 'AUC',roc_auc_T\n",
    "    # AUC_Th2.append(roc_auc_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score(y_test, y_p)\n",
    "# MulticlassAuc(y_test,y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "#         ACC_Th2_T=accuracy_score(y_test, y_p)\n",
    "#         AUC_Th2_T=MulticlassAuc(y_test,y_p)\n",
    "#         print 'Shape', X_test[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))].shape\n",
    "#         print 'ACC',ACC_Th2_T,AUC_Th2_T\n",
    "#         ACC_Th2.append(ACC_Th2_T)\n",
    "#         AUC_Th2.append(AUC_Th2_T)\n",
    "#         Bins.append(i)\n",
    "#     except:\n",
    "#         print 'error at:',i\n",
    "#     # false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_p)\n",
    "#     # roc_auc_T = auc(false_positive_rate, true_positive_rate)\n",
    "#     # print 'AUC',roc_auc_T\n",
    "#     # AUC_Th2.append(roc_auc_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC_Th2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter\n",
    "Th_2_Bins=np.asarray(Bins)\n",
    "data=clf.scores_\n",
    "fig, ax = plt.subplots()\n",
    "fig.subplots_adjust(right=0.75)\n",
    "#counts, bins, patches = ax.hist(data,10 ,edgecolor='gray')\n",
    "counts, bins, patches = ax.hist(data,10,facecolor=\"None\",edgecolor='blue', lw=1)\n",
    "# Set the ticks to be at the edges of the bins.\n",
    "ax.set_xticks(bins)\n",
    "# Set the xaxis's tick labels to be formatted with 1 decimal place...\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter('%0.1f'))\n",
    "\n",
    "\n",
    "bin_centers = 0.5 * np.diff(bins) + bins[:-1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#show % value\n",
    "for count, x in zip(counts, bin_centers):\n",
    "    # Label the raw counts\n",
    "    ax.annotate(int(count), xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "        xytext=(0, -18), textcoords='offset points', va='top', ha='center')\n",
    "\n",
    "    # Label the percentages\n",
    "    percent = '%0.0f%%' % (100 * float(count) / counts.sum())\n",
    "    ax.annotate(percent, xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "        xytext=(0, -32), textcoords='offset points', va='top', ha='center')\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Give ourselves some more room at the bottom of the plot\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(Th_2_Bins,AUC_Th2, color='red',ls='dashed' )#,THbin,CCC_Per)\n",
    "ax2.set_frame_on(False)\n",
    "ax2.set_ylabel('AUC', color='red')\n",
    "ax2.patch.set_visible(False)\n",
    "for i,j in zip(Th_2_Bins,AUC_Th2):\n",
    "    #ax2.annotate((\"%.2f\" % j),xy=(i+0.04,j-0.01), color ='red') ##############################\n",
    "    ax2.annotate((\"%.2f\" % j),xy=(i,j-0.01), color ='red') ##############################\n",
    "    ax2.plot(i,j, marker='o', markersize=7, color=\"red\")\n",
    "\n",
    "\n",
    "    \n",
    "ax3 = ax.twinx()\n",
    "ax3.plot(Th_2_Bins,ACC_Th2, color='black')#,THbin,CCC_Per)\n",
    "ax3.set_frame_on(False)\n",
    "ax3.set_ylabel('Accuracy', color='black')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i,j in zip(Th_2_Bins,ACC_Th2):\n",
    "     #ax3.annotate((\"%0.2f\" % j),xy=(i-0.05,j), color='black')\n",
    "    #ax3.annotate((\"%0.2f\" % j),xy=(i-0.1,j), color='black')##################################\n",
    "    ax3.annotate((\"%0.2f\" % j),xy=(i,j+0.01), color='black')##################################\n",
    "    ax3.plot(i,j, marker='*', markersize=10, color=\"black\")\n",
    "    #ax3.annotate((\"%0.2f,%0.2f\" % (i,j)),xy=(i-0.05,j), color='green')\n",
    "    #ax3.annotate((\"%0.3f\" %j),xy=(i,j), color='green')\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Move the last y-axis spine over to the right by 20% of the width of the axes\n",
    "ax3.spines['right'].set_position(('axes', 1.15))\n",
    "ax3.spines['right'].set_visible(True)\n",
    "\n",
    "# To make the border of the right-most axis visible, we need to turn the frame\n",
    "# on. This hides the other plots, however, so we need to turn its fill off.\n",
    "ax3.set_frame_on(True)\n",
    "ax3.patch.set_visible(False)\n",
    "\n",
    "\n",
    "#ax.plot(bins,np.linspace(0,1,11))\n",
    "plt.subplots_adjust(bottom=0.15)\n",
    "plt.grid(False,which='both')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.yaxis.label.set_color('Blue')\n",
    "plt.tight_layout()\n",
    "# #Save the image\n",
    "\n",
    "filename='Corr_StabilitySelection_TH2'\n",
    "save_format='png'\n",
    "#print filename+'.'+save_format\n",
    "#pp='home/ralfahad/Pictures'\n",
    "#plt.savefig(filename+'.'+save_format,dpi=100)\n",
    "plt.savefig(filename+'.'+save_format,dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,j in zip(Th_2_Bins,AUC_Th2):\n",
    "#     print i,j\n",
    "All_ACC=[]\n",
    "All_AUC=[]\n",
    "ALL_Bins=[]\n",
    "NumberofElement=[]\n",
    "for i,j,k in zip(Th_2_Bins,ACC_Th2,AUC_Th2):\n",
    "    Th2Index=np.squeeze(np.asarray(np.where(clf.scores_>=i)))\n",
    "    print (\"{0:.2f}\".format(i)),(\"{0:.2f}\".format(j)),(\"{0:.2f}\".format(k)),len(Th2Index)\n",
    "    NumberofElement.append(len(Th2Index))\n",
    "    ALL_Bins.append(\"{0:.2f}\".format(i))\n",
    "    All_ACC.append(\"{0:.2f}\".format(j))\n",
    "    All_AUC.append(\"{0:.2f}\".format(k))\n",
    "\n",
    "Selected_Feature_Result=pd.concat([pd.DataFrame(ALL_Bins),pd.DataFrame(All_ACC),\n",
    "           pd.DataFrame(All_AUC),pd.DataFrame(NumberofElement)],axis=1)\n",
    "Selected_Feature_Result.columns=['Threshold','ACC','AUC','NoEle']\n",
    "Selected_Feature_Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to chage gamma range . It is selecting too many features\n",
    "\n",
    "# Let 0.34 is our best Thr. TO get the index numer with this thr\n",
    "\n",
    "\n",
    "fealoc=np.squeeze(np.asarray(np.where(clf.scores_>=0.34)))\n",
    "fealoc\n",
    "\n",
    "# Do you get it? yes > How about number of support of the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI=fealoc%68\n",
    "ROI\n",
    "np.unique(ROI,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(ROI))\n",
    "# np.unique(ROI,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for th in [0.17, 0.26,0.34,0.42]:\n",
    "    clf_Tune.fit(X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=th)))],y_train)\n",
    "    print X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=th)))].shape ,y_train.shape\n",
    "    print 'Finish tuning'\n",
    "    print float(len(clf_Tune.best_estimator_.support_vectors_))/X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=th)))].shape[0]*100\n",
    "# use tuned parameter on to get model\n",
    "#y_p = clf_Tune.best_estimator_.predict(X_test[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# float(len(clf_Tune.best_estimator_.support_vectors_))/X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=0.25)))].shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result it overfitting need to be less or equal to 40%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank the Feature Vectors as their importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank the Features according to the importance\n",
    "names=range(0,1428) # Feature names used as 1-1428 features\n",
    "cn=np.asarray(names) # converted as numpy.ndarray\n",
    "# print \"Features sorted by their score:\"\n",
    "b= sorted(zip(map(lambda x: round(x, 4), clf.scores_), cn), reverse=True)\n",
    "bb=np.asarray(b)\n",
    "rakfe=bb[bb[:,0]>=0.34]\n",
    "ROIs=rakfe[:,1]%68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI\n",
    "print np.unique(ROI,return_counts=True)\n",
    "print len(np.unique(ROIs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Roiname=pd.read_csv(\"/home/sultan/EEG/Source_Level_Analysis/DK_atlas_Visualize_index_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shdkroi=Roiname['Desikan_Freesurfer_v5.1']\n",
    "sdk=shdkroi[ROIs]\n",
    "sdk.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dkfull=Roiname['BrainMesh_ICBM152.nv']\n",
    "dk=dkfull[ROIs]\n",
    "dk.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rakfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[0,1,7,8,68,1427]\n",
    "b=np.array(a)\n",
    "b%68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
