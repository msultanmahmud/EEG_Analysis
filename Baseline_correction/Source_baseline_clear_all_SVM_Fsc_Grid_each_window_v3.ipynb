{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm, metrics,preprocessing\n",
    "#from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,roc_curve, auc\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "from scipy.stats import norm\n",
    "# import seaborn as sns; sns.set(font_scale=1.2)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path='/home/sultan/EEG/Source_Level_Analysis/25sam_10ms_clear_all_erp.csv'\n",
    "# path='/home/sultan/EEG/Source_Level_Analysis/50tr10ms_all_clear_erp.csv'\n",
    "# path=\"/home/sultan/EEG/Source_Level_Analysis/75sam_10ms_clear_all_erp.csv\"\n",
    "# path=\"/home/sultan/EEG/Source_Level_Analysis/100sam_10ms_clear_all_erp.csv\"\n",
    "path=\"/home/sultan/EEG/Source_Level_Analysis/Baseline_100sam_10ms_clear_all_erp.csv\"\n",
    "dataset =pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xc=dataset.iloc[:,2:].values\n",
    "y=dataset.iloc[:,1].values\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X = scaler.fit_transform(Xc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## random state:\n",
    "rs=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.20, random_state=rs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((373, 1428), (373,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([148, 225]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test)\n",
    "np.unique(y_test,return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv=5\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# # parameters = {'kernel':['rbf'], 'C':[1, 6.5, 10,20,100,1000],'gamma':[0.01,2/1428.0,1/1428.0]}\n",
    "# parameters = {'kernel':['rbf'], 'C':[1, 6.5, 10,20,100,1000],'gamma':[0.01,0.002,0.00069,0.0007,0.0005]}\n",
    "# svc = svm.SVC()\n",
    "# clf = GridSearchCV(svc, parameters,cv=cv)\n",
    "# clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv=5\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# parameters = {'kernel':['rbf'], 'C':[0.90,1.00,1.25],'gamma':[3.0,3.25,3.25 ]}\n",
    "# svc = svm.SVC()\n",
    "# clf = GridSearchCV(svc, parameters,cv=cv)\n",
    "# clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Average Scores\n",
    "# #  print clf.cv_results_\n",
    "# # clf.best_estimator_\n",
    "# # np.mean\n",
    "# scores=clf.cv_results_['mean_test_score']\n",
    "# print(\"Accuracy:%0.3f (+/-%0.3f)\" %(scores.mean(), scores.std()*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pred=clf.best_estimator_.predict(X_test)\n",
    "# acc1=accuracy_score(y_test, pred)\n",
    "# print \"Accuracy:\", clf.score(X_test, y_test) \n",
    "# print acc1\n",
    "# # print pred\n",
    "# # print y_test\n",
    "# print \"support:\", len(clf.best_estimator_.support_vectors_)*100.0/(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf_mat=confusion_matrix(y_test,pred)\n",
    "# conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "# #target_names = ['class 0', 'class 1', 'class 2']\n",
    "# print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,pred)\n",
    "# roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "# roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpr, tpr, thresholds = metrics.roc_curve(y_test,pred)\n",
    "# roc_auc=metrics.auc(fpr, tpr)\n",
    "# roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv=5\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# parameters = {'kernel':['rbf'], 'C':[1],'gamma':[0.01 ]}\n",
    "# svc = svm.SVC()\n",
    "# clf = GridSearchCV(svc, parameters,cv=cv)\n",
    "# clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv=5\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# parameters = {'kernel':['rbf'], 'C':[1,5,10*.65,10**0.651,7,8],'gamma':[0.1,0.0005,0.000612,0.0006815,10**-3.20]}\n",
    "# svc = svm.SVC()\n",
    "# clf = GridSearchCV(svc, parameters,cv=cv)\n",
    "# clf.fit(X_train, y_train)\n",
    "# pred=clf.best_estimator_.predict(X_test)\n",
    "# print clf.score(X_test, y_test)  \n",
    "# # print pred\n",
    "# # print y_test\n",
    "# print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,pred)\n",
    "# roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "# roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred=clf.best_estimator_.predict(X_test)\n",
    "# print \"Accuracy:\", clf.score(X_test, y_test)  \n",
    "# # print pred\n",
    "# # print y_test\n",
    "# print \"support:\", len(clf.best_estimator_.support_vectors_)*100.0/(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred=clf.best_estimator_.predict(X_test)\n",
    "# clf.score(X_test, y_test)  \n",
    "# # print pred\n",
    "# # print y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k=0;j=68;\n",
    "# for i in range(0,21):\n",
    "#     print k,j\n",
    "#     k=k+68;j=j+68;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6032171581769437\n",
      "ROC 0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00       148\n",
      "        1.0       0.60      1.00      0.75       225\n",
      "\n",
      "avg / total       0.36      0.60      0.45       373\n",
      "\n",
      "0 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6836461126005362\n",
      "ROC 0.6684084084084084\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.60      0.59      0.60       148\n",
      "        1.0       0.74      0.74      0.74       225\n",
      "\n",
      "avg / total       0.68      0.68      0.68       373\n",
      "\n",
      "68 136\n",
      "Accuracy: 0.7345844504021448\n",
      "ROC 0.7360660660660661\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.64      0.74      0.69       148\n",
      "        1.0       0.81      0.73      0.77       225\n",
      "\n",
      "avg / total       0.74      0.73      0.74       373\n",
      "\n",
      "136 204\n",
      "Accuracy: 0.7319034852546917\n",
      "ROC 0.735\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.64      0.75      0.69       148\n",
      "        1.0       0.81      0.72      0.76       225\n",
      "\n",
      "avg / total       0.74      0.73      0.73       373\n",
      "\n",
      "204 272\n",
      "Accuracy: 0.7935656836461126\n",
      "ROC 0.7930480480480482\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.72      0.79      0.75       148\n",
      "        1.0       0.85      0.80      0.82       225\n",
      "\n",
      "avg / total       0.80      0.79      0.79       373\n",
      "\n",
      "272 340\n",
      "Accuracy: 0.8016085790884718\n",
      "ROC 0.7997147147147147\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.73      0.79      0.76       148\n",
      "        1.0       0.85      0.81      0.83       225\n",
      "\n",
      "avg / total       0.81      0.80      0.80       373\n",
      "\n",
      "340 408\n",
      "Accuracy: 0.8310991957104558\n",
      "ROC 0.8241591591591592\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.79      0.79       148\n",
      "        1.0       0.86      0.86      0.86       225\n",
      "\n",
      "avg / total       0.83      0.83      0.83       373\n",
      "\n",
      "408 476\n",
      "Accuracy: 0.7774798927613941\n",
      "ROC 0.7808708708708708\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.69      0.80      0.74       148\n",
      "        1.0       0.85      0.76      0.81       225\n",
      "\n",
      "avg / total       0.79      0.78      0.78       373\n",
      "\n",
      "476 544\n",
      "Accuracy: 0.7828418230563002\n",
      "ROC 0.7795345345345346\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.71      0.76      0.74       148\n",
      "        1.0       0.84      0.80      0.82       225\n",
      "\n",
      "avg / total       0.79      0.78      0.78       373\n",
      "\n",
      "544 612\n",
      "Accuracy: 0.7560321715817694\n",
      "ROC 0.7526876876876877\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.68      0.74      0.71       148\n",
      "        1.0       0.82      0.77      0.79       225\n",
      "\n",
      "avg / total       0.76      0.76      0.76       373\n",
      "\n",
      "612 680\n",
      "Accuracy: 0.7882037533512064\n",
      "ROC 0.7793543543543543\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.73      0.74      0.73       148\n",
      "        1.0       0.83      0.82      0.82       225\n",
      "\n",
      "avg / total       0.79      0.79      0.79       373\n",
      "\n",
      "680 748\n",
      "Accuracy: 0.7774798927613941\n",
      "ROC 0.7704654654654655\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.71      0.74      0.72       148\n",
      "        1.0       0.82      0.80      0.81       225\n",
      "\n",
      "avg / total       0.78      0.78      0.78       373\n",
      "\n",
      "748 816\n",
      "Accuracy: 0.7908847184986595\n",
      "ROC 0.7850450450450451\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.73      0.76      0.74       148\n",
      "        1.0       0.84      0.81      0.82       225\n",
      "\n",
      "avg / total       0.79      0.79      0.79       373\n",
      "\n",
      "816 884\n",
      "Accuracy: 0.7560321715817694\n",
      "ROC 0.7538438438438437\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.67      0.74      0.71       148\n",
      "        1.0       0.82      0.76      0.79       225\n",
      "\n",
      "avg / total       0.76      0.76      0.76       373\n",
      "\n",
      "884 952\n",
      "Accuracy: 0.7721179624664879\n",
      "ROC 0.7706456456456455\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.69      0.76      0.73       148\n",
      "        1.0       0.83      0.78      0.80       225\n",
      "\n",
      "avg / total       0.78      0.77      0.77       373\n",
      "\n",
      "952 1020\n",
      "Accuracy: 0.7855227882037533\n",
      "ROC 0.7794444444444444\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.72      0.75      0.74       148\n",
      "        1.0       0.83      0.81      0.82       225\n",
      "\n",
      "avg / total       0.79      0.79      0.79       373\n",
      "\n",
      "1020 1088\n",
      "Accuracy: 0.7801608579088471\n",
      "ROC 0.7888738738738739\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.68      0.83      0.75       148\n",
      "        1.0       0.87      0.75      0.80       225\n",
      "\n",
      "avg / total       0.80      0.78      0.78       373\n",
      "\n",
      "1088 1156\n",
      "Accuracy: 0.7479892761394102\n",
      "ROC 0.7425525525525525\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.67      0.72      0.69       148\n",
      "        1.0       0.80      0.77      0.79       225\n",
      "\n",
      "avg / total       0.75      0.75      0.75       373\n",
      "\n",
      "1156 1224\n",
      "Accuracy: 0.7211796246648794\n",
      "ROC 0.7053003003003004\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.65      0.63      0.64       148\n",
      "        1.0       0.76      0.78      0.77       225\n",
      "\n",
      "avg / total       0.72      0.72      0.72       373\n",
      "\n",
      "1224 1292\n",
      "Accuracy: 0.6943699731903485\n",
      "ROC 0.6877027027027027\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.61      0.66      0.63       148\n",
      "        1.0       0.76      0.72      0.74       225\n",
      "\n",
      "avg / total       0.70      0.69      0.70       373\n",
      "\n",
      "1292 1360\n",
      "Accuracy: 0.7184986595174263\n",
      "ROC 0.7238888888888889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.62      0.75      0.68       148\n",
      "        1.0       0.81      0.70      0.75       225\n",
      "\n",
      "avg / total       0.73      0.72      0.72       373\n",
      "\n",
      "1360 1428\n"
     ]
    }
   ],
   "source": [
    "nstep=(X_train.shape[1]/68); ##number of step\n",
    "k=0;j=68; acgw=[];pmw=[];aucw=[];\n",
    "for i in range(0,21):\n",
    "    cv=5\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    parameters = {'kernel':['rbf'], 'C':[1, 10,20,30, 40, 50, 60, 70, 90,100,1000],'gamma':[0.01,0.0147, 0.016, 0.019, 0.021, 2/1428.0,1/1428.0]}\n",
    "    svc = svm.SVC()\n",
    "    clf = GridSearchCV(svc, parameters,cv=cv)\n",
    "    clf.fit(X_train[:,k:j], y_train)\n",
    "    pred=clf.best_estimator_.predict(X_test[:,k:j])\n",
    "    acc=clf.score(X_test[:,k:j], y_test)\n",
    "    acgw=np.append(acgw,acc)\n",
    "    print \"Accuracy:\",acc\n",
    "    perf=classification_report(y_test, pred)\n",
    "    pmw.append(perf)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test,pred)\n",
    "    roc_auc=metrics.auc(fpr, tpr)\n",
    "    roc_auc\n",
    "    aucw.append(roc_auc)\n",
    "    print\"ROC\", roc_auc\n",
    "    print perf\n",
    "    print k,j\n",
    "    k=k+68;j=j+68;\n",
    "#     scores=clf.cv_results_['mean_test_score']\n",
    "#     print(\"Accuracy:%0.3f (+/-%0.3f)\" %(scores.mean(), scores.std()*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.000700280112045,\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yr=X_test[:,0:68]\n",
    "yr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset\n",
    "Xc=dataset.iloc[:,2:].values\n",
    "y=dataset.iloc[:,1].values\n",
    "# Xc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape\n",
    "np.max(acgw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hemisphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-b8877fe3941a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msvc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    638\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    639\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 640\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             train_scores = _score(estimator, X_train, y_train, scorer,\n\u001b[0;32m--> 492\u001b[0;31m                                   is_multimetric)\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \"\"\"\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36m_multimetric_score\u001b[0;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/metrics/scorer.pyc\u001b[0m in \u001b[0;36m_passthrough_scorer\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_passthrough_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;34m\"\"\"Function that wraps estimator.score\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \"\"\"\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \"\"\"\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseSVC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dense_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_dense_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobA_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobB_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvm_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             cache_size=self.cache_size)\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sparse_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "a=range(0,(X.shape[1]),2)\n",
    "d11=X[:,a];\n",
    "X_train, X_test, y_train, y_test = train_test_split(d11,y, test_size=.20, random_state=rs) \n",
    "cv=5\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# parameters = {'kernel':['rbf'], 'C':[1, 10,100,1000],'gamma':[0.01,2/1428.0,1/1428.0]}\n",
    "parameters = {'kernel':['rbf'], 'C':[1, 10,20,30, 40, 50, 60, 70, 90,100,1000],'gamma':[0.01,0.0147, 0.016, 0.019, 0.021, 2/1428.0,1/1428.0]}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters,cv=cv)\n",
    "clf.fit(X_train, y_train)\n",
    "pred=clf.best_estimator_.predict(X_test)\n",
    "print clf.score(X_test, y_test)  \n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test,pred)\n",
    "roc_auc=metrics.auc(fpr, tpr)\n",
    "roc_auc\n",
    "print roc_auc\n",
    "# print pred\n",
    "# print y_test\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=clf.best_estimator_.predict(X_test)\n",
    "print \"Accuracy:\", clf.score(X_test, y_test)  \n",
    "# print pred\n",
    "# print y_test\n",
    "print \"support:\", len(clf.best_estimator_.support_vectors_)*100.0/(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only 34 features \n",
    "parameters = {'kernel':['rbf'], 'C':[1, 10,20,30, 40, 50, 60, 70, 90,100,1000],'gamma':[0.015,0.025, 0.029, 0.030,0.035]}\n",
    "svc = svm.SVC()\n",
    "k=0;j=34; acgr=[];aucrh=[];pmrh=[];\n",
    "for i in range(0,21):\n",
    "    cv=5\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "#     parameters = {'kernel':['rbf'], 'C':[1, 10,100,1000],'gamma':[0.01,2/1428.0,1/1428.0]}\n",
    "    svc = svm.SVC()\n",
    "    clf = GridSearchCV(svc, parameters,cv=cv)\n",
    "    clf.fit(X_train[:,k:j], y_train)\n",
    "    pred=clf.best_estimator_.predict(X_test[:,k:j])\n",
    "    acc=clf.score(X_test[:,k:j], y_test)\n",
    "    acgr=np.append(acgr,acc)\n",
    "    print \"Accuracy:\", acc\n",
    "    perf=classification_report(y_test, pred)\n",
    "    pmrh.append(perf)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test,pred)\n",
    "    roc_auc=metrics.auc(fpr, tpr)\n",
    "    roc_auc\n",
    "    aucrh.append(roc_auc)\n",
    "    print \"ROC:\", roc_auc\n",
    "    print perf\n",
    "    print k,j\n",
    "    k=k+34;j=j+34;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=range(1,(X.shape[1]),2)\n",
    "d22=X[:,b];\n",
    "X_train, X_test, y_train, y_test = train_test_split(d22,y, test_size=.20, random_state=rs) \n",
    "cv=5\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# parameters = {'kernel':['rbf'], 'C':[1, 10,100,1000],'gamma':[0.01,2/1428.0,1/1428.0]}\n",
    "parameters = {'kernel':['rbf'], 'C':[1, 10,20,30, 40, 50, 60, 70, 90,100,1000],'gamma':[0.01,0.0147, 0.016, 0.019, 0.021, 2/1428.0,1/1428.0]}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters,cv=cv)\n",
    "clf.fit(X_train, y_train)\n",
    "pred=clf.best_estimator_.predict(X_test)\n",
    "# print clf.score(X_test, y_test)  \n",
    "# print pred\n",
    "# print y_test\n",
    "perf=classification_report(y_test, pred)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test,pred)\n",
    "roc_auc=metrics.auc(fpr, tpr)\n",
    "roc_auc\n",
    "print roc_auc\n",
    "print perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=clf.best_estimator_.predict(X_test)\n",
    "print \"Accuracy:\", clf.score(X_test, y_test)  \n",
    "# print pred\n",
    "# print y_test\n",
    "print \"support:\", len(clf.best_estimator_.support_vectors_)*100.0/(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acg=[];\n",
    "# for i in range(0,6,2):\n",
    "#     acg=np.append(acg,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0;j=34; acgl=[];auclh=[];pmlh=[];\n",
    "for i in range(0,21):\n",
    "    cv=5\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "#     parameters = {'kernel':['rbf'], 'C':[1, 10,100,1000],'gamma':[0.01,2/1428.0,1/1428.0]}\n",
    "    parameters = {'kernel':['rbf'], 'C':[1, 10,20,30, 40, 50, 60, 70, 90,100,1000],'gamma':[0.015,0.025, 0.029, 0.030,0.035]}\n",
    "    svc = svm.SVC()\n",
    "    clf = GridSearchCV(svc, parameters,cv=cv)\n",
    "    clf.fit(X_train[:,k:j], y_train)\n",
    "    pred=clf.best_estimator_.predict(X_test[:,k:j])\n",
    "    acc=clf.score(X_test[:,k:j], y_test)\n",
    "    acgl=np.append(acgl,acc)\n",
    "    print \"Accuracy:\", acc\n",
    "    perf=classification_report(y_test, pred)\n",
    "    pmlh.append(perf)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test,pred)\n",
    "    roc_auc=metrics.auc(fpr, tpr)\n",
    "    roc_auc\n",
    "    auclh.append(roc_auc)\n",
    "    print \"ROC:\", roc_auc\n",
    "    print perf\n",
    "    print k,j\n",
    "    k=k+34;j=j+34;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=np.linspace(0,200,21, endpoint=True)\n",
    "time=pd.DataFrame(t)\n",
    "# a=pd.concat([time,pd.DataFrame(acgw),pd.DataFrame(acgl),pd.DataFrame(acgr)],axis=1, keys=[ 'time',\"Whole\", \"LH\", \"RH\"])\n",
    "a=pd.concat([time,pd.DataFrame(acgw),pd.DataFrame(acgl),pd.DataFrame(acgr),],axis=1, keys=[ 'time',\"Whole\", \"LH\", \"RH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(acgl)\n",
    "np.max(a.iloc[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing the csv data all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wpath=\"/home/sultan/EEG/Source_Level_Analysis/SVM_results/\"\n",
    "# dall=a\n",
    "# dall.to_csv(wpath+'svm_res_100sam_10ms_clear_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_font = {'fontname':'Arial', 'size':'15'}\n",
    "#tw1=tad.iloc[1:,0];Acdw1=tad.iloc[1:,1];\n",
    "tw1=a.iloc[0:,0];Acdw=a.iloc[0:,1];Acdlh=a.iloc[0:,2];Acdrh=a.iloc[0:,3]\n",
    "# plt.plot(tw1,Acdw1,c='g')\n",
    "plt.plot(tw1,Acdw,'g',linewidth=2,marker='*')\n",
    "plt.plot(tw1, Acdlh,'--r',linewidth=2,marker='o')\n",
    "plt.plot(tw1, Acdrh,'--b',linewidth=2,marker='x')\n",
    "plt.title(\"100ms_10ms_clear\")\n",
    "plt.xlim(0,200)\n",
    "# plt.plot(tw1,Acdw1, 'k--', label='noise')\n",
    "# plt.xlabel('Time (ms)',**axis_font)\n",
    "# plt.ylabel('Accuracy (%)',**axis_font)\n",
    "# plt.title('Whole brain',**axis_font)\n",
    "# plt.yticks(**axis_font)\n",
    "# plt.xticks(**axis_font)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.gca().legend(('Whole','LH','RH'),fontsize=16,loc='best')\n",
    "# plt.savefig('whole_acc_timem.eps')\n",
    "# plt.savefig('whole_acc_timem.tif')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tttt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-180ce7c87868>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtttt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tttt' is not defined"
     ]
    }
   ],
   "source": [
    "tttt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_font = {'fontname':'Arial', 'size':'15'}\n",
    "#tw1=tad.iloc[1:,0];Acdw1=tad.iloc[1:,1];\n",
    "tw1=a.iloc[0:,0];Acdw=a.iloc[0:,1];Acdlh=a.iloc[0:,2];Acdrh=a.iloc[0:,3]\n",
    "# plt.plot(tw1,Acdw1,c='g')\n",
    "plt.plot(tw1,Acdw,'g',linewidth=2,marker='*')\n",
    "plt.plot(tw1, Acdlh,'--r',linewidth=2,marker='o')\n",
    "plt.plot(tw1, Acdrh,'--b',linewidth=2,marker='x')\n",
    "plt.title(\"100ms_10ms_clear\")\n",
    "plt.xlim(0,200)\n",
    "# plt.plot(tw1,Acdw1, 'k--', label='noise')\n",
    "# plt.xlabel('Time (ms)',**axis_font)\n",
    "# plt.ylabel('Accuracy (%)',**axis_font)\n",
    "# plt.title('Whole brain',**axis_font)\n",
    "# plt.yticks(**axis_font)\n",
    "# plt.xticks(**axis_font)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.gca().legend(('Whole','LH','RH'),fontsize=16,loc='best')\n",
    "# plt.savefig('whole_acc_timem.eps')\n",
    "# plt.savefig('whole_acc_timem.tif')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clf.best_estimator_.support_vectors_)*100.0/(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wpath=\"/home/sultan/EEG/Source_Level_Analysis/SVM_results/\"\n",
    "# dall=a\n",
    "# dall.to_csv(wpath+'svm_res_Baseline_100sam_10ms_clear_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
