{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,ShuffleSplit\n",
    "from sklearn import svm\n",
    "import sys\n",
    "# sys.path.append('/home/ralfahad/PythonUtility/PTE')\n",
    "# from PhaseTE_MF import PhaseTE_MF\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "import warnings\n",
    "from sklearn import svm, metrics,preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,roc_curve, auc,classification_report\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "from scipy.stats import norm\n",
    "# from sklearn import metrics\n",
    "# import seaborn as sns; sns.set(font_scale=1.2)\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>1418</th>\n",
       "      <th>1419</th>\n",
       "      <th>1420</th>\n",
       "      <th>1421</th>\n",
       "      <th>1422</th>\n",
       "      <th>1423</th>\n",
       "      <th>1424</th>\n",
       "      <th>1425</th>\n",
       "      <th>1426</th>\n",
       "      <th>1427</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.270001e-10</td>\n",
       "      <td>1.756739e-10</td>\n",
       "      <td>-1.582226e-10</td>\n",
       "      <td>-1.382528e-10</td>\n",
       "      <td>-1.566167e-10</td>\n",
       "      <td>-1.135809e-10</td>\n",
       "      <td>-1.100892e-10</td>\n",
       "      <td>-1.589276e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.110038e-10</td>\n",
       "      <td>1.152507e-10</td>\n",
       "      <td>-2.399226e-10</td>\n",
       "      <td>3.433448e-10</td>\n",
       "      <td>2.240594e-10</td>\n",
       "      <td>3.181698e-10</td>\n",
       "      <td>-1.644904e-10</td>\n",
       "      <td>1.001664e-10</td>\n",
       "      <td>-5.799119e-11</td>\n",
       "      <td>-4.880700e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.456352e-10</td>\n",
       "      <td>2.865467e-10</td>\n",
       "      <td>-2.532695e-10</td>\n",
       "      <td>-2.100140e-10</td>\n",
       "      <td>-2.099953e-10</td>\n",
       "      <td>-5.603980e-12</td>\n",
       "      <td>-2.883015e-10</td>\n",
       "      <td>1.572863e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>8.383168e-11</td>\n",
       "      <td>2.517060e-10</td>\n",
       "      <td>-8.620627e-11</td>\n",
       "      <td>2.037169e-10</td>\n",
       "      <td>2.261165e-10</td>\n",
       "      <td>3.166203e-10</td>\n",
       "      <td>-7.354289e-11</td>\n",
       "      <td>-5.902324e-11</td>\n",
       "      <td>-4.279494e-11</td>\n",
       "      <td>-3.508126e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 1430 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  label             0             1             2             3  \\\n",
       "0           0    0.0  4.270001e-10  1.756739e-10 -1.582226e-10 -1.382528e-10   \n",
       "1           1    0.0  5.456352e-10  2.865467e-10 -2.532695e-10 -2.100140e-10   \n",
       "\n",
       "              4             5             6             7      ...       \\\n",
       "0 -1.566167e-10 -1.135809e-10 -1.100892e-10 -1.589276e-10      ...        \n",
       "1 -2.099953e-10 -5.603980e-12 -2.883015e-10  1.572863e-11      ...        \n",
       "\n",
       "           1418          1419          1420          1421          1422  \\\n",
       "0  1.110038e-10  1.152507e-10 -2.399226e-10  3.433448e-10  2.240594e-10   \n",
       "1  8.383168e-11  2.517060e-10 -8.620627e-11  2.037169e-10  2.261165e-10   \n",
       "\n",
       "           1423          1424          1425          1426          1427  \n",
       "0  3.181698e-10 -1.644904e-10  1.001664e-10 -5.799119e-11 -4.880700e-10  \n",
       "1  3.166203e-10 -7.354289e-11 -5.902324e-11 -4.279494e-11 -3.508126e-10  \n",
       "\n",
       "[2 rows x 1430 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the metadata\n",
    "# path='/home/sultan/EEG/Source_Level_Analysis/25sam_10ms_clear_all_erp.csv'\n",
    "# path=\"/home/sultan/EEG/Source_Level_Analysis/50tr10ms_all_clear_erp.csv\"\n",
    "# path=\"/home/sultan/EEG/Source_Level_Analysis/75sam_10ms_clear_all_erp.csv\"\n",
    "# path=\"/home/sultan/EEG/Source_Level_Analysis/Baseline_100sam_10ms_clear_all_erp.csv\"\n",
    "path=\"/home/sultan/EEG/Source_Level_Analysis/100sam_10ms_noise_all_erp.csv\"\n",
    "# path=\"/home/sultan/EEG/Source_Level_Analysis/125sam_10ms_clear_all_erp.csv\"\n",
    "Metadata=pd.read_csv(path)\n",
    "Metadata.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random state; \n",
    "rs=53;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1804, 1428), (1804,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=Metadata.iloc[:,2:]\n",
    "y=Metadata['label']\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply SVM on Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma_range = np.logspace(-2, 2, 5)\n",
    "gamma_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1804, 1428) (1804,)\n",
      "[1.e-02 1.e-01 1.e+00 1.e+01 1.e+02] [0.01, 0.002, 0.00069, 0.0007, 0.0005]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "# X=preprocessing.scale(X)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "print X.shape,y.shape\n",
    "from sklearn.preprocessing import label_binarize\n",
    "y=label_binarize(np.asarray(y),[0,1])\n",
    "\n",
    "#C_range = np.logspace(-2, 10, 13)\n",
    "# gamma_range = np.logspace(-2, 2, 5)\n",
    "gamma_range = [0.01,0.002,0.00069,0.0007,0.0005]\n",
    "C_range = np.logspace(-2, 2, 5)\n",
    "#gamma_range = np.logspace(-2, 2, 5)\n",
    "\n",
    "print C_range,gamma_range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## here I disable the l-15 clf_tune....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classifiaction:\n",
    "# #Splitting\n",
    "from sklearn import preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,random_state=rs)\n",
    "cv = ShuffleSplit(X_train.shape[0], test_size=0.20, random_state=rs)\n",
    "\n",
    "# Define Classifier\n",
    "svr = svm.SVC(kernel='rbf')\n",
    "\n",
    "# Deffine tuning parameter\n",
    "C_range = np.logspace(-2, 2, 5)\n",
    "# gamma_range = np.logspace(-2, 2, 5)\n",
    "gamma_range = [0.01,0.002,0.00069,0.0007,0.0005]\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "# clf_Tune = GridSearchCV(estimator=svr, cv=5, param_grid=param_grid,n_jobs=-1, verbose=True)\n",
    "# clf_Tune.fit(X_train,y_train)\n",
    "# print 'Finish tuning'      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_p=clf_Tune.best_estimator_.predict(X_test)\n",
    "# print \"Accuracy:\", clf_Tune.score(X_test, y_test)  \n",
    "# # print pred\n",
    "# # print y_test\n",
    "# print \"support:\", len(clf_Tune.best_estimator_.support_vectors_)*100.0/(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print 'Validation accuracy={}, best {}' .format(clf_Tune.best_score_,clf_Tune.best_params_)\n",
    "# clf_Tune.best_params_\n",
    "# # clf_Tune.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## uptothis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Utility function to move the midpoint of a colormap to be around\n",
    "# # the values of interest.\n",
    "# from matplotlib.colors import Normalize\n",
    "# class MidpointNormalize(Normalize):\n",
    "\n",
    "#     def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "#         self.midpoint = midpoint\n",
    "#         Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "#     def __call__(self, value, clip=None):\n",
    "#         x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "#         return np.ma.masked_array(np.interp(value, x, y))\n",
    "    \n",
    "# scores = clf_Tune.cv_results_['mean_test_score'].reshape(len(C_range),len(gamma_range))\n",
    "# #print scores.shape,len(C_range),len(gamma_range)\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# #plt.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n",
    "# plt.imshow(scores, interpolation='nearest', cmap=plt.cm.hot, norm=MidpointNormalize(vmin=0.2, midpoint=0.92))\n",
    "# plt.xlabel('gamma')\n",
    "# plt.ylabel('C')\n",
    "# plt.colorbar()\n",
    "# plt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n",
    "# plt.yticks(np.arange(len(C_range)), C_range)\n",
    "# plt.title('Validation accuracy={}, best {}' .format(clf_Tune.best_score_,clf_Tune.best_params_))\n",
    "\n",
    "# #filename='ParameterTuning'\n",
    "# #save_format='png'\n",
    "# #print filename+'.'+save_format\n",
    "# #pp='home/ralfahad/Pictures'\n",
    "# #plt.savefig(filename+'.'+save_format,dpi=100)\n",
    "# #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Significant correlation with stability selections "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.67814456,  0.15669646, -0.30946844, -0.22098055, -0.67369314,\n",
       "       -0.48778411,  0.07977262, -1.51255317, -0.17331251, -0.14478503])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre Processing \n",
    "X[0,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1804, 1428) (1804, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "X=preprocessing.scale(X)\n",
    "# scaler = preprocessing.StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "print X.shape,y.shape\n",
    "from sklearn.preprocessing import label_binarize\n",
    "y=label_binarize(np.asarray(y),[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.var(X[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import (RandomizedLasso, lasso_stability_path,LassoLarsCV)\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "#Model Library\n",
    "from sklearn.linear_model import (RandomizedLasso, lasso_stability_path, LassoLarsCV)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, RandomizedLogisticRegression\n",
    "from sklearn import svm\n",
    "\n",
    "# Performance analysis library \n",
    "from sklearn.model_selection import KFold, cross_val_score, LeaveOneOut, cross_val_predict\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split # test train split\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00284981])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    #warnings.simplefilter('ignore', UserWarning)\n",
    "    warnings.simplefilter('ignore', ConvergenceWarning)\n",
    "    lars_cv = LassoLarsCV(cv=5).fit(X, y)\n",
    "# print lars_cv.alpha_\n",
    "lars_cv.alphas_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00284981 0.00256483 0.00227985 0.00199487 0.00170988 0.0014249\n",
      " 0.00113992 0.00085494 0.00056996 0.00028498]\n"
     ]
    }
   ],
   "source": [
    "# Run the RandomizedLasso: we use a paths going down to .1*alpha_max\n",
    "# to avoid exploring the regime in which very noisy variables enter\n",
    "# the model\n",
    "alphas = np.linspace(lars_cv.alphas_[0], .1 * lars_cv.alphas_[0], 10)\n",
    "print alphas\n",
    "clf = RandomizedLasso(alpha=alphas,random_state=rs,max_iter=1000).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02, 0.03, 0.  , ..., 0.  , 0.  , 0.  ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Rank the Features according to the importance\n",
    "# names=range(0,1428) # Feature names used as 1-1428 features\n",
    "# cn=np.asarray(names) # converted as numpy.ndarray\n",
    "# # print \"Features sorted by their score:\"\n",
    "# b= sorted(zip(map(lambda x: round(x, 4), clf.scores_), cn), reverse=True)\n",
    "# bb=np.asarray(b)\n",
    "# rakfe=bb[bb[:,0]>0.34]\n",
    "# ROIs=rakfe[:,1]%68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print \"Features sorted by their score:\"\n",
    "# b= sorted(zip(map(lambda x: round(x, 4), clf.scores_), \n",
    "#                  cn), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bb=np.asarray(b)\n",
    "# # rf=np.where(bb[:,0]>0.7)\n",
    "# # ifea=np.squeeze(np.asarray(np.where(clf.scores_>=0.815)))\n",
    "# ra=bb[bb[:,0]>0.50]\n",
    "# # r=bb[e]\n",
    "# ra[:,1]%68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ind=np.where(clf.scores_>=0.710)\n",
    "# ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter\n",
    "data=clf.scores_\n",
    "fig, ax = plt.subplots()\n",
    "counts, bins, patches = ax.hist(data,bins=np.round(0.1*np.arange(0,10),2) ,edgecolor='gray')\n",
    "\n",
    "# Set the ticks to be at the edges of the bins.\n",
    "ax.set_xticks(bins)\n",
    "\n",
    "# Set the xaxis's tick labels to be formatted with 1 decimal place...\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter('%0.1f'))\n",
    "\n",
    "\n",
    "# Label the raw counts and the percentages below the x-axis...\n",
    "bin_centers = 0.5 * np.diff(bins) + bins[:-1]\n",
    "for count, x in zip(counts, bin_centers):\n",
    "    # Label the raw counts\n",
    "    ax.annotate(str(count), xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "        xytext=(0, -18), textcoords='offset points', va='top', ha='center')\n",
    "\n",
    "    # Label the percentages\n",
    "    percent = '%0.0f%%' % (100 * float(count) / counts.sum())\n",
    "    ax.annotate(percent, xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "        xytext=(0, -32), textcoords='offset points', va='top', ha='center')\n",
    "\n",
    "\n",
    "# Give ourselves some more room at the bottom of the plot\n",
    "plt.subplots_adjust(bottom=0.15)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9]\n",
      "[0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9]\n"
     ]
    }
   ],
   "source": [
    "Th_2_Bins_Index= np.where((bins<=1.0) & (bins>=0.0)) # take the bins within a range\n",
    "# print Th_2_Bins_Index\n",
    "print bins\n",
    "Th_2_Bins=bins[Th_2_Bins_Index]\n",
    "print Th_2_Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1804, 1428) (1804, 1)\n",
      "(1443, 1428) (361, 1428) (1443, 1) (361, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "X=preprocessing.scale(X)\n",
    "print X.shape,y.shape\n",
    "from sklearn.preprocessing import label_binarize\n",
    "y=label_binarize(np.asarray(y),[0,1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rs)\n",
    "print X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.55140356, -0.20517394,  0.03449121, ..., -0.60399898,\n",
       "         0.65247799,  0.39627747],\n",
       "       [-0.82352793, -0.70349053, -1.12936675, ..., -0.37663084,\n",
       "        -0.72824404, -0.45430628],\n",
       "       [ 1.27950148, -0.7408457 , -0.93416599, ..., -0.36361161,\n",
       "         0.15566685,  0.57384258],\n",
       "       ...,\n",
       "       [ 0.22101097,  0.54979101,  0.37063901, ...,  1.1369938 ,\n",
       "        -1.37903969, -0.41634861],\n",
       "       [-0.94242887,  1.53028742,  1.89935983, ..., -1.71948438,\n",
       "         0.07273096,  1.31079737],\n",
       "       [ 0.05353941,  1.6017647 ,  1.70557364, ..., -0.23021553,\n",
       "         0.0533477 , -0.77853545]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:,1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)#[:,np.squeeze(np.asarray(np.where(clf.scores_>=0.16)))].shape#,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 65 candidates, totalling 325 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 325 out of 325 | elapsed:  9.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'C': [1, 2, 4, 6, 8, 10, 12, 15, 16, 20, 30, 40, 100], 'gamma': [0.01, 0.002, 0.00069, 0.0007, 0.0005]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C_range = np.logspace(-2, 2, 5)\n",
    "C_range = [1,2,4,6,8,10,12,15,16,20,30,40,100]\n",
    "gamma_range = [0.01,0.002,0.00069,0.0007,0.0005]\n",
    "# gamma_range = np.logspace(-2, 2, 5)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "#clf_Tune = GridSearchCV(estimator=svr, cv=1, param_grid=param_grid,n_jobs=-1)\n",
    "clf_Tune = GridSearchCV(estimator=svr, cv=5, param_grid=param_grid,n_jobs=-1, verbose=True)\n",
    "clf_Tune.fit(X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=Th_2_Bins[0])))],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8448753462603878\n"
     ]
    }
   ],
   "source": [
    "# use tuned parameter on to get model\n",
    "y_p = clf_Tune.best_estimator_.predict(X_test[:,np.squeeze(np.asarray(np.where(clf.scores_>=Th_2_Bins[0])))])\n",
    "\n",
    "print accuracy_score(y_test, y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "(1443, 1428)\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:  4.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1443, 1428) (1443, 1)\n",
      "Finish tuning\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.002, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Shape (361, 1428)\n",
      "ACC 0.817174515235457 0.7934817019121184\n",
      "0.939015939016\n",
      "0.1\n",
      "(1443, 332)\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:   46.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1443, 332) (1443, 1)\n",
      "Finish tuning\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.002, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Shape (361, 332)\n",
      "ACC 0.8587257617728532 0.8557838419653033\n",
      "0.569646569647\n",
      "0.2\n",
      "(1443, 198)\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:   28.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1443, 198) (1443, 1)\n",
      "Finish tuning\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.002, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Shape (361, 198)\n",
      "ACC 0.8587257617728532 0.8587754843611499\n",
      "0.50103950104\n",
      "0.3\n",
      "(1443, 103)\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:   18.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1443, 103) (1443, 1)\n",
      "Finish tuning\n",
      "SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Shape (361, 103)\n",
      "ACC 0.8642659279778393 0.8545175383056858\n",
      "0.611226611227\n",
      "0.4\n",
      "(1443, 59)\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:   12.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1443, 59) (1443, 1)\n",
      "Finish tuning\n",
      "SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.002, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Shape (361, 59)\n",
      "ACC 0.8227146814404432 0.8211346080790175\n",
      "0.451143451143\n",
      "0.5\n",
      "(1443, 22)\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:    7.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1443, 22) (1443, 1)\n",
      "Finish tuning\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Shape (361, 22)\n",
      "ACC 0.7534626038781164 0.7561890591363809\n",
      "0.533610533611\n",
      "0.6\n",
      "(1443, 4)\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 118 out of 125 | elapsed:    5.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:    5.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1443, 4) (1443, 1)\n",
      "Finish tuning\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.25, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Shape (361, 4)\n",
      "ACC 0.631578947368421 0.6175129796125112\n",
      "0.756063756064\n",
      "0.7\n",
      "(1443, 2)\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 118 out of 125 | elapsed:    5.2s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:    5.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1443, 2) (1443, 1)\n",
      "Finish tuning\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.25, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Shape (361, 2)\n",
      "ACC 0.590027700831025 0.5153222742813727\n",
      "0.797643797644\n",
      "0.8\n",
      "(1443,)\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "error at: 0.8\n",
      "0.9\n",
      "(1443,)\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "error at: 0.9\n"
     ]
    }
   ],
   "source": [
    "# #Splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rs)\n",
    "#cv = ShuffleSplit(X_train.shape[0], test_size=0.2, random_state=rs)\n",
    "\n",
    "# Define Classifier\n",
    "svr = svm.SVC(kernel='rbf')\n",
    "\n",
    "# Deffine tuning parameter\n",
    "# C_range = np.logspace(-2, 10, 13)\n",
    "# gamma_range = np.logspace(-9, 3, 13)\n",
    "\n",
    "C_range = np.logspace(-2, 2, 5)\n",
    "gamma_range = [1,0.5, 0.25,0.01,0.002]\n",
    "# gamma_range = [0.01,0.002,0.0006,0.0007]\n",
    "# gamma_range = [0.1,0.01,0.002,0.0005,0.0006,0.0007,]\n",
    "# C_range = [20, 30,50]\n",
    "# C_range=[1000,1500]\n",
    "# C_range = [1,2,4,6,8,10,12,15,16,20,30,40,100]\n",
    "# gamma_range = [0.01,0.015, 0.018, 0.002,0.003,0.0004, 0.0005,0.0006,0.0007]; # 0.0007=1/1428 1428 = no. of features\n",
    "# gamma_range = np.logspace(-2, 2, 5)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "#clf_Tune = GridSearchCV(estimator=svr, cv=1, param_grid=param_grid,n_jobs=-1)\n",
    "clf_Tune = GridSearchCV(estimator=svr, cv=5, param_grid=param_grid,n_jobs=-1, verbose=True)\n",
    "##  Define LeaveOneOutCrossValidation\n",
    "#loocv = LeaveOneOut()\n",
    "ACC_Th2=[]\n",
    "AUC_Th2=[]\n",
    "SV=[]\n",
    "Bins=[]\n",
    "Fsc=[]\n",
    "for i in Th_2_Bins:\n",
    "    print i\n",
    "    try:\n",
    "        print X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))].shape\n",
    "        \n",
    "        #Hyper parameter Tuning \n",
    "        clf_Tune.fit(X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))],y_train)\n",
    "        print X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))].shape ,y_train.shape\n",
    "        print 'Finish tuning'\n",
    "        print clf_Tune.best_estimator_\n",
    "\n",
    "        # use tuned parameter on to get model\n",
    "        y_p = clf_Tune.best_estimator_.predict(X_test[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))])\n",
    "\n",
    "        ACC_Th2_T=accuracy_score(y_test, y_p)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test,y_p)\n",
    "        AUC_Th2_T=metrics.auc(fpr, tpr)\n",
    "        perf=classification_report(y_test, y_p)\n",
    "        print 'Shape', X_test[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))].shape\n",
    "        print 'ACC',ACC_Th2_T,AUC_Th2_T\n",
    "        SVe=float(len(clf_Tune.best_estimator_.support_vectors_))/X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))].shape[0]\n",
    "        print SVe\n",
    "        SV.append(SVe)\n",
    "#         print 'Report',classification_report(y_test, y_p)\n",
    "        ACC_Th2.append(ACC_Th2_T)\n",
    "        AUC_Th2.append(AUC_Th2_T)\n",
    "        Fsc.append(perf)\n",
    "        Bins.append(i)\n",
    "    except:\n",
    "        print 'error at:',i\n",
    "    # false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_p)\n",
    "    # roc_auc_T = auc(false_positive_rate, true_positive_rate)\n",
    "    # print 'AUC',roc_auc_T\n",
    "    # AUC_Th2.append(roc_auc_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score(y_test, y_p)\n",
    "# MulticlassAuc(y_test,y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.817174515235457\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.66      0.75       149\n",
      "          1       0.79      0.93      0.86       212\n",
      "\n",
      "avg / total       0.82      0.82      0.81       361\n",
      "\n",
      "0.8587257617728532\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.84      0.83       149\n",
      "          1       0.89      0.87      0.88       212\n",
      "\n",
      "avg / total       0.86      0.86      0.86       361\n",
      "\n",
      "0.8587257617728532\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.86      0.83       149\n",
      "          1       0.90      0.86      0.88       212\n",
      "\n",
      "avg / total       0.86      0.86      0.86       361\n",
      "\n",
      "0.8642659279778393\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.80      0.83       149\n",
      "          1       0.87      0.91      0.89       212\n",
      "\n",
      "avg / total       0.86      0.86      0.86       361\n",
      "\n",
      "0.8227146814404432\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.81      0.79       149\n",
      "          1       0.86      0.83      0.85       212\n",
      "\n",
      "avg / total       0.82      0.82      0.82       361\n",
      "\n",
      "0.7534626038781164\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.77      0.72       149\n",
      "          1       0.82      0.74      0.78       212\n",
      "\n",
      "avg / total       0.76      0.75      0.76       361\n",
      "\n",
      "0.631578947368421\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.54      0.55       149\n",
      "          1       0.68      0.70      0.69       212\n",
      "\n",
      "avg / total       0.63      0.63      0.63       361\n",
      "\n",
      "0.590027700831025\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.09      0.15       149\n",
      "          1       0.60      0.94      0.73       212\n",
      "\n",
      "avg / total       0.56      0.59      0.49       361\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-1033f4833abe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0mACC_Th2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mFsc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(0,9):\n",
    "    print ACC_Th2[i] \n",
    "    print (Fsc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "#         ACC_Th2_T=accuracy_score(y_test, y_p)\n",
    "#         AUC_Th2_T=MulticlassAuc(y_test,y_p)\n",
    "#         print 'Shape', X_test[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))].shape\n",
    "#         print 'ACC',ACC_Th2_T,AUC_Th2_T\n",
    "#         ACC_Th2.append(ACC_Th2_T)\n",
    "#         AUC_Th2.append(AUC_Th2_T)\n",
    "#         Bins.append(i)\n",
    "#     except:\n",
    "#         print 'error at:',i\n",
    "#     # false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_p)\n",
    "#     # roc_auc_T = auc(false_positive_rate, true_positive_rate)\n",
    "#     # print 'AUC',roc_auc_T\n",
    "#     # AUC_Th2.append(roc_auc_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC_Th2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter\n",
    "Th_2_Bins=np.asarray(Bins)\n",
    "data=clf.scores_\n",
    "fig, ax = plt.subplots()\n",
    "fig.subplots_adjust(right=0.75)\n",
    "#counts, bins, patches = ax.hist(data,10 ,edgecolor='gray')\n",
    "counts, bins, patches = ax.hist(data,bins=np.round(0.1*np.arange(0,10),2),facecolor=\"None\",edgecolor='blue', lw=1)\n",
    "# Set the ticks to be at the edges of the bins.\n",
    "ax.set_xticks(bins)\n",
    "# Set the xaxis's tick labels to be formatted with 1 decimal place...\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter('%0.1f'))\n",
    "\n",
    "\n",
    "bin_centers = 0.5 * np.diff(bins) + bins[:-1]\n",
    "\n",
    "#show % value\n",
    "for count, x in zip(counts, bin_centers):\n",
    "    # Label the raw counts\n",
    "    ax.annotate(int(count), xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "        xytext=(0, -18), textcoords='offset points', va='top', ha='center')\n",
    "\n",
    "    # Label the percentages\n",
    "    percent = '%0.0f%%' % (100 * float(count) / counts.sum())\n",
    "    ax.annotate(percent, xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "        xytext=(0, -32), textcoords='offset points', va='top', ha='center')\n",
    "    \n",
    "    # Give ourselves some more room at the bottom of the plot\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(Th_2_Bins,AUC_Th2, color='red',ls='dashed' )#,THbin,CCC_Per)\n",
    "ax2.set_frame_on(False)\n",
    "ax2.set_ylabel('AUC', color='red')\n",
    "ax2.patch.set_visible(False)\n",
    "for i,j in zip(Th_2_Bins,AUC_Th2):\n",
    "    #ax2.annotate((\"%.2f\" % j),xy=(i+0.04,j-0.01), color ='red') ##############################\n",
    "    ax2.annotate((\"%.3f\" % j),xy=(i,j-0.01), color ='red') ##############################\n",
    "    ax2.plot(i,j, marker='o', markersize=7, color=\"red\")\n",
    "\n",
    "\n",
    "    \n",
    "ax3 = ax.twinx()\n",
    "ax3.plot(Th_2_Bins,ACC_Th2, color='black')#,THbin,CCC_Per)\n",
    "ax3.set_frame_on(False)\n",
    "ax3.set_ylabel('Accuracy', color='black')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i,j in zip(Th_2_Bins,ACC_Th2):\n",
    "     #ax3.annotate((\"%0.2f\" % j),xy=(i-0.05,j), color='black')\n",
    "    #ax3.annotate((\"%0.2f\" % j),xy=(i-0.1,j), color='black')##################################\n",
    "    ax3.annotate((\"%0.3f\" % j),xy=(i,j+0.01), color='black')##################################\n",
    "    ax3.plot(i,j, marker='*', markersize=10, color=\"black\")\n",
    "    #ax3.annotate((\"%0.2f,%0.2f\" % (i,j)),xy=(i-0.05,j), color='green')\n",
    "    #ax3.annotate((\"%0.3f\" %j),xy=(i,j), color='green')\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Move the last y-axis spine over to the right by 20% of the width of the axes\n",
    "ax3.spines['right'].set_position(('axes', 1.15))\n",
    "ax3.spines['right'].set_visible(True)\n",
    "\n",
    "# To make the border of the right-most axis visible, we need to turn the frame\n",
    "# on. This hides the other plots, however, so we need to turn its fill off.\n",
    "ax3.set_frame_on(True)\n",
    "ax3.patch.set_visible(False)\n",
    "\n",
    "\n",
    "#ax.plot(bins,np.linspace(0,1,11))\n",
    "plt.subplots_adjust(bottom=0.15)\n",
    "plt.grid(False,which='both')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.yaxis.label.set_color('Blue')\n",
    "plt.title(\"Noise\")\n",
    "plt.tight_layout()\n",
    "# #Save the image into a folder\n",
    "\n",
    "filename='StabilitySelection_clear'\n",
    "save_format='png'\n",
    "#print filename+'.'+save_format\n",
    "#pp='home/ralfahad/Pictures'\n",
    "#plt.savefig(filename+'.'+save_format,dpi=100)\n",
    "# plt.savefig(filename+'.'+save_format,dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROIs added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roisc=[68,68,61,45,22,8,3,0,2]\n",
    "roisc=[68,64,56,46,35,13,5,2,2]\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "Th_2_Bins=np.asarray(Bins)\n",
    "data=clf.scores_\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "fig.subplots_adjust(right=0.75)\n",
    "#counts, bins, patches = ax.hist(data,10 ,edgecolor='gray')\n",
    "counts, bins, patches = ax.hist(data,bins=np.round(0.1*np.arange(0,10),2),facecolor=\"None\",edgecolor='blue', lw=1)\n",
    "# Set the ticks to be at the edges of the bins.\n",
    "ax.set_xticks(bins)\n",
    "# Set the xaxis's tick labels to be formatted with 1 decimal place...\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter('%0.1f'))\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "                tick.label.set_fontsize(14) \n",
    "\n",
    "bin_centers = 0.5 * np.diff(bins) + bins[:-1]\n",
    "\n",
    "#show % value\n",
    "for count, x,rois in zip(counts, bin_centers,roisc):\n",
    "    # Label the raw counts\n",
    "    ax.annotate(int(count), xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "        xytext=(0, -20), fontsize=14,textcoords='offset points', va='top', ha='center')\n",
    "\n",
    "    # Label the percentages\n",
    "    percent = '%0.0f%%' % (100 * float(count) / counts.sum())\n",
    "    ax.annotate(percent, xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "        xytext=(0, -40), fontsize=14,textcoords='offset points', va='top', ha='center')\n",
    "    # ROIs\n",
    "    ax.annotate(rois, xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "    xytext=(0, -60),fontsize=14, textcoords='offset points', va='top', ha='center')\n",
    "    \n",
    "    # Give ourselves some more room at the bottom of the plot\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(Th_2_Bins,AUC_Th2, color='red',ls='dashed',alpha=0.5)#,THbin,CCC_Per)\n",
    "ax2.set_frame_on(False)\n",
    "ax2.set_ylabel('AUC', color='red',fontsize=15)\n",
    "ax2.patch.set_visible(False)\n",
    "for i,j in zip(Th_2_Bins,AUC_Th2):\n",
    "    #ax2.annotate((\"%.2f\" % j),xy=(i+0.04,j-0.01), color ='red') ##############################\n",
    "    ax2.annotate((\"%.3f\" % j),xy=(i,j-0.01), color ='red',fontsize=12) ##############################\n",
    "    ax2.plot(i,j, marker='o', markersize=7, color=\"red\")\n",
    "\n",
    "\n",
    "    \n",
    "ax3 = ax.twinx()\n",
    "ax3.plot(Th_2_Bins,ACC_Th2, color='black')#,THbin,CCC_Per)\n",
    "ax3.set_frame_on(False)\n",
    "ax3.set_ylabel('Accuracy', color='black',fontsize=15)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i,j in zip(Th_2_Bins,ACC_Th2):\n",
    "     #ax3.annotate((\"%0.2f\" % j),xy=(i-0.05,j), color='black')\n",
    "    #ax3.annotate((\"%0.2f\" % j),xy=(i-0.1,j), color='black')##################################\n",
    "    ax3.annotate((\"%0.3f\" % j),xy=(i,j+0.015), color='black',fontsize=12)##################################\n",
    "    ax3.plot(i,j, marker='*', markersize=10, color=\"black\",alpha=0.2)\n",
    "    #ax3.annotate((\"%0.2f,%0.2f\" % (i,j)),xy=(i-0.05,j), color='green')\n",
    "    #ax3.annotate((\"%0.3f\" %j),xy=(i,j), color='green')\n",
    "    \n",
    "    \n",
    "# Move the last y-axis spine over to the right by 20% of the width of the axes\n",
    "ax3.spines['right'].set_position(('axes', 1.15))\n",
    "ax3.spines['right'].set_visible(True)\n",
    "\n",
    "# To make the border of the right-most axis visible, we need to turn the frame\n",
    "# on. This hides the other plots, however, so we need to turn its fill off.\n",
    "ax3.set_frame_on(True)\n",
    "ax3.patch.set_visible(False)\n",
    "\n",
    "\n",
    "#ax.plot(bins,np.linspace(0,1,11))\n",
    "plt.subplots_adjust(bottom=.15)\n",
    "plt.grid(False,which='both')\n",
    "ax.set_ylabel('Frequency',fontsize=15)\n",
    "ax.yaxis.label.set_color('Blue')\n",
    "plt.title(\"Noise\")\n",
    "plt.tight_layout()\n",
    "# #Save the image\n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "                tick.label.set_fontsize(14)\n",
    "filename='StabilitySelection_clear'\n",
    "save_format='png'\n",
    "#print filename+'.'+save_format\n",
    "#pp='home/ralfahad/Pictures'\n",
    "#plt.savefig(filename+'.'+save_format,dpi=100)\n",
    "plt.savefig(filename+'.'+save_format,dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make it inside boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roisc=[68,68,61,45,22,8,3,0,2]\n",
    "roisc=[68,64,56,46,35,13,5,2,2]\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "Th_2_Bins=np.asarray(Bins)\n",
    "data=clf.scores_\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "fig.subplots_adjust(right=0.75)\n",
    "#counts, bins, patches = ax.hist(data,10 ,edgecolor='gray')\n",
    "counts, bins, patches = ax.hist(data,bins=np.round(0.1*np.arange(0,10),2),facecolor=\"None\",edgecolor='blue', lw=1)\n",
    "# Set the ticks to be at the edges of the bins.\n",
    "ax.set_xticks(bins)\n",
    "# Set the xaxis's tick labels to be formatted with 1 decimal place...\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter('%0.1f'))\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "                tick.label.set_fontsize(14) \n",
    "\n",
    "bin_centers = 0.5 * np.diff(bins) + bins[:-1]\n",
    "\n",
    "#show % value\n",
    "for count, x,rois in zip(counts, bin_centers,roisc):\n",
    "    # Label the raw counts\n",
    "    ax.annotate(int(count), xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "        xytext=(0, -20), fontsize=14,textcoords='offset points', va='top', ha='center')\n",
    "\n",
    "    # Label the percentages\n",
    "    percent = '%0.0f%%' % (100 * float(count) / counts.sum())\n",
    "    ax.annotate(percent, xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "        xytext=(0, -40), fontsize=14,textcoords='offset points', va='top', ha='center')\n",
    "    # ROIs\n",
    "    ax.annotate(rois, xy=(x, 0), xycoords=('data', 'axes fraction'),\n",
    "    xytext=(0, -60),fontsize=14, textcoords='offset points', va='top', ha='center')\n",
    "    \n",
    "    # Give ourselves some more room at the bottom of the plot\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(Th_2_Bins,AUC_Th2, color='red',ls='dashed',alpha=0.5)#,THbin,CCC_Per)\n",
    "ax2.set_frame_on(False)\n",
    "ax2.set_ylabel('AUC', color='red',fontsize=15)\n",
    "ax2.patch.set_visible(False)\n",
    "for i,j in zip(Th_2_Bins,AUC_Th2):\n",
    "    #ax2.annotate((\"%.2f\" % j),xy=(i+0.04,j-0.01), color ='red') ##############################\n",
    "    ax2.annotate((\"%.3f\" % j),xy=(i,j-0.012), color ='red',fontsize=12) ##############################\n",
    "    ax2.plot(i,j, marker='o', markersize=7, color=\"red\")\n",
    "\n",
    "\n",
    "    \n",
    "ax3 = ax.twinx()\n",
    "ax3.plot(Th_2_Bins,ACC_Th2, color='black')#,THbin,CCC_Per)\n",
    "ax3.set_frame_on(False)\n",
    "ax3.set_ylabel('Accuracy', color='black',fontsize=15)\n",
    "\n",
    "\n",
    "\n",
    "for i,j in zip(Th_2_Bins,ACC_Th2):\n",
    "     #ax3.annotate((\"%0.2f\" % j),xy=(i-0.05,j), color='black')\n",
    "    #ax3.annotate((\"%0.2f\" % j),xy=(i-0.1,j), color='black')##################################\n",
    "    ax3.annotate((\"%0.3f\" % j),xy=(i,j+0.0065), color='black',fontsize=12)##################################\n",
    "    ax3.plot(i,j, marker='*', markersize=10, color=\"black\",alpha=0.2)\n",
    "    #ax3.annotate((\"%0.2f,%0.2f\" % (i,j)),xy=(i-0.05,j), color='green')\n",
    "    #ax3.annotate((\"%0.3f\" %j),xy=(i,j), color='green')\n",
    "    \n",
    "    \n",
    "# Move the last y-axis spine over to the right by 20% of the width of the axes\n",
    "ax3.spines['right'].set_position(('axes', 1.15))\n",
    "ax3.spines['right'].set_visible(True)\n",
    "\n",
    "# To make the border of the right-most axis visible, we need to turn the frame\n",
    "# on. This hides the other plots, however, so we need to turn its fill off.\n",
    "ax3.set_frame_on(True)\n",
    "ax3.patch.set_visible(False)\n",
    "\n",
    "#ax.plot(bins,np.linspace(0,1,11))\n",
    "plt.subplots_adjust(bottom=.15)\n",
    "plt.grid(False,which='both')\n",
    "ax.set_ylabel('Frequency',fontsize=15)\n",
    "ax.yaxis.label.set_color('Blue')\n",
    "plt.title(\"Noise speech\", fontsize=15)\n",
    "plt.tight_layout()\n",
    "# #Save the image\n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "                tick.label.set_fontsize(12)\n",
    "filename='StabilitySelection_clear'\n",
    "save_format='png'\n",
    "#print filename+'.'+save_format\n",
    "#pp='home/ralfahad/Pictures'\n",
    "#plt.savefig(filename+'.'+save_format,dpi=100)\n",
    "# plt.savefig(filename+'.'+save_format,dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,j in zip(Th_2_Bins,AUC_Th2):\n",
    "#     print i,j\n",
    "All_ACC=[]\n",
    "All_AUC=[]\n",
    "ALL_Bins=[]\n",
    "All_SV=[]\n",
    "NumberofElement=[]\n",
    "for i,j,k,l in zip(Th_2_Bins,ACC_Th2,AUC_Th2, SV):\n",
    "    Th2Index=np.squeeze(np.asarray(np.where(clf.scores_>=i)))\n",
    "#     print (\"{0:.2f}\".format(i)),(\"{0:.2f}\".format(j)),(\"{0:.2f}\".format(k)),len(Th2Index),(\"{0:.2f}\".format(l))\n",
    "#     NumberofElement.append(len(Th2Index))\n",
    "    print (\"{0:.2f}\".format(i)),(\"{0:.2f}\".format(j)),(\"{0:.2f}\".format(k)),len(Th2Index)\n",
    "    NumberofElement.append(len(Th2Index))\n",
    "    ALL_Bins.append(\"{0:.2f}\".format(i))\n",
    "    All_ACC.append(\"{0:.2f}\".format(j))\n",
    "    All_AUC.append(\"{0:.2f}\".format(k))\n",
    "    All_SV.append(\"{0:.2f}\".format(l))\n",
    "\n",
    "# Selected_Feature_Result=pd.concat([pd.DataFrame(ALL_Bins),pd.DataFrame(All_ACC),\n",
    "#            pd.DataFrame(All_AUC),pd.DataFrame(NumberofElement),pd.DataFrame(All_SV)],axis=1)\n",
    "# Selected_Feature_Result.columns=['Threshold','ACC','AUC','NoEle','SV']\n",
    "Selected_Feature_Result=pd.concat([pd.DataFrame(ALL_Bins),pd.DataFrame(All_ACC),\n",
    "           pd.DataFrame(All_AUC),pd.DataFrame(NumberofElement)],axis=1)\n",
    "Selected_Feature_Result.columns=['Threshold','ACC','AUC','NoEle']\n",
    "Selected_Feature_Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Th_2_Bins[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to chage gamma range . It is selecting too many features\n",
    "# Let 0.34 is our best Thr. TO get the index numer with this thr\n",
    "fealoc=np.squeeze(np.asarray(np.where(clf.scores_>=Th_2_Bins[4])))\n",
    "fealoc\n",
    "# len(fealoc)\n",
    "# Do you get it? yes > How about number of support of the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI=fealoc%68\n",
    "ROI\n",
    "np.unique(ROI,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(ROI))\n",
    "# np.unique(ROI,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for th in Th_2_Bins:\n",
    "    clf_Tune.fit(X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=th)))],y_train)\n",
    "    print X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=th)))].shape ,y_train.shape\n",
    "    print 'Finish tuning'\n",
    "    print float(len(clf_Tune.best_estimator_.support_vectors_))/X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=th)))].shape[0]*100\n",
    "# use tuned parameter on to get model\n",
    "#y_p = clf_Tune.best_estimator_.predict(X_test[:,np.squeeze(np.asarray(np.where(clf.scores_>=i)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# float(len(clf_Tune.best_estimator_.support_vectors_))/X_train[:,np.squeeze(np.asarray(np.where(clf.scores_>=0.25)))].shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result it overfitting need to be less or equal to 40%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank the Feature Vectors as their importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank the Features according to the importance\n",
    "names=range(0,1428) # Feature names used as 1-1428 features\n",
    "cn=np.asarray(names) # converted as numpy.ndarray\n",
    "# print \"Features sorted by their score:\"\n",
    "b= sorted(zip(map(lambda x: round(x, 4), clf.scores_), cn), reverse=True)\n",
    "# print b\n",
    "bb=np.asarray(b)\n",
    "rakfe=bb[bb[:,0]>=Th_2_Bins[4]]\n",
    "# rakfe=bb[bb[:,0]>=.50]\n",
    "ROIs=rakfe[:,1]%68\n",
    "print ROIs\n",
    "print len(ROIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # b\n",
    "# ROIstime=np.floor(rakfe[:,1]/68)\n",
    "# timeloc=ROIstime*10\n",
    "# plt.hist(timeloc, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI\n",
    "print np.unique(ROI,return_counts=True)\n",
    "print len(np.unique(ROIs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Roiname=pd.read_csv(\"/home/sultan/EEG/Source_Level_Analysis/DK_atlas_Visualize_index_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nor=81\n",
    "shdkroi=Roiname['Desikan_Freesurfer_v5.1'] # \"Desikan_Freesurfer_v5.1\"  is the label of short name columns \n",
    "sdk=shdkroi[ROIs]# ROIs is the index of label\n",
    "# sdk.head(nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dkfull=Roiname['BrainMesh_ICBM152.nv']\n",
    "dk=dkfull[ROIs]\n",
    "print dk.head(nor)\n",
    "len(dk.head(nor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aa=pd.DataFrame(dk.values[0:nor])\n",
    "# aa.columns=['ROIs']\n",
    "# ab=aa.drop_duplicates()\n",
    "# Toprois=pd.DataFrame(ab.values)\n",
    "# print Toprois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rois1=bb[0:16,1]%68\n",
    "# pd.DataFrame(bb[0:16,0],shdkroi[rois1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saa=pd.DataFrame(sdk.values[0:nor])\n",
    "# saa.columns=['short ROIs']\n",
    "# sab=saa.drop_duplicates()\n",
    "# sToprois=pd.DataFrame(sab.values)\n",
    "# # print sToprois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nor1=14\n",
    "# sc=pd.DataFrame(bb[0:nor1,0])\n",
    "# sn=pd.concat([Toprois,sToprois,sc],axis=1)\n",
    "# sn.columns=['Fullname','ROIs short name', 'Feature score'] # sn: score and roi\n",
    "# # ddd=pd.DataFrame(bb[0:16,0],sToprois)\n",
    "# sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sn.to_csv('Top15fea.csv')\n",
    "# Th_2_Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=pd.DataFrame(dk.values[0:nor])\n",
    "aa.columns=['ROIs']\n",
    "Toprois=pd.DataFrame(aa.values)\n",
    "# print Toprois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saa=pd.DataFrame(sdk.values[0:nor])\n",
    "saa.columns=['short ROIs']\n",
    "sToprois=pd.DataFrame(saa.values)\n",
    "# print sToprois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nor1=75\n",
    "sc=pd.DataFrame(bb[0:nor1,0])\n",
    "sn=pd.concat([Toprois,sToprois,sc],axis=1)\n",
    "sn.columns=['Fullname','ROIs short name', ' Feature score'] # sn: score and roi\n",
    "# ddd=pd.DataFrame(bb[0:16,0],sToprois)\n",
    "sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allrois=sn.drop_duplicates(subset=['Fullname']) # Drop the duplicate name \n",
    "alluR=pd.DataFrame(allrois.values) #alluR is the unique ROIs\n",
    "alluR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alluR.to_csv('Top14.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wpath=\"/home/sultan/EEG/Source_Level_Analysis/SVM_results/\"\n",
    "# dall=alluR\n",
    "# dall.to_csv(wpath+'Clear_top_rois_0.4_stability.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clf.scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AllROIs_stability selection_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g=clf.scores_\n",
    "# allROIs=range(0,68)\n",
    "# x=[];\n",
    "# for i in allROIs:\n",
    "# #     print i\n",
    "#     r=np.arange(i,1428,68)\n",
    "#     l=np.int_(r)\n",
    "# #     ll=g[r]\n",
    "#     ll=g[l]\n",
    "#     x.append(ll)\n",
    "# hh=pd.DataFrame(x)  \n",
    "# t=np.linspace(0,200,21)\n",
    "# yu=hh.values\n",
    "# # yu=hh.values[[0,1,2,3,4,16],:]\n",
    "# plt.plot(t,yu.T)\n",
    "# plt.xlim(0, 200)\n",
    "# plt.ylim(0,1)\n",
    "# plt.grid(True)\n",
    "# plt.ylabel(\"Stability scores\")\n",
    "# plt.xlabel(\"Epoch time (ms)\")\n",
    "# plt.title(\"Clear_all\")\n",
    "# # plt.legend(leg)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t=np.linspace(0,200,21)\n",
    "# yu=hh.values\n",
    "# # yu=hh.values[[0,1,2,3,4,16],:]\n",
    "# plt.plot(t,yu.T)\n",
    "# plt.xlim(0, 200)\n",
    "# plt.ylim(0,1)\n",
    "# plt.grid(True)\n",
    "# plt.ylabel(\"Stability scores\")\n",
    "# plt.xlabel(\"Epoch time (ms)\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top score selected ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leg=['rTP','rFUS', 'rPRC','lPRC','lSP']\n",
    "# x=[];\n",
    "# for i in ROIs:\n",
    "# #     print i\n",
    "#     r=np.arange(i,1428,68)\n",
    "#     l=np.int_(r)\n",
    "# #     ll=g[r]\n",
    "#     ll=g[l]\n",
    "#     x.append(ll)\n",
    "# hh=pd.DataFrame(x)  \n",
    "# t=np.linspace(0,200,21)\n",
    "# yu=hh.values\n",
    "# # yu=hh.values[0:9,:]\n",
    "# # yu=hh.values[[0,1,2,3,4],:]\n",
    "# plt.plot(t,yu.T)\n",
    "# plt.xlim(0, 200)\n",
    "# plt.ylim(0,1)\n",
    "# plt.grid(True)\n",
    "# plt.ylabel(\"Stability scores\")\n",
    "# plt.xlabel(\"Epoch time (ms)\")\n",
    "# plt.title(\"Clear\")\n",
    "# # plt.legend(leg)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leg=['rTP','rFUS', 'rPRC','lPRC','lSP']\n",
    "# x=[];\n",
    "# for i in ROIs:\n",
    "# #     print i\n",
    "#     r=np.arange(i,1428,68)\n",
    "#     l=np.int_(r)\n",
    "# #     ll=g[r]\n",
    "#     ll=g[l]\n",
    "#     x.append(ll)\n",
    "# hh=pd.DataFrame(x)  \n",
    "# t=np.linspace(0,200,21)\n",
    "# yu=hh.values\n",
    "# # yu=hh.values[0:9,:]\n",
    "# yu=hh.values[[0,1,2,3,4],:]\n",
    "# plt.plot(t,yu.T)\n",
    "# plt.xlim(0, 200)\n",
    "# plt.ylim(0,1)\n",
    "# # plt.ylim(0.5,1)\n",
    "# plt.grid(True)\n",
    "# plt.ylabel(\"Stability scores\")\n",
    "# plt.xlabel(\"Epoch time (ms)\")\n",
    "# plt.title(\"Clear\")\n",
    "# plt.legend(leg)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leg=['rTP','rFUS', 'rPRC','lPRC','lSP']\n",
    "# x=[];\n",
    "# for i in ROIs:\n",
    "# #     print i\n",
    "#     r=np.arange(i,1428,68)\n",
    "#     l=np.int_(r)\n",
    "# #     ll=g[r]\n",
    "#     ll=g[l]\n",
    "#     x.append(ll)\n",
    "# hh=pd.DataFrame(x)  \n",
    "# t=np.linspace(0,200,21)\n",
    "# yu=hh.values\n",
    "# # yu=hh.values[0:9,:]\n",
    "# yu=hh.values[[0,1,2],:]\n",
    "# plt.plot(t,yu.T)\n",
    "# plt.xlim(0, 200)\n",
    "# plt.ylim(top=1)\n",
    "# # plt.ylim(0.50,1)\n",
    "# plt.grid(True)\n",
    "# plt.ylabel(\"Stability scores\")\n",
    "# plt.xlabel(\"Epoch time (ms)\")\n",
    "# plt.title(\"Clear\")\n",
    "# plt.legend(leg)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROIs=range(0,68)\n",
    "# x=[];\n",
    "# for i in ROIs:\n",
    "# #     print i\n",
    "#     r=np.arange(i,1428,68)\n",
    "#     l=np.int_(r)\n",
    "# #     ll=g[r]\n",
    "#     ll=g[l]\n",
    "#     x.append(ll)\n",
    "# hh=pd.DataFrame(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urois=[];\n",
    "names=range(0,1428) # Feature names used as 1-1428 features\n",
    "cn=np.asarray(names) # converted as numpy.ndarray\n",
    "# print \"Features sorted by their score:\"\n",
    "b= sorted(zip(map(lambda x: round(x, 4), clf.scores_), cn), reverse=True)\n",
    "# print b\n",
    "bb=np.asarray(b)\n",
    "for i in range(0,9):\n",
    "    rakfe=bb[bb[:,0]>=Th_2_Bins[i]]\n",
    "    # rakfe=bb[bb[:,0]>=.50]\n",
    "    ROIs=rakfe[:,1]%68\n",
    "#     print ROIs\n",
    "    print len(ROIs)\n",
    "    un= len(np.unique(ROIs));\n",
    "    urois.append(un)\n",
    "print urois    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_ACC=[]\n",
    "All_AUC=[]\n",
    "ALL_Bins=[]\n",
    "All_SV=[]\n",
    "All_UR=[];\n",
    "NumberofElement=[]\n",
    "for i,j,k,l,m in zip(Th_2_Bins,ACC_Th2,AUC_Th2, SV,urois):\n",
    "    Th2Index=np.squeeze(np.asarray(np.where(clf.scores_>=i)))\n",
    "#     print (\"{0:.2f}\".format(i)),(\"{0:.2f}\".format(j)),(\"{0:.2f}\".format(k)),len(Th2Index),(\"{0:.2f}\".format(l))\n",
    "#     NumberofElement.append(len(Th2Index))\n",
    "    print (\"{0:.2f}\".format(i)),(\"{0:.2f}\".format(j)),(\"{0:.2f}\".format(k)),len(Th2Index)\n",
    "    NumberofElement.append(len(Th2Index))\n",
    "    ALL_Bins.append(\"{0:.3f}\".format(i))\n",
    "    All_ACC.append(\"{0:.3f}\".format(j))\n",
    "    All_AUC.append(\"{0:.3f}\".format(k))\n",
    "    All_SV.append(\"{0:.3f}\".format(l))\n",
    "    All_UR.append(\"{0:.3f}\".format(m))\n",
    "\n",
    "# Selected_Feature_Result=pd.concat([pd.DataFrame(ALL_Bins),pd.DataFrame(All_ACC),\n",
    "#            pd.DataFrame(All_AUC),pd.DataFrame(NumberofElement),pd.DataFrame(All_SV)],axis=1)\n",
    "# Selected_Feature_Result.columns=['Threshold','ACC','AUC','NoEle','SV']\n",
    "Selected_Feature_Result=pd.concat([pd.DataFrame(ALL_Bins),pd.DataFrame(All_ACC),\n",
    "           pd.DataFrame(All_AUC),pd.DataFrame(NumberofElement),pd.DataFrame(All_UR)],axis=1)\n",
    "Selected_Feature_Result.columns=['Threshold','ACC','AUC','NoEle','UR']\n",
    "Selected_Feature_Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wpath=\"/home/sultan/EEG/Source_Level_Analysis/SVM_results/\"\n",
    "# dall=alluR\n",
    "# dall.to_csv(wpath+'Clear_top_rois_0.4_stability.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allrois=sn.drop_duplicates(subset=['Fullname']) # Drop the duplicate name \n",
    "alluR=pd.DataFrame(allrois.values) #alluR is the unique ROIs\n",
    "alluR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
